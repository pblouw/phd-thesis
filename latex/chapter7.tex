%----------------------------------------------------------------------
% MAIN BODY
%----------------------------------------------------------------------

%======================================================================
\chapter{How Meanings Do What They Do}
%======================================================================
\renewcommand{\epigraphrule}{0pt}
\setlength{\epigraphwidth}{4.5in}
\epigraph{\textit{In order to communicate with language, I must be able to predict how other people will react to my language. But no such predictions could possibly be made were it not for the possibility of conventions of use and response.}}{- Ruth Millikan, 2005}

\section{Introduction}

The core idea developed in this thesis is that linguistic expressions have meanings primarily in virtue of the fact that their uses license certain predictions in the context of intentional interpretation. A theory of meaning, then, is a theory of how speakers and listeners interact with one another so as to give rise to a predictive framework in which various forms of verbal behavior become communicatively significant. This theory takes shape as an account of how norms and conventions sustain patterns of social behavior in which utterances license speakers and listeners to form expectations about one another and the surrounding environment. The purpose of introducing the IPA framework is to organize this approach to thinking about language in terms of (a) the inferences that are licensed by particular linguistic expressions, (b) the predictions that uses of these expressions thereby sustain, and (c) the affordances that the expressions then come to possess as a result.

The IPA framework favors the development of an inferential role semantics, in which the inferential role of a sentence provides an explanation for why its utterance sustains certain predictions and affords certain opportunities for action. Put simply, it is the inferential relations that linguistic expressions bear both to one another and to non-linguistic perceptions and actions that allow these expressions to function as instruments of prediction in the context of intentional interpretation. Such inferential relations, in turn, are what a theory of semantics ought to codify or formalize. The methods and models discussed in Chapters 2 and 3 take up this challenge. Chapters 4 through 6 examine the theoretical implications of the resulting semantics. 

In this final chapter, my goal is to provide an all-things-considered evaluation of the theory developed in this thesis. To that end, I first summarize the theory's central claims and commitments. Next, I assess whether these claims and commitments are consistent with the criteria introduced in Chapter 1. I conclude with some general reflections and suggestions for future research.  

\section{Summarizing the Theory}

A basic presupposition of theory I have developed is that language use is a natural phenomenon. There is nothing special about language; it does not provide a window onto the world or a foundation for ``first philosophy'' \citep[see][]{Stanley:2008}. Given as much, linguistic phenomena are phenomena that involve organisms producing and responding to sounds and gestures of various kinds. The patterns that arise amongst these sounds and gestures can be fruitfully understood if they are assumed to be structured so as to allow those who use them to make successful predictions. These predictions are centered both on the behavior of other organisms and on the state of the surrounding environment. 

Some predictions, as discussed in Chapter 1, are more naturally described as pragmatic in nature. One who asks a question, for instance, will expect an answer, but they are unlikely to expect a \textit{specific} answer (otherwise, why ask the question?). Other predictions are more naturally described as semantic in nature. One who makes a claim, for instance, can be expected to acknowledge those things that follow from the claim (otherwise, why think the person understands what they have said?). These expectations on the part of language users can be in large part be explained on the assumption that language users engage in a reciprocal form of intentional interpretation \citep{Brandom:1994,Dennett:1987}. In short, people attribute linguistically-characterized mental states to one another, and implicitly derive behavioral predictions from these attributions.\footnote{The inferences underlying such predictions are often made explicit in the form of verbal explanations that derive what a person will do from what they think or believe: ``He'll be at the theater at 7:15 because he thinks the movie starts at 7:30 and doesn't want to miss the opening credits.''} Linguistic utterances are the main instruments through which intentional state attributions are updated and modified over time. 

Language users engage in ``dance-like'' dialogues with another by tracking how various linguistic acts determine which intentional states ought to be attributed to which individuals. These intentional state attributions are fundamentally holistic, perspectival, and predictive in nature. Chapter 1, overall, develops the idea that words and sentences mean what they do in virtue of the role they play in practices that involve intentional interpretation.

Chapter 2 lays the groundwork for formalizing the inferential relations that make intentional interpretation possible. I describe a number of mathematical techniques that exploit statistical patterns in text corpora to treat linguistic expressions as predictors of other linguistic expressions. I then describe variants of these techniques that rely on information about how linguistic expressions are distributed as premises and conclusions in a space of possible inferences, which allows for the introduction of models that codify inferential relationships between arbitrary pairs of sentences. Models of this nature, I contend, set the stage for formalizing the tacit predictions that result from intentional state attributions involving particular sentences. 

Chapter 3 provides the core technical contribution of the thesis in the form of a model that learns to generate sentences that are the inferential consequences of its inputs. The predictions made by this model are evaluated quantitatively and qualitatively. On a quantitative level, the model is primarily evaluated by measuring the accuracy (on a word-by-word basis) of the sentences it generates from inputs for which appropriate inferential consequences are known. On a qualitative level, the model is primarily evaluated in terms of how well it can iteratively generate the inferential role of an input sentence. Further qualitative evaluations are used to assess the model's sensitivity to word-level substitutions and the presence of certain theoretically interesting expressions such as quantifiers and numerals. Overall, the inferential relations formalized by this model are hypothesized to set down the predictions that are licensed by the attribution of certain intentional states. It is for this reason that the model provides a small first step towards making intentional systems theory less ``informal and unsystematic'' than it currently is \citep[][p. 67]{Dennett:1987}.

The remaining chapters are concerned with the broader theoretical implications of the view of language that emerges from the IPA framework. Chapter 4 concerns the principle of compositionality, and argues that the standard way of thinking about this principle is a red herring. It is a mistake to assume that meanings are entities that get assigned to complex linguistic expressions on the basis of certain rules for combining the meanings of their simpler constituents. The right way to think about compositionality is in terms of a capacity for generalizing from the predictions licensed by familiar uses of language to the predictions licensed by novel uses of language. I go on to explain this capacity by analyzing three different kinds of generalization: similarity-based, syntactic, and procedural. I then contend that it is possible to account for the flexibility of human language use in terms of similarity-based and procedural forms of generalization. I argue for this conclusion largely by appeal to the model introduced in Chapter 3 -- it generalizes to predictions far beyond those it was explicitly trained to perform, and it does this without making use of formal rules that assign meanings to complex expressions using the meanings of their simpler parts. Instead, the model generalizes on the basis of similarities amongst its inputs and the procedures that are used to transform these inputs into outputs. 

Chapter 5 addresses questions about the implications of my view for theories of mental representation and cognitive architecture. I argue, following Dennett (\citeyear{Dennett:1987}), that it only makes sense to treat the internal states of a system as representations if the behavior of the system can be predicted using the intentional stance. I go on to argue that this view has an important and overlooked consequence: one cannot begin with a prior theory of mental representation and then use this theory to derive an explanation of how intentional interpretation works; rather, one has to start with intentional interpretation before one can go on to describe certain system states in representational terms. One benefit of adopting this view is that it explains the fruitfulness of identifying representational states in cognitive systems, while avoiding any commitment to the idea that there are definite answers to questions about what a state \textit{really} represents.\footnote{Note that there are definite answers to questions about which causal relations a state gets caught up in. But it is widely accepted that these answers under-determine what the state represents \citep{Dennett:1987}.} Such questions have historically proven to be almost impossible to answer satisfactorily, and my position demonstrates why. I conclude the chapter with a discussion of evidence indicating that cognitive systems do in fact implement processes that sustain intentional interpretation. 

Chapter 6, finally, discusses the representational properties of linguistic expressions. I contend that if a theory of meaning is a theory of the inferential norms governing language use, then it makes sense to analyze the concepts of truth and reference in terms of these norms. It is plausible that uses of the word ``true'' function to express or emphasize that certain claims are able to indefinitely satisfy the main aim of descriptive language use, which is to foster success in prediction and action. Saying that a claim is true is a way of endorsing it with respect this ideal of success. This analysis carries over naturally to the concept of reference, since referring terms such as ``book'' are used to make demonstrative claims that similarly aim to foster success in prediction and action. Saying that a word refers is a way of endorsing its use in demonstrative constructions with respect to this ideal of success. As such, our words and sentences are \textit{about} things in virtue of being governed by norms that promote success in prediction and action.

The overall theory, then, is an inferential role semantics for natural language. Linguistic expressions mean what they do in virtue of how they license various inferences and predictions in the context of intentional interpretation. There are three main theoretical consequences that follow from this view. First, concerns about compositionality are really concerns about generalizing from familiar inferences involving known linguistic expressions to unfamiliar inferences involving novel linguistic expressions. Second, it is mistake to think of linguistic expressions as vehicles for conveying mental states, since there is no reasonable way to describe these states in semantic terms without presupposing the existence of the social practices that give rise to intentional interpretation. And finally, questions about reference relations and truth conditions are really questions about certain norms that guide intentional interpretation. So, with all of the details of the theory now on the table, I turn to evaluating it with respect to the criteria introduced in Chapter 1. 

\section{Evaluating the Theory}

The criteria introduced in Chapter 1, recall, concern five features that I argued a good theory of semantics ought to possess. First, such a theory must be predictively adequate, in that it successfully accounts for observable linguistic phenomena. Second, such a theory must be cognitively plausible, in that it is consistent with available evidence concerning the properties of the cognitive systems that give rise to linguistic phenomena. Third, such a theory must account for the compositionality of language, or the fact that people are able to understand an indefinitely large number of linguistic expressions. Fourth, the theory must account for the fact that linguistic expressions are about things in the non-linguistic world. Fifth, the theory must account for the fact that uses of language are subject to normative assessment, in the sense that words and sentences can be used both properly and improperly.

\subsubsection{Predictive Adequacy}

The meaning of a linguistic expression, on my view, is captured by the inferences it appropriately gets caught up in. The utterance of a sentence during a conversation, for instance, warrants the attribution of certain intentional states to the participants in the conversation, which in turn warrant certain predictions about what the targets of these attributions will go on to say and do. The whole point of the model described in Chapter 3 is to begin to formalize these predictions by inducing the inferential roles of various sentences from real-world linguistic data. To take a concrete example, the model predicts that anyone who utters the sentence ``A boy and a girl are waiting in a store'' will also be willing to utter the sentence ``Two kids are indoors.'' Given the experimental results discussed in Chapter 3, it is clear that these predictions are reasonably accurate, and that the model thereby accounts for a small but genuine set of regularities in language use. 

In Chapter 1, I introduced the predictive adequacy criterion with the observation that a competent speaker of English would be able to infer from the sentence ``The boy waited for the pitch and then hit the ball over the fence'' that the boy is likely playing baseball, that he has likely used a bat to hit the ball, and that the phrase ``over the fence'' describes where the ball went after he hit it, rather than the location of the ball when he hit it. It is now clear that my model codifies exactly these sorts of inferences. For instance, the act of concluding that two kids are indoors from the fact that they are in a store is no different in kind from the act of concluding that a boy likely used a bat from the fact that he hit a ball. In both cases, the inference in question is a commonsense, material inference of the sort required for linguistic comprehension. I therefore conclude that my theory does a good job of satisfying the predictive adequacy criterion. 

\subsubsection{Cognitive Plausibility}

There is a significant amount of empirical evidence to support the claim that linguistic cognition is fundamentally predictive and usage-based. This evidence can grouped into three general categories. First, in the domain of language acquisition, it is fairly clear that children learn the meanings of words by learning about the role that they play in simple, convention-governed interactions \citep{Tomasello:2005,Tomasello:2001}. Learning how to use words in the context of such interactions importantly involves learning to form appropriate expectations about how the interactions tend to unfold. Second, in the domain of language processing, there is plenty of evidence indicating that the brain anticipates upcoming linguistic events so as to better cope with a deluge of input and appropriately control behavior in response to this input \citep{Christiansen:2015,Pickering:2007,Pickering:2013}. Third, in the domain of cognition more generally, there is a growing consensus that the brain is fundamentally in the business of making predictions \citep{clark:2013}. If so, then linguistic cognition should be similarly structured around prediction at every level of analysis, from phonology to pragmatics. 

One striking feature of the available psycholinguistic evidence is that it does \textit{not} support a view on which language is a vehicle for transporting ``states of mind'' from one person to another. The problem with this commonsense view is that it suggests that the cognitive processes underlying linguistic comprehension simply map a sequence of words onto a representation of some kind, and that the occurrence of this representation somehow constitutes an understanding of the corresponding sequence of words. But the mere occurrence of a representation in a cognitive system does little to explain the phenomena that go along with linguistic comprehension. Moreover, the available evidence suggests that the processes underlying linguistic comprehension generate appropriate predictions and actions in a more or less continuous manner. Comprehension is accordingly a process that involves drawing inferences rather than a state that is the result of extracting a ``meaning'' from a linguistic expression.

Overall, it is fairly clear that my theory is consistent with the available psycholinguistic evidence. The model in Chapter 3, for instance, incorporates hierarchical compression and decompression procedures of the sort described by Christiansen and Chater (\citeyear{Christiansen:2015}). The model also produces rudimentary discourse-level predictions of the sort described by Rohde (\citeyear{Rohde:2008}). And perhaps most importantly, the model performs exactly the kind of statistical inference that is thought to be a core feature of cognition \citep{Eliasmith:2007,clark:2013}. I accordingly conclude that my inferentialist approach to semantics is cognitively plausible.  

\subsubsection{Compositionality}

A common criticism of inferential role semantics is that it is inherently non-compositional \citep{FodorLepore:1991}. However, when questions about semantic composition are recast as questions about inferential generalization, this criticism largely evaporates. If a theory provides an account of how language users are able to derive appropriate predictions concerning the use of arbitrary linguistic expressions, then the theory satisfies the explanatory burden that motivates positing the principle of compositionality in the first place. The model in Chapter 3, moreover, clearly does generalize to make appropriate predictions concerning the use of arbitrary linguistic expressions. For example, the model derives plausible predictions for a wide range of substitutional variants of the sentence ``A boy in a beige shirt is sleeping in a car,'' even though none of these variants are present in the model's training data. 

The model generalizes by ``interpolating'' between known inferential transitions on the basis of certain similarities amongst its inputs and the computational procedures used to map them to their outputs. For instance, the model learns to group words and phrases with similar meanings into approximate equivalence classes with respect to their impact on the inferential roles of the sentences in which they occur. The model also learns to treat words and phrases similarly if they play a similar computational role in the encoding-decoding procedure. Thus, words and phrases that occur in similar syntactic contexts will also be grouped into approximate equivalence classes with respect to their impact on the inferential roles of the sentences in which they occur. As the results in Chapter 3 demonstrate, this strategy of generalizing by interpolating amongst inferential contexts is fairly successful. The result, then, is an inferential role semantics that is compositional in the ways that matter. 

\subsubsection{Normativity}

Uses of language are governed by a variety of communal norms and conventions. On the story I have told, these norms and conventions arise from a process in which interpersonal interactions fall into stable patterns that sustain a reasonable degree of mutual prediction \citep{clark:2013}. Or in other words, communities adopt norms ``of use and response'' because doing so allows for complex behavioral co-ordinations that are both valuable and otherwise impossible to carry out \citep[][p. 50]{Millikan:2005}. The force of these linguistic norms, in turn, derives from the fact that behavioral co-ordination breaks down when they are violated. For instance, if someone uses the sentence ``A boy and girl are waiting in a store'' with the intention of informing someone else that the lawn needs to be mowed, both parties are likely to end up confused and unable to go about their business.

This approach is a relatively uncontroversial in the context of research on the nature of conventions \citep{Millikan:2005,Lewis:1975}, and I accordingly do not devote much space to developing it. The view does, however, bear on the question of whether meaning is intrinsically normative. I have argued that meaningful language use is a norm-governed phenomenon, and that norm-governed phenomena are pattern-governed phenomena for which their are standards against which the patterns in question can be assessed. In the context of language use, the standards are the standards of rationality that determine what a language user \textit{ought} to infer on the basis of a linguistic act performed by someone else. The advantage of this view is that it explains the norm-governed nature of language use in an appropriately naturalistic manner. The only non-naturalistic notion invoked is the notion that it is good or rational for people to abide by the norms set down by the behaviors of their linguistic community. And the reason that this is good or rational is because it enables one to act successfully. I accordingly conclude that my approach accounts for the fact that linguistic expressions can be used either correctly or incorrectly in a naturalistically respectable manner. 

\subsubsection{Intentionality}

My view characterizes the intentional objects of linguistic expressions in inferential terms. The basic idea is that the norms governing language use are such that the inferences licensed by particular linguistic acts support a broad range of successful predictions and actions. The notion that a word refers to or is \textit{about} something else, then, is just a way of saying that the inferences licensed by the use of this particular word (paradigmatically in demonstrative constructions) sustain a broad range of successful predictions and actions that are organized into a stable category. For instance, the notion that the word ``rock'' refers to rocks captures the idea that this word plays a role in a bundle of inferences that are practically infallible: if something is a rock, then it is hard and likely heavy; if you smash one rock into another, they will make a distinctive sound; and so forth. While this view is somewhat counterintuitive, it has the advantage of generalizing to cover \textit{all} types of linguistic expressions, not just those that correspond to everyday perceivable objects. The upshot of thinking about things in this way is that it becomes possible to treat the concepts of truth and reference as concepts for endorsing certain uses of language with respect to the ideal of ongoing success in prediction and action. Referring terms are ``good'' in that they occupy an indispensable role within the inferential framework defined by a particular language. True claims are similarly good in that they promote successful predictions and actions; they perfectly fulfill the aims of descriptive language use. 

The principle benefit of this approach to dealing with the intentionality of language is that it avoids the internal confusions found in theories based on more robust notions of the reference relation and the truth property. For one thing, these theories have difficulty accounting for linguistic expressions that do not refer or correspond to the world in a clear-cut manner. For another, they also problematically imply that one can grasp the fundamental structure of reality by grasping the meanings of linguistic expressions. Inferential role semantics, overall, is a view that is consistent with the idea that a language is a fallible and continually evolving tool for describing the world. Language using organisms do not have direct and pure access to their environment. Rather, they \textit{infer} the state of this environment by reasoning about the deliverances of their perceptual faculties. Linguistic expressions are accordingly about the non-linguistic world in virtue of the inferential roles they occupy. 

\subsubsection{Summary}

The upshot of this evaluation is that a very plausible theory of meaning can be constructed by taking \textit{inference} to be at the core of semantics. The advantages are fivefold. First, attributing inferential roles to linguistic expressions allows for successful predictions of linguistic behavior. Second, the idea that linguistic cognition is fundamentally inferential in nature is consistent with available psycholinguistic evidence. Brains, in short, are inference machines. Third, it is possible to account for the evident generality of human linguistic abilities by positing methods for interpolating between the inferential roles of known linguistic expressions. Forth, the inferential role of a linguistic expression clearly sets down how one \textit{ought} to use it, and therefore accounts for the sense in which uses of language are subject to normative assessment. And fifth, an inferential role semantics accommodates the idea that the norms that define the meanings of linguistic expressions are continually changing so as to foster an ever broader range of successful predictions and actions. Language is not a window onto reality, and an inferentialist approach to meaning does a good job of accommodating this fact. So overall, while the theory is undoubtedly incomplete and much work needs to be done to develop it in more detail, I conclude that the case in favor of an inferential role semantics for natural language is much stronger than is often supposed. 

\section{Conclusion}

I have largely concluded my case, but it is worth reflecting on whether there are questions that one might want to ask about the meaning of a linguistic expression that cannot, in principle, be answered by a theory of the sort I am offering. Arguably, there is little that is left out of the picture of language use that emerges from the IPA framework. To explain, suppose that one had a near-perfect model of how linguistic expressions regulate intentional interpretation, or a model that can be used to derive successful predictions concerning the moment-to-moment transitions in a conversation between two individuals. If this model is comprehensible, then I contend that it would capture everything one could want to know about what linguistic expressions mean. Moreover, one would be able to explain various facts about the use of certain linguistic expressions through appeal to the properties of the model. So, if meanings are supposed to do the job of explaining language use, then the hypothetical model under consideration would go a long way towards finishing the job.

In summary, there are two main contributions offered in this thesis. The first, theoretical contribution is a re-evaluation of some of the core concepts used in research on semantics. Specifically, I develop a novel account on which a linguistic expression's meaning is a characterization of the predictions it licenses within the context of intentional interpretation. The second, technical contribution is a demonstration of how these theoretical insights can be applied to build a model that formalizes the inferential roles of arbitrary linguistic expressions. Such models can be used to operationalize linguistic comprehension and thereby demonstrate the empirical adequacy of an inferentialist approach to semantics. Furthermore, such models can provide answers to questions about the meanings of specific linguistic expressions. And if one could go on to design and understand a version of this model that engages in intentional interpretation in the same way that people do, it is not clear what more one could wish to know in order to achieve greater insight into nature of meaning.