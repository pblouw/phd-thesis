%----------------------------------------------------------------------
% MAIN BODY
%----------------------------------------------------------------------
\externaldocument{chapter3}
%======================================================================
\chapter{Representing in Virtue of Reasoning}
%======================================================================
\renewcommand{\epigraphrule}{0pt}
\setlength{\epigraphwidth}{4.5in}
\epigraph{\textit{We are seekers and speakers of truths because we are makers and takers of reasons.}}{- Robert Brandom, 2009}

\epigraph{\textit{When all is said and done, should we not join the pragmatist in saying that in any nontrivial sense of this term, the ``meaning'' of a term lies in its role as an instrument in the organism's transactions with its environment?}}{- Wilfrid Sellars, 1953}

\section{Introduction}

One risk of adopting an inferentialist approach to semantics is that important relationships between linguistic expressions and the non-linguistic world are left unaccounted for. This risk is particularly evident given that the models of inferential roles described in previous chapters do almost nothing to relate linguistic expressions to what they are \textit{about}. For instance, a word like ``bicycle'' is characterized in terms of the effect it has on the inferential roles of bicycle-mentioning sentences, but these roles do not yet specify how the word ``bicycle'' relates to bicycles. It accordingly seems as though the inferentialist model will have difficulties satisfying the intentionality criterion discussed in Chapter 1.

The challenge of satisfying this criterion can also be characterized in terms of the traditional semantic notions of truth and reference. Reference relations are what connect words to the world and thereby determine what words are about. Truth, furthermore, is a property of sentences that are built out of words that connect to the world in the right sort of way. Many philosophers have accordingly treated truth and reference as the explanatory primitives of semantic theory, wherein facts about what a word or sentence \textit{means} are accounted for in terms of facts about the word's referent or the sentence's truth-conditions. Building a theory of meaning out of reference relations and truth-conditions is therefore highly conducive to the goal of explaining the ways in which linguistic expressions connect to the non-linguistic world.  

Taking inference to be the basic building block of a semantic theory, however, in no way makes this goal unattainable. My purpose here is to provide a characterization of the representational properties of linguistic expressions in terms of their inferential roles. The basic ideas are familiar from the work of Sellars (\citeyear{Sellars:1953}) and Brandom (\citeyear{Brandom:2000,Brandom:1994}). An expression's meaning is constituted by its place in a network of inferences, some of which connect it to non-linguistic perceptions and actions. For example, the perception of a marble countertop can make it appropriate to say things like ``The countertop is marble, not tile,'' which can in turn can make it appropriate to say things like ``It's probably very heavy.'' Likewise, saying something like ``I'm going to the pharmacy now'' can make it appropriate to go to the pharmacy, which can in turn make it appropriate to say things like ``I'm no longer at home.''\footnote{People of course often see and do things without saying or even explicitly thinking anything, but the relevant fact is that they \textit{would} describe what they are seeing and doing in accordance with the sort of inferential transitions just described.} As such, the strategy is to make sense of representation relations in terms of inferential transitions between linguistic expressions and perceptual or behavioral responses to the surrounding environment. In the context of the model developed in Chapters 2 and 3, this strategy amounts to developing the idea that linguistic expressions are not just predictors of other linguistic expressions, but also predictors of certain non-linguistic experiences. It is accordingly possible to define models that generate ``entailments'' between perceptual inputs and natural language expressions, and between natural language expressions and behavioral outputs, as discussed in Chapter 3. 

An obvious challenge for this account is to provide objective standards of representational correctness. To deal with this challenge, I largely appeal to the norm-governed nature of language use. When a linguistic expression is used to make a claim, the propriety of the claim depends in large part on whether or not the inferential consequences of the claim are borne out. For example, if I claim that an animal is a horse based on its appearance, but you notice that it has antlers, then something that directly follows from my initial claim has failed to come about. You can then correct the claim or question its appropriateness. One lesson to draw from this sort of example is that existence public norms concerning the use of particular words (e.g. ``horse'') ensures that what follows from claims invoking these words (e.g. ``That animal is a horse'') is not just a matter of personal inclination. A further lesson to draw is that if the inferential consequences of a claim can be specified inter-subjectively, then it becomes possible to frame questions concerning what claims are about in terms of these consequences. In short, once a complete account has been given of what a particular expression follows from and is followed by, there is simply nothing more to say about what the expression is \textit{about}. Intentional content is exhausted by inferential consequence. 

Careful work is required to spell out the details of this view, but the motivation for it is quite straightforward. As inquirers, we have no direct or unmediated access to reality \citep{Misak:2013}. Our claims about the world and the objects that populate it are always open to revision in light of countervailing evidence. As such, it is dubious to invoke brute relations between linguistic expressions and the non-linguistic world as a presupposition of semantic theory. A smarter strategy involves starting with the notion that linguistic expressions stand in normative relations to both one another and certain non-linguistic perceptions and actions. In one sense, these normative relations are simply the product of communal interaction. What \textit{makes} it the case that the presence of a four-legged creature ought to follow from an utterance of  ``There's a horse!'' is that people just \textit{take} it to be the case. Collectively, we institute the norms that set down what ought to go along with uses of particular words and sentences. But this is not to say that the inferential roles we attach to linguistic expressions are the product of communal whim. We also care about getting things right \citep{Misak:2013}. So when we learn something new about horses, for instance, the socially-instituted norms concerning horse-talk shift accordingly. Overall, since we only ``get at'' the world by reasoning about our experiences and the relations they bear to one another, it follows that the norms governing such reasoning should be taken as foundational in the development of semantic theory. I take these norms, finally, to be grounded in our interest in making accurate predictions concerning what goes on around us. 

The rest of the chapter works out the details of this view in three stages. First, I outline a number of problems associated with relying on antecedently specified theories of truth and reference to construct a semantic theory. Second, I provide arguments that demonstrate how the intentional objects of linguistic expressions can be derived from the norms that specify which inferential relations these expressions get caught up in. The purpose of these arguments is to illustrate how an inferential role semantics can accommodate the intentionality criterion. Finally, I discuss the nature of the norms that give rise to the intentionality of linguistic expressions, and argue that they are grounded by the fact they yield accurate predictions concerning worldly phenomena. 

\section{Challenges for Theories of Truth and Reference}

When discussing traditional semantic concepts like truth and reference, it is important to separate these concepts from everyday talk about which claims are true and which things a word refers to. For one thing, it is quite plausible that truth-and-reference talk is governed by a wide range of pragmatic norms, as is indicated by expressions like ``True enough!'',``Truly, I support you'', and ``How true!'' So the fact that people \textit{use} words like ``true'' and ``refers'' in a variety of ways has relatively little bearing on the question of whether truth properties and reference relations provide an appropriate foundation for semantic theory. Additionally, it is quite clear that the metaphysical baggage philosophers associate with such properties and relations are far removed from the considerations of competent language users. For instance, if I claim that the word ``mice'' refers to mice, I would not thereby be taken to claim or even imply that there are laws, causes, or functions that connect this word to all the mice in the world.\footnote{Note too that words like ``mice'' are the easy cases. Compare ``Tuesday'' and Fodor's (\citeyear{Fodor:1998}) odd claim that representations of Tuesdays \textit{refer} to Tuesdays by somehow ``resonating'' to the property of Tuesday-hood (p. 75).} Overall, it is important not to get initially distracted by the ordinary idea that claims can be true or false, or the similar idea that words refer to things. No one denies this. The debate is about characterizing what being true or referring to something actually amounts to.

A typical proposal involves treating truth as special kind of property that a sentence or proposition acquires when it ``corresponds with the facts'' (citations). Correspondence is then analyzed in terms of relations of reference, denotation, and satisfaction involving the sentence's constituents. For instance, a simple subject-predicate construction (e.g. ``Bruce is smiling'') will become true if and only if the entity referred to or denoted by the subject is \textit{satisfied} by the predicate, or contained within the set of items it denotes. Interestingly, work in formal (i.e. truth-conditional) semantics often proceeds by simply stipulating or assuming certain denotation relations in the definition of a model \citep{Carpenter:1997}, and relatively little attention has been paid to the question of \textit{how} these relations obtain \citep{Stanley:2008}. Theories that aim to naturalize representation in terms of causal or functional relations might be seen as tackling this question, but efforts to extend these theories to cover a wide range of linguistic expression have been markedly unsuccessful \citep[c.f.][]{Millikan:2005}. Regardless, the point here is that if one accepts the intuitive idea that language connects to reality, one acquires a commitment to explain the exact nature of the connections in question.

There are several reasons why this intuitive approach leads to problems. First, semantics becomes a domain in which one poorly understood and theoretically loaded concept (i.e. meaning) gets explained in terms of two other poorly understood and theoretically loaded concepts (i.e. truth and reference). To explain, if reference is taken to be a genuine metaphysical relation, then one is stuck with all sorts of thorny questions concerning how this relation holds between, say, the word ``fictitious'' and things that are fictitious. Naturalization strategies of the sort discussed in the previous chapter have yet to offer any clear answers on this front, and alternative strategies are hard to come by. Similarly, if truth is taken to be a genuine metaphysical property of sentences (or propositions, if that is preferable), then one is stuck with equally thorny questions concerning how this property attaches to sentences like ``He is bald''. Such questions have given rise to a vast literature on vagueness, with few clear results. Overall, the strategy of building a theory of meaning out of theories of truth and reference would be reasonable if these latter theories were independently well-developed and thereby positioned to do some amount of explanatory work. Unfortunately, they aren't. 

A second, related problem is that there are few clear standards for what good theories of truth and reference ought to accomplish. Even if one grants that truth is a genuine property or that reference is genuine relation, it is not obvious how these properties and relations become evident to us, since there are no natural phenomena that issue from their presence in the world. A comparison to more familiar relations and properties is illustrative. The relation of distance, for example, is well-defined in terms of various units (cm, km, etc.) and can be used help explain such things as how long it takes to drive from Waterloo to Toronto. Likewise, the property of temperature is well-defined in terms of units of Celsius and can be used to help explain such things as the transition of water from a liquid to a solid state. The important point is that theories concerning the nature of temperature and distance are good in virtue of their ability to account for phenomena that are products of temperatures and distances (e.g. melting points, driving times, etc.). By analogy, theories concerning the nature of truth and reference should qualify as good insofar as they can account for the phenomena that result from truth properties and reference relations. But it is not clear that there \textit{are} such phenomena.\footnote{There are, of course, phenomena concerning the role that words like ``true'' and ``refers'' play in our linguistic practices, but such phenomena are plainly sociological in nature.}

Why, then, have truth conditions and reference relations played such an out-sized role in the philosophy of language? One plausible hypothesis is that certain philosophical intuitions concerning the relationship between language and reality are naturally quite compelling. It just \textit{seems} that claims are made true by reality, that words correspond to parts of reality, and that reality consists of ``states of affairs'' or facts. But if theories of truth and reference are ultimately judged by the degree to which they accommodate intuitions concerning the relationship between language and the world, then it is hard to justify putting much explanatory weight on them. Intuitions are fickle, and satisfying them achieves no special theoretical goal. Moreover, an intuitive characterization of truth and reference in terms of facts and correspondences requires that these latter concepts also be given proper (intuitive?) characterizations. And so on with concepts appearing in the further characterizations. Overall, such reliance on intuitions is not methodologically promising.

A third problem is that assigning truth-conditions to sentences and referents to words does very little to explain the \textit{use} of these words and sentences, and therefore does very little in the way of semantic work \citep{Brandom:1994,Block:1986}. So even if the previous two problems were somehow resolved, it still wouldn't be the case that semantics would settle onto a firm truth-theoretic foundation. To see why, notice that it is possible to know what a word refers to without being able to use it effectively for communicative purposes. One can, for instance, know that ``tree'' refers to trees, without knowing anything about the circumstances under which they would be appropriately mentioned \citep{Block:1986}. It is also possible to identify whether a claim is true (e.g. by checking it against a list of facts or by consulting an ``oracle'') while having no idea what it means \citep{Block:1986}. So it is not the case that reference relations and truth-conditions explain linguistic phenomena, and therefore not the case that they can provide explanations of the sort required of a good semantic theory. 

One might argue that a grasp of truth-conditions and reference relations is necessary but not sufficient to engage in meaningful linguistic behavior, in which case they will still play an important role in semantic theory. The difficulty with this response is that it fails to account for the possibility that public norms of use for the words ``true'' and ``refers'' are what give rise to the idea that there are truth-conditions and reference relations in the first place. If there are norms governing the use of these words, then it follows that are conditions under which it is appropriate to say ``\textit{X} is true'' or ``\textit{Y} refers to \textit{Z}''. Since such norms clearly fall out of communicative practices and methods of inquiry,\footnote{For example, we care about the coherence and predictive adequacy of our claims, and the norms governing our uses of the word ``true'' reflect this, since we tend say that predictively inadequate claims are not true.}, we should start by trying to understand these methods and practices, not by trying to understand truth and reference.

Overall, the point of this discussion is not to advocate any sort of radical relativism or to deny that some claims are true while others are false. The point, rather, is to reject the idea that it is sensible to make an initial appeal to theories of truth and reference to do explanatory work regarding the nature of meaning. Insofar as such theories are substantive, they are products of the sort of metaphysical speculation that is rightly avoided by naturalistic approaches to philosophy. This conclusion is familiar from the literature on pragmatism and deflationism \citep[see, e.g.][]{Brandom:2000,Brandom:2009,Brandom:1994,Misak:2013,Misak:2007,Horwich:2005},\footnote{To explain, deflationism builds on the observation that there is no significant difference between saying ``\textit{X} is true'' and just saying ``\textit{X}'' to argue that the concept of truth is essentially just a tool for conveniently expressing certain generalizations \citep{Horwich:2005}. For instance, one can say ``Everything Peter said is true'' instead of something like ``If Peter said `semantics is important', then semantics is important, and if Peter said `inference is at the core of semantics', then inference is at the core of semantics, and ...'' \citep{Horwich:2005}. Pragmatism is similar, but introduces the idea that the use of ``...is true'' signals a commitment to all of the consequences of a claim being borne out by future inquiry \citep{Misak:2007,Misak:2013}. True claims are those that hold up to scrutiny over the long run; they cannot be overturned indefinitely as inquiry progresses \citep{Peirce:1992}. However, the extent to which pragmatism and deflationism offer distinct theories of truth is actually not that clear \citep{Misak:2007}.} and my goal is to build upon it to develop an account of intentionality that is compatible with the inferential role semantics described in the rest of this thesis. The concepts of truth and reference, on this account, just fall out of the norms that govern our uses of language and our methods for learning about the world. In the case of truth, we care that our claims are predictive, coherent, fruitful, explanatory, and so forth. There is nothing more to a claim being true than it being able to satisfy these norms indefinitely. In the case of reference, we care that our words help set down which experiential consequences are expected to follow from a given claim. There is nothing more to a word referring than it being able to account for what the experiential consequences of diverse claims involving the same word all have in common. 

\section{Language Use and Normative Statuses}

The view I am proposing is that the traditional semantic notions of truth and reference are better thought of in terms of norms governing our linguistic practices than in terms of metaphysical relations between mind and world. As such, the plausibility of the view rests in large part on whether a satisfactory account of these norms can be given. My strategy is to provide an account in three parts: linguistic norms are (a) inferential in nature, (b) socially instituted, and (c) ``answerable'' to the non-linguistic world \citep{Brandom:1994}. By elaborating on these features of linguistic norms, I hope to illustrate how the question of what a linguistic expression refers to or is true of can be fruitfully re-framed as a question about the norms governing its use. 
 
The inferential nature of linguistic norms, to start with, can be made apparent by observing that uses of linguistic expressions do not occur in a vacuum; they are always preceded and followed by other events. The question of whether a particular linguistic expression has been used correctly, then, can be posed as a question about whether it has been used under the right preconditions. For instance, if I am told that Lisa got a sunburn on the beach, the preconditions have been set for me to appropriately say things like ``It must have been a clear day'' and to \textit{inappropriately} say things like ``It must have been cloudy'' or ``It must have been the middle of the night''. The normative status of my claim (i.e. whether it is made well or poorly) depends upon its relation to the preceding events concerning what I have been told or have observed about Lisa. If my claim is justified, warranted, evidentially supported or otherwise licensed by these events, then the claim has a positive normative status. Otherwise, it does not. \textit{Reasons}, not connections between language and the world, are what determine whether a claim has a particular normative status. 

What makes one thing count as a reason in favor of another? Simply put, the existence of a predictive relationship between the two things. The fact that Lisa got a sunburn on the beach, for instance, is predictive of clear skies and daylight, since one would not expect to see evidence of a sunburn (e.g. peeling skin) without also seeing evidence of sunshine (e.g. a visible sun). In general, the norms governing linguistic practice favor uses of language that are warranted by a ``predictive license'' of sorts: what \textit{makes} an utterance appropriate is a kind of consistency between the circumstances that prompt it and the consequences that are taken to follow from it.\footnote{The notion that linguistic expressions have appropriate circumstances and consequences of application originates with Michael Dummett \citep{Brandom:1994}} For example, if the sight of Lisa's sunburn provides the circumstances under which I am prompted to say ``It must have been a clear day'', then the propriety of my utterance depends on whether or not what follows from my utterance is to be expected given these circumstances. Since it follows from my utterance that there was sunshine, and since sunshine can be predicted from the presence of a sunburn, the circumstances that prompt my utterance are consistent with its corresponding consequences.

At this point, it is possible to describe the ways in which linguistic norms are socially instituted. Consider again the idea that the use of a particular linguistic expression has certain consequences. Clearly, these consequences are not such that saying something makes the world change so as to fit with what was said. Rather, the consequences of saying something are to produce certain expectations in the surrounding audience. Hearing ``It must have been a clear day'', for instance, introduces the expectation that one's subsequent experiences will be consistent with the skies having been clear (it goes without saying that the force of such an expectation depends on the credibility assigned to the speaker). The important point is that these expectations are social conventions. The visibility of clear skies only became an expected consequence of talk of a ``clear day'' once the community tacitly agreed that this should be so. People started using and responding to utterances of ``It's a clear day'' in a particular way, and it is only in virtue of these patterns of use and response that the expression ``clear day'' is governed by particular linguistic norms. The question of how such conventions come into existence and stabilize is the subject of a considerable amount of research \citep{Millikan:2005}. What is important for my purposes is the fact that linguistic conventions are what Millikan (\citeyear{Millikan:2005}, Ch. 1) and Lewis (\citeyear{Lewis:1969}, Ch. 1) call ``co-ordinating conventions,'' or conventions that involve interactions amongst multiple people. As such, it straightforwardly follows that linguistic norms are socially instituted: they are norms that emerge from interactions, not individual behaviors.

The fact that linguistic norms are socially instituted does not entail that they somehow detached from the non-linguistic world or lacking in objectivity. These norms serve the purpose of helping us to co-ordinate our activities with one another and to effectively engage with our surroundings. Not all norms can satisfy this requirement. For instance, a norm on which it is appropriate to infer ``there is a beetle here'' from ``the gust of wind is blowing from the east'' would be utterly without value in efforts to act effectively. Any community that abides by this norm would not (in virtue of the norm at least) be able to deal with beetles and wind gusts successfully; their expectations would simply fail to hold up. Moreover, it would be incorrect to think of this community as bestowing meanings on their utterances that are anything like those familiar to us. The behavior sustained by the norm in question essentially involves an arbitrary pairing of sounds: nothing follows from an utterance of ``the gust of wind is blowing from the east'' except that an utterance of ``there is a beetle here'' ought to then occur. Any linguistic community that entirely abides by such norms would likely not be recognizable as a \textit{linguistic} community, since the patterns to be found in their interactions with one another would be completely random. 

A plausible explanation for why our linguistic norms are \textit{not} random is that they have to serve the purpose of helping us to engage with our surroundings. In other words, our linguistic norms are constrained by the world; they only survive insofar as they yield patterns of behavior that are successful and useful. For instance, the norms governing how we talk about beetles specify various inferences that can be drawn on the basis of something being a beetle (e.g. that it can fly, that it has six legs, etc.). If our experiences with beetles fail to line up with what is to be expected given the norms governing beetle-talk, then the norms themselves may get called into question. For instance, suppose you tell me that the insects in my basement are beetles, and I then infer that they are capable of flight. If I then fail to observe the insects fly after a systematic investigation, one of two conclusions might be drawn. First, you could be wrong, and the insects are not actually beetles. Second, it could be that some beetles do not actually fly. In the latter case, the norms governing our use of the word ``beetle'' are revealed to be subtly defective. The inference from something being a beetle to it  being capable of flight fails to be uniformly vindicated by experience. Such failures are disappointing and problematic from a practical perspective. Just imagine an entymologist trying to study a beetle population and continually being stymied by their puzzling behavior. To avoid such disappointments, we adjust our norms; we collectively learn to infer that something \textit{might} be able to fly if it is a beetle, with the happy consequence that we are less often surprised by what beetles do. It is plausible that this sort of norm-adjustment is what underlies various well-known conceptual changes that have been produced by scientific discoveries (e.g. that water is H2O, that diamonds are made of carbon, etc.)

In summary, I have argued that linguistic norms are constrained by the world, social in origin, and inferential in nature. I have not yet shown how to derive an account of the intentional properties of linguistic expressions from these norms. Providing this derivation requires building further on the idea that uses of language are subject to normative assessment. It is fairly uncontroversial to say that true claims are claims that have a particular normative status, or are ``good'' in a special sort of way. Likewise, words that refer are words that are \textit{true of} certain things. So, to say that a word refers is to say that certain uses of it can acquire the normative status characteristic of a true claim. My approach is to characterize these normative statuses in purely inferential terms. I consider a number of objections along the way. 
 
\subsection{Truth as a Direct Normative Status}

An utterance of a declarative sentence is typically presumed to have a certain propriety. Such propriety, in turn, derives from the utterance's ability to license successful predictions and actions on the part of those who hear it. For instance, if someone says, ``The bus leaves from the university at 4pm'', then the propriety of this utterance hinges on whether its consequences are borne out by experience. The utterance is good (in the sense under consideration) insofar as it would lead to successful predictions and actions on the part of others. Or put another way, if the utterance were well-made, then one would find evidence of a bus arriving on campus at 4pm, and one would be able to make successful plans that involve this bus. Good utterances do not disappoint - they can be relied upon in practical matters \citep{Misak:2007}. 

A more conventional way of putting things is to say that good utterances are \textit{true}, since true utterances can similarly be relied upon in practical matters. The reason I avoid this formulation is because it implies that the notion of an utterance being true can be made sense of independently of its ability to license successful predictions and actions. Truth, on the conventional view, becomes an example of what Brandom (\citeyear{Brandom:1994}) calls an ``unexplained explainer'' (p. 7), or a property that just brutely accounts for certain phenomena. So instead of deriving the practical adequacy of an utterance from its truth, I propose to adopt the converse order of explanation and derive the truth of an utterance from its practical adequacy. The advantage here is that the question of whether an utterance has the normative status characteristic of truth can be informatively answered. For instance, one can explain why an utterance of ``The bus leaves from the university at 4pm'' has a particular normative status by invoking evidence: the departure time is noted in the bus schedule, the driver closed the doors at 3:59, and so on. No comparable explanation is achieved by simply invoking the truth of ``The bus leaves from the university at 4pm''. So insofar as we wish to account for the role of truth-talk in linguistic practices, we should treat ``is true'' as a marker of normative status that is constituted by inferential relations.

As described, there is an obvious problems with the idea that truth is an inferentially defined normative status. Put simply, there is difference between the normative status of a claim that is merely justifiable and a claim that is actually true. For instance, I might have overwhelming evidence for thinking that the bus leaves at 4pm, yet I could nonetheless be wrong. Things could be different from what I have reason to believe. So there is a sense in which normative statuses that are instituted by evidential relations come apart from normative statuses that are determined by the way the world is. In conventional philosophical terms, the problem is that my view misses the distinction between assertibility conditions and truth conditions.

The way to avoid this problem is by adopting a less individualist picture of the inferential relations that determine a claim's normative status. There is no reason to restrict the reasons relevant to determining a claim's status to those available to any particular person or group. Rather, it is possible to identify a continuous scale of linguistic propriety that allows for reasons that transcend those available to any community or individual. Random guesses, for example, land at the bottom of the scale. Subjectively well-supported claims land a bit farther up. Claims that are well-supported by evidence from a broad range of perspectives land further still. True claims, finally, are at the top. No matter how long any person or group were to inquire into the consequences of the claim, its status would never diminish. A true claim, as Misak (\citeyear{Misak:2013}) puts it, is ``indefeasible'',\footnote{The view that true claims are indefeasible originates with Charles Sanders Peirce - see, for example, ``How to make our ideas clear'' \citep{Peirce:1992}. However, neither Peirce nor Misak, to my knowledge, develops the notion of truth-as-indefeasibility within the context of inferential role semantics of the sort I have proposed.} and since indefeasibility is clearly an inferential concept, it follows that true claims are true in virtue of their inferential status.\footnote{One could, of course, appeal to world to explain why a claim is true. But such appeals yield rather circular explanations like ``It is true that diamonds are hard because diamonds are hard'' or, more generally, ``\textit{X} is true because \textit{X}.'' Deflationists such as Horwich (\citeyear{Horwich:2005}) have long pointed to these kinds of observations to argue against the notion that ``..is true'' is a predicate corresponding a genuine metaphysical property.}

\subsection{Reference as an Indirect Normative Status}

In order to assess the normative status of a claim, one must know what its expected consequences are. These consequences, in turn, are determined by the inferential role of the sentence used to make the claim. The inferential role of a sentence is determined by the words it contains and the way in which they are combined, as discussed in Chapter 4. Given as much, the words in a sentence determine what follows from it, and hence determine the conditions under which its utterance takes on a particular normative status. Words that \textit{refer}, in turn, are words that paradigmatically take on such statuses when used in tandem with demonstrative pronouns, as in examples like ``\textit{This} is an airport'' and ``\textit{That} is a beetle''. 

The question of what a word refers to can accordingly be framed as a question about the considerations relevant to assessing the normative status of its use in demonstrative constructions. The meaning of the word ``beetle,'' for instance, is what sets down the kinds of evidence that are relevant to determining whether a claim of ``This is a beetle'' has been well made. Beetles have numerous properties that have been documented by biologists and these properties can be used to inspire the kinds of questions that are relevant to assessing a claim of ``This is a beetle'': Does it have six legs? Does it have a rigid exoskeleton? Does its life cycle include a larval stage? And so on. In general, once such questions are exhausted --- once we have specified everything that follows from something being a beetle --- there is nothing more to say concerning what the word ``beetle'' is about. Everything is in place to determine what one can expect to observe and experience upon being told that something is a beetle. Moreover, everything that is relevant to explaining linguistic phenomena involving beetle-talk is on the table. Adding something further to the story in the form of the genuine referent of ``beetle'' or the true essence of beetlehood is superfluous and theoretically unmotivated. Whatever is genuinely ``referred to'' on such a story never makes its way into awareness, never makes a difference to our practices, and never lends any explanatory insight into observable phenomena. 

One advantage of thinking about reference in this way is that a number of familiar philosophical problems simply disappear. Consider, for instance, the challenge of characterizing the meanings of words with non-existent referents (e.g. ``centaur'', ``wizard'', etc.). On the view I am proposing, such words simply help to determine the conditions under which sentences containing them can be uttered appropriately. There is no requirement that these conditions ever obtain outside of imaginary and fictional circumstances. In general, there is nothing mysterious about the existence of linguistic norms that assign inferential roles to sentences that make it difficult or impossible for claims involving these sentences to stand up to evidential scrutiny. A similar thought can be used to deal with the challenge of characterizing the meanings of terms that have been eliminated from scientific theories (e.g. ``aether'', ``phlogiston'', etc.). The right thing to say about these words is that they were simply abandoned because the norms governing their use failed to sustain successful predictions and actions. There is nonetheless a clear sense in which sentences containing these words have determinate inferential roles and hence determinate meanings. Certain consequences follow from something being phlogiston. It's just that there is insufficient evidence of these consequences actually obtaining. As such, the fact that the word ``phlogiston'' has no genuine referent poses no special problem for characterizing its meaning. But there are still norms governing the use of ``phlogiston'', and these norms are what make it mean what it does.

Another advantage of my view is that helps to make sense of the ways in which word meanings change over time. A language is a body of norm-governed patterns of use and response that are continually adapting to accommodate the needs of the people the language belongs to. Some of these norm-governed patterns are highly stable. For instance, the norms governing the use of everyday words like ``briefcase'', ``pen'', and ``book'' are largely the same as they were one hundred years ago; what counts as an appropriate response to a question like ``Is that pen yours?'' is the same now as it was then. But the norms governing other words are much less stable. Consider social terms like ``modesty'', ``relationship'', and ``charisma''. The inferences that are appropriate to draw from claims like ``she has charisma'' and ``they are in a relationship'' are much different now then they were one hundred years ago.\footnote{Such differences can be analyzed empirically using the methods discussed in Chapter 2. The simplest strategy is to examine changes to the distributional profiles of words in text corpora collected from different periods of time.} Words corresponding to scientific concepts like ``chromosome'' are similarly plastic, in that the norms governing what one ought to infer from something being a chromosome have changed as our theories concerning these entities have grown more sophisticated. Making sense of these sorts of changes in word meaning is difficult if one maintains a more traditional view on which meaning is constituted by reference. On this more traditional view, if we do not know exactly what our words refer to (as in the case of certain scientific concepts), then we do not know what our words mean (since meaning is constituted by reference). Similarly, if we \textit{do} know what our words refer to (as in the case of social concepts), but these referents change over time, then we have to give some non-linguistic account of how they change. Clearly, neither of these outcomes is theoretically attractive.  

At this point, it is worth revisiting some of the evidence concerning language acquisition that was discussed in previous chapters \citep[e.g.][]{Miller:2006,Bloom:2001,Tomasello:2001,Tomasello:2005}. It would be misleading to say that when a child learns a new word, they are learning about a mapping between a sound or image and a chunk of reality. Rather, they learn how to engage in linguistically mediated joint actions with others. Consider the hypothetical example of a child learning the word ``drum'' while playing with a toy drum. What exactly is the child learning in this case? Depending on their level of prior linguistic competence, they may learn (a) that ``drum'' can be used in certain linguistic frames (e.g. ``Bring me \_\_'', ``Where is \_\_'', etc.) to direct the attention of others, (b) that the word can be used by others in these frames on the expectation that certain things get done (e.g. one brings the drum or says where it is), (c) that certain perceptual experiences ought to follow from utterances like ``There's a drum!' (e.g. one should see a round object that makes a certain noise when struck), and (d) that these experiences also make it appropriate to say ``There's a drum''. Even if one supposes that the child learns something further, there is nothing to suggest that this further thing is relevant to explaining or predicting the child's behavior. Everything the child says or does that involves drums can be accounted for in inferential terms. As such, the evidence suggests the children acquire language by learning how to use linguistic expressions, not by learning about reference relations.

The view I am advocating is admittedly somewhat counterintuitive. Commonsense suggests that is it appropriate to say things like ``This is a beetle'' if and only if the thing being demonstrated is a beetle. So why not invoke the thing being referred to when evaluating the normative status of an act of referring? The problem with this common-sense notion of reference is that it breaks down once it is adopted for theoretical rather than merely practical purposes. Practically speaking, it poses no problem to speak of beetles as the referents of ``beetle'', since we have a stable conception of beetles as entities, and this conception holds up under an enormous variety of circumstances and from an enormous variety of perspectives. Our conception of the world, in short, would have to be drastically revised in order for use to abandon the notion that word ``beetle'' usefully organizes a stable category of experiences, or that beetles are a kind of thing. The mistake reference theorists make is to overgeneralize from our practical certainty concerning the status of beetles as ``real things'' to the idea that \textit{all} words with referring uses similarly correspond to real things. Put simply, the idea that meaning is constituted by reference incorrectly implies that we are \textit{certain} about the nature of the world, and that nature of the world can simply be read off of our linguistic expressions. It would be astonishing if this were true, since one could give certain answers to questions about the fundamental nature of reality merely by appealing to the meanings of linguistic expressions. I take the absurdity of this conclusion to cast doubt on the idea that meaning can characterized in terms of reference. 

\section{Objectivity and Error}

So far, I've been trying to argue that the concepts of truth and reference ought to be understood in terms of norms governing inference, rather than in terms of brute correspondences between mind and world. Here, I extend this argument by illustrating how the fact that our descriptions of the world are prone to error actually \textit{mandates} an inferentialist approach to semantics. The basic idea is simple. On a referential approach to semantics, we either (a) fully grasp what our words mean and achieve certain knowledge of reality, or (b) fail to fully grasp what our words mean and achieve fallible conceptions of reality. Since we do not obtain certain knowledge of reality, (a) gets ruled out. Since we do not fail to grasp what our words mean (b) gets ruled out. Therefore, referential approaches to semantics are untenable, and by exhaustion of alternatives, some sort of inferentialist approach must win out. In short, inferential role semantics is only the view that is consistent with both the fact that language does not provide us with an infallible window onto reality, and the fact that we are not grossly ignorant of the meanings of our linguistic expressions. 

It helps to spell out this argument in a bit more detail. The problem being posed is that, on referential approaches to semantics, word and world are treated as conjoint entities, or as two sides of one coin. In order for a referring term to mean what it does, its referent must be a part of the world, since without a referent, there is no relation of reference. But if reality is (at least partly) constituted by the referents of words, then our grasp of the meanings of these words (i.e. what they refer to) would be tantamount to a grasp of reality. All room for error is eliminated. Yet we clearly do make errors. We cannot state with any certainty that our words latch on to the fundamental structure of reality. Some words, like ``phlogiston'' and ``aether'', get abandoned (and not because their referents suddenly disappeared). Other words, like ``obesity'' and ``alive'' have their referents change over time (and not because the nature of life and obesity changed). Overall, option (a) is non-starter given the overwhelming evidence of our fallibility when using language to describe the world.

What about option (b)? One could maintain that words actually do pick out fundamental features of reality, but we just happen not to know what these are. The strategy here is save reference by postulating widespread semantic ignorance.\footnote{Views in keeping with the sort of semantic externalism introduced by Putnam \citeyear{Putnam:1975} are a case in point.} There are two problems with adopting this strategy. First, if people are often collectively ignorant of the meanings of their linguistic expressions, then meanings do not do the job of explaining language use, since it becomes possible for there to be differences in meaning that make no difference to linguistic behavior. For example, if nobody knew about the difference between gold and fool's gold, then it would make no sense to say that ``gold'' has two distinct meanings, since by hypothesis there is no evidence of this distinction in the behavior of people who use the word. Second, postulating genuine reference relations alongside widespread semantic ignorance is tantamount to supposing that, by some miracle, every time a referring term is introduced into a language, it latches onto some genuine feature of reality, despite our ignorance of this fact. Moreover, if we always get things right when we introduce new words, it becomes hard to make sense how we make intellectual progress. It would be odd, for instance, to contend that we make progress by learning more about what we always meant to begin with. As such, option (b) is perhaps even less promising than option (a). Given that referential approaches to semantics make the fallibility of our theories and descriptions of the world a mystery, I contend that they ought to be abandoned. 

Unless there is some third option I have not considered, this leaves only the inferential approach as a viable alternative. And as I've argued, inferential role semantics has much to recommend it. The fallibility of our linguistic practices, for instance, can be accounted for by supposing that the inferential norms governing language use are continually being adjusted to enlarge the domains in which we are able to make successful predictions and perform successful actions. And despite the fact that these norms are products of human activity, they are not by that token subjective or relativistic. As inquirers, we are concerned with getting things right, and such concern is manifests itself in the norm that our descriptions of the world are indefinitely vindicated by future experience. This norm we call truth. Insofar as linguistic practice is continually evolving so as to better satisfy this norm, it is directed towards the production of objectivity and the elimination of error.

It is now possible to clearly see how the inferentialist is able to accommodate the intentionality criterion. The idea that linguistic expressions stand in representation relations, or are ``about'' things, is best characterized in terms of linguistic norms that lead to successful predictions and actions organized into stable categories. The notion that there are ``objects'' represented by particular words, for instance, is primarily just a way of saying that certain collections of experiences invariably go along with one another. Consider the example of a flowerpot. If you can see its front, you can invariably expect to see its back if you shift your perspective. If you pick it up and drop it, you can invariably expect it to fall down. If you flip it over, you can invariably expect the dirt in it to tumble out. If you hit it hard enough, you can invariably expect it to crack or break. And so forth. The unwavering stability and reliability of these patterns in experience is then explained by postulating the existence of an ``object'' that gives rise to them. Objects, then, are what give rise to the patterns in experience of which we are practically certain. They are ``real'' because the expectations we form on the basis of postulating their existence never fail us. But notice that the criteria that have just been invoked to explain what makes something real are \textit{inferential} criteria. Real objects are what can give rise to indefeasible inferences and predictions. Adding more to the story, as I've argued above, is both superfluous and theoretically misleading insofar as it results in the adoption of confused notions of truth and reference. 

It should be clear that outside of the familiar confines of our interactions with everyday objects, our experiences do not always coincide with one another in predictable ways; the world often fails to behave as we expect. It frustrates the achievement of our goals and fails to comply with our wishes. And it is only by contrast to such experiences of surprise, frustration, and disappointment that idea of ``getting things right'' even arises. Representations, then, are fundamentally the sorts of things arise in contrast to error. Errors, in turn, can only be identified by distinguishing between two perspectives \citep{Brandom:1994}: the one that gives rise to an expectation concerning future experience, and the one that gives rise to an experience that contradicts this expectation. These perspectives can be distinguished temporally, as when I see what looks like a fish and later conclude that it was actually an otter upon moving closer to it. Alternatively, the perspectives might be distinguished socially, as when I see what looks like a fish, but you notice that the ``fish'' is actually an otter, and go on to correct me. It is helpful to think of our linguistic practices (and scientific inquiry more generally) as being guided by the goal of self-correcting so as to minimize or eliminate the degree to which such distinctions in perspective lead to ``recalcitrant experiences'' \citep{Misak:2013}. Given such self-correction, the sort of inferential role semantics I am endorsing is immune to charges of subjectivity and relativism. 

\section{Grounding Linguistic Norms in Predictive Adequacy}

Many of my arguments have leaned heavily on the idea that language use is governed by socially instituted norms. I have not, however, given a particularly detailed account of the relationship between these norms and the social practices in which they originate. Absent such an account, my view is open to the objection that it invokes a mysterious realm of normative entities that has no place within a scientific world view. The objection is an important one, and cuts to the core of a longstanding debate concerning the relationship between meaning and normativity. Some scholars, such as Kripke (\citeyear{Kripke:1982}) and Brandom (\citeyear{Brandom:1994}), maintain that linguistic norms are fundamentally irreducible to non-normative facts about behavior. Other scholars, such as Horwich (\citeyear{Horwich:2005}) and Dennett (\citeyear{Dennett:2010,Dennett:1987}) reject this view. The issues here are complex given that the debate essentially concerns the relationship between ``ought'' and ``is'' - a mainstay of philosophical discussion for centuries. 

I opt in favor of a naturalistic position of the sort advocated by Dennet (\citeyear{Dennett:2010,Dennett:1991,Dennett:1987}).\footnote{Though, to be fair, I think the disagreement at the core of the debate is a bit exaggerated. Dennett (\citeyear{Dennett:2010,Dennett:1987}), for instance, is quick to agree that intentionality is a fundamentally normative phenomenon. Brandom (\citeyear{Brandom:1994,Brandom:2010}), in turn, is quick to agree that the social behaviors that engender linguistic norms are fully describable in naturalistic terms. It's plausible that the appearance of major disagreement is an artifact of the difficulty of giving a plausible account of the relationship between the normative and non-normative without committing to any familiar fallacies.} Specifically, I propose to explain the norms governing our linguistic practices in terms of the predictive success they give rise to. The idea is that there are certain regularities present in our communicative interactions that are only visible if one adopts the intentional stance, as described in earlier chapters. From the perspective of this stance, it is possible to make reliable predictions about how linguistic interactions unfold. For instance, if one hiker says to another, ``I just saw a bear up ahead'', one can on this basis make reliable predictions about the further utterances and actions of both individuals. The second hiker might ask ``Was it close to the trail?'', but probably not ``Where were you born?'' Likewise, the hikers might turn and walk in the opposite direction of the bear; they probably won't run towards it. The important thing is that these predictions can only be made if one assumes that the hikers are \textit{rational}, or that they are sensitive to the difference between what ought and ought not be inferred from what was said. They must, in short, be sensitive to the norms that determine appropriate language use. 

The reliability of the predictions afforded by the intentional stance indicates that it reveals real patterns in social behavior. In other words, people \textit{really do} think and infer in the ways described using the stance, since the postulation of these thoughts and inferences gives rise so many successful predictions that would otherwise be impossible to make. This observation helps to shed light on the nature of the norms that govern language use. The adoption of the intentional stance requires positing linguistic norms, so insofar as the behavioral patterns the stance reveals are real, the norms that give rise to these patterns are too. Or to put things another way, linguistic norms are part of the world in roughly the same way that centers of gravity and life expectancies are; you might not be able to touch them or see them, yet there is ample evidence of their existence. If we fail to acknowledge their presence, some fairly basic facts about communication are rendered quite mysterious.

It is possible to say even more about the nature of linguistic norms by considering questions about \textit{why} they have the particular properties that they do. As Dennett (\citeyear{Dennett:2010}) notes, people do not direct noises at one another aimlessly: the collection of norms that defines a language has to yield ``a working system of communication'' (p. 54) that confers certain benefits on its users. These benefits, in turn, explain why the norms have remained in effect. The existence of a working system of linguistic norms helps people to engage in mutual prediction, coordinate activities, obtain information about events that are removed in time and space, along with a variety of other things. We know enough about the needs of human beings to begin asking questions about how a stable system of linguistic norms goes towards satisfying these needs. For instance, it is plausible that the norms governing a natural language constitute a ``good enough'' trade-off between simplicity and informativeness. The domains of morphology and syntax are constrained by such trade-offs \citep{Frank:2016}, and there is no reason to think that semantics is somehow an exception to this general rule. The predictions that are warranted by the occurrence of a sentence in the linguistic environment are such that (a) they are simple enough to be made so as to guide action in real time, and (b) they are accurate enough to guide action to appropriate ends.\footnote{In the sophisticated domain of scientific inquiry, this trade-off is almost certainly relaxed to favor accuracy over simplicity. But the point here is to account for how basic linguistic norms got off the ground in the first place amongst (e.g. by allowing people to coordinate the building of huts and the avoidance of dangerous animals, in real time).} 

Overall, if this high-level account is correct, then there is nothing mysterious about the norms invoked by my view. All the questions one could possibly want to ask about them can be investigated in naturalistic terms using familiar scientific tools. One can, for instance, investigate the role of feedback from parents in molding or habituating children to form expectations that are compatible with the norms of the relevant linguistic community. This is clearly what psychologists and linguists who study language acquisition aim to accomplish. One can similarly investigate the cognitive and neural mechanisms that allow people to habituate themselves to such norms. This is clearly what researchers in the fields of psycholinguistics and neurolinguistics aim to accomplish. At some level of description, of course, linguistic activity is just people emitting noises and reacting to noises, but it is hard to get a handle on what is going in these terms. With descriptions in which people are forming expectations, complying with norms, and acting in accord with conventions, it is possible to both predict and explain what goes on. It's not clear that the philosophical naturalist could want anything more than this. 

\section{Models, Norms, and Regularities}

The discussion up to this point might seem quite unrelated to the models described in Chapters 2 and 3. However, it is quite natural to think of these models as learning to comply with a set of norms governing what ought to be inferred or predicted from different forms of input data. The encoder-decoder model described in Chapter 3, for instance, makes use of an ``error signal'' to slowly adjust its parameters so as to optimally comply with a function specification implicit in its training data. This function specification is essentially a norm stating what the model ought to be doing. Put more generally, the cost function used to define a supervised learning model is essentially just a norm against which the behavior of the model is evaluated. So the fact that the norms of the sort I am countenancing show up in even the most technical contexts provides yet further evidence that they are in no way mysterious or unscientific. 

It is natural at this point to wonder whether there is real difference between norm-governed phenomena such as language use and merely pattern-governed phenomena such as fluid flows or planetary orbits. These latter phenomena are natural events, and it makes no sense to say that something irrational or sanction-worthy has occurred if these events unfold in unexpected ways. Acts of language use, on the other hand, are also natural events, but they are tied to the purposes, interests, and needs of those who perform them. Linguistic behavior is only exhibited by the sorts of things for which it makes sense to ask whether a given outcome or event is \textit{good}. Or put another way, linguistic behavior is something that is only performed by entities that are subject to rational assessment. The plausibility of this claim is evident upon the consideration of some simple examples: stones and raindrops do not mean things to one another, and are not subject to assessments of rationality; crickets and dolphins, on the other hand, do mean things to one another, and are subject to assessments of rationality. 

The question of how norms are related to regularities is too broad to tackle in any depth \citep[see][]{Brandom:1994,Kripke:1982}, but I think that the answer should be developed along the follow lines: norm-governed phenomena are pattern-governed phenomena for which there are standards against which the patterns in question can be measured. Importantly, the standards in question cannot be ``read off'' of the patterns themselves. For instance, the fact that it is \textit{bad} for a cricket not to make mating calls is not something that directly follows from the fact that such a cricket will fail to reproduce; one must add the further assumption that failures to reproduce are themselves bad. This further assumption is normative, not natural. 

I think the lesson to draw here is that norms arise only from a perspective in which it is possible to impose purpose on nature. Put another way, norm-governed phenomena are pattern-governed phenomena brought into Sellars' (\citeyear{Sellars:1963}) ``space of reasons'' or manifest image. Norms of behavior are therefore not equivalent to mere patterns in behavior, but to grant as much does not require one to embrace a non-naturalistic world view. There is a completely naturalistic story to be told about how humans came to be the sort of creatures that have a particular manifest image of the world. This image of norms and reasons is the only place where the question of what something ``means'' even arises. Intentional interpretation is a part of the manifest image, and to understand intentional interpretation, one must seek to explain \textit{how and why} the manifest image is structured as it is. Providing such an explanation is beyond the scope of my efforts here, but see Dennett (\citeyear{Dennett:1987,Dennett:2010}) for a number of useful insights.

To return briefly to issue of modeling linguistic phenomena, the preceding observations suggest that models exhibit patterns of behavior that can be interpreted normatively so long as the requisite standards of assessment are available. A model that categorizes images, for instance, can exhibit norm-governed behavior because image categorization is a task that is subject to assessments of error. The task has a purpose or goal, and it is therefore a task defined within the space of reasons, or a task that can be performed by a rational agent. A model of soil erosion, by comparison, cannot exhibit such norm-governed behavior, simply because erosion events are not subject to assessments of error. Eroding is not something done in accordance with a norm; it just \textit{happens} in accordance with physical law. The point to draw from this comparison is that two models (i.e. of soil erosion versus image categorization) can have similar mathematical properties or be similarly deterministic in that every set of input variables is mapped to a well-defined set of output variables, and yet differ in whether they exhibit norm-governed behavior. Invoking a norm offers a way to understand what a model is doing - it becomes possible to think about how well the model would perform under certain conditions, what kinds of changes might make it perform better, and what downstream tasks that model's outputs might used to perform. The norm does not change the mathematical definition of the model or the regularities it exhibits; it just changes our interpretation of the model, and the kinds of reasoning we use the model to perform. As such, there is still no reason to suppose that linguistic norms are theoretically vague or incompatible with the naturalistic standards for inquiry that I have adopted throughout this thesis. 

\section{Conclusion}

The idea that philosophically weighty concepts such as truth, reference, and meaning are best understood in terms of the role they play in our practices originates with classical American pragmatists \citep{Misak:2013,Misak:2007,Peirce:1992} and the later Wittgenstein (\citeyear{Wittgenstein:1953}). I've tried to adapt this idea to accommodate the intentionality criterion within an approach to semantics that is based on inference and prediction rather than reference and truth. There were four general parts to my argument. First, I illustrated the problems that arise when truth conditions and reference relations as taken are treated as basic primitives of semantic theory. Second, I argued that linguistic norms ought to instead be used to underwrite a semantic theory, and that questions about what makes a sentence true or word refer to something can be answered in terms of inferential criteria for determining the normative statuses of particular uses of sentences and words. Third, I argued that the norms governing language use are grounded in their predictive adequacy, and that they self-correct so as to become increasingly more objective. Finally, I argued that norm-governed linguistic phenomena are natural phenomena (i.e. patterns in behavior) interpreted using the notions of rationality and agency that find their home in the manifest image. The existence of this image, in turn, can be given a naturalistic explanations of the sort offered by Dennett. 

My overall view is a combination of inferentialism, pragmatism, and naturalism. Reasoning, on this view, is more basic than representing, and representational concepts like truth and reference are best thought of in terms of norms that constitute good reasoning. I've marshaled a number of arguments in favor of this conclusion, but they are all basically expressions of the following thought: semantics is about \textit{language}, not the world. Pushing the world, in the form of objects and states of affairs, directly into semantic theory introduces confusion and detracts from the goal of explaining linguistic phenomena. Such phenomena arise primarily from the inferences and expectations of language users. And insofar as the world is introduced to help explain things, it is the world \textit{as it is conceived of by language users}. People, put simply, represent the world in virtue of reasoning about it.
