%---------------------------------------------------------------------
% MAIN BODY
%----------------------------------------------------------------------
\externaldocument{chapter3}
%======================================================================
\chapter{Compositionality Reconsidered}
%======================================================================
\renewcommand{\epigraphrule}{0pt}
\setlength{\epigraphwidth}{4.5in}
\epigraph{\textit{It is enough if the sentence as whole has meaning; thereby also its parts obtain their meanings.}}{- Gottlob Frege, 1884}

\epigraph{\textit{...it looks as if when someone says ``Bring me a slab!'', he could mean this expression as one long word corresponding indeed to the single word ``Slab!'' Then can one mean it sometimes as one word, and sometimes as four? And how does one usually mean it? I think we'll be inclined to say: we mean the sentence as one consisting of four words when we use it in contrast to other sentences such as ``Hand me a slab'', ``Bring him a slab'', ``Bring two slabs'', etc.}}{- Ludwig Wittgenstein, 1953}

\section{Introduction}

The principle of compositionality states that the meaning of a complex expression is fixed by its syntactic structure and the meanings of its simpler parts \citep{Szabo:2013,Szabo:2012,FodorLepore:1991}. In the study of natural language semantics, this principle is typically taken to entail that expressions such as phrases and sentences are interpreted in the following two-step manner \citep{Recanati:2012}: first, a set of a lexical rules are used to assign meanings to simple expressions; then, a set of composition rules are used to combine these simple meanings into the meaning of a phrase or sentence. A compositional semantics for a language is accordingly given by a finite number of instances of the following two rule schemes \citep[p. 175-76]{Recanati:2012}:


\begin{enumerate}
  \item $ I(e) = m $
  \item $ I(f(e_1, e_2)) = g(I(e_1),I(e_2)) $
\end{enumerate}

\noindent
where \textit{I} is an interpretation function that maps an expression \textit{e} to some entity that constitutes its meaning, \textit{f} is a syntactic operation that combines simple or complex linguistic expressions, and \textit{g} is semantic operation that maps the meanings of the inputs to a syntactic operation to the meaning of its output \citep{Szabo:2012}. Conventional wisdom states that if natural languages were not compositional in the manner spelled out by (1) and (2), it would be impossible to explain the capacity of language users to produce and comprehend indefinitely large numbers of sentences.

There are at least three significant assumptions built into this characterization of compositionality. The first assumption is that lexical meanings are explanatorily prior to sentence meanings. One cannot, in other words, give a characterization of the meaning of a sentence in the absence of some independent characterization of the meanings the words it is comprised of. The second assumption is that meanings are entities of some kind. A semantic theory is thereby tasked with the job of pairing linguistic expressions with the entities that constitute their meanings. The third assumption is that semantic interpretation is rule-based. Once the conditions for the application of a composition rule are satisfied, all interpretations inconsistent with the rule's consequences are eliminated from consideration.   

Arguably, all three of these assumptions are mistaken. The problem with giving explanatory priority to words is that words have no pragmatic significance in isolation from the sentences in which they occur \citep{Brandom:1994}. Since it is impossible to give non-sentential explanations of word use, the idea that word meanings are fundamental is a non-starter. The problem with treating meanings as entities is that the pairing of an entity with an expression is generally insufficient to provide any insight into the expression's use. Moreover, this ``pairing'' view falsely suggests that the meaning of a one linguistic expression can be specified without reference to other linguistic expressions. Finally, the problem with treating semantic interpretation in rule-based terms is that, empirically speaking, there are essentially no inviolable regularities governing the behavior of linguistic expressions \citep{SmolenskyLegendre:2006,Manning:2015,Seidenberg:1997}. Hence, there should be no strict rules involved in the characterization of these expressions' meanings. 

The preceding considerations point to a significant tension between semantic theories that are compositional and semantic theories that actually do the job of explaining language use. To help resolve this tension, I propose to translate the question of how meanings compose into the question of how people are able to generalize to the use of expressions beyond those that they have had direct exposure to. The motivation for adopting this strategy is simple: existing arguments to the effect that natural languages are compositional largely take the form of inferences to the best explanation, in which the phenomenon to be explained is the evident generality of our capacities for linguistic comprehension \citep{Szabo:2013,Szabo:2012}. As such, my first contention is that debates about the principle of compositionality \textit{are really about generalization rather than semantic composition per se}. My second contention is that the kind of generalization at issue can be achieved without appeal to composition rules like (1) and (2). 

In what follows, I first analyze some standard arguments in favor of the principle of compositionality. I conclude that these arguments do little to show that the semantics of natural language is well accounted for by a system of rules like (1) and (2). I then discuss three kinds of generalization --- similarity-based, syntactic, and procedural --- that are potentially relevant to explanations of how people extrapolate on the basis of prior experience to the correct usage of novel linguistic expressions. I assess the degree to which each of form of generalization is relevant to explanations of language use. On the basis of this assessment, I provide a positive account of linguistic generalization that is consistent with the formal properties of the models discussed in the previous two chapters. Specifically, I argue that the ability to correctly use a realistically large number of linguistic expressions requires: (a) the ability to assimilate sentences in terms of similarities between the inferential contexts in which they occur; (b) the ability to assimilate subsentential expressions on the basis of similarities between the substitution-inferential contexts in which they occur; and (c) the ability to generalize certain cognitive procedures involved in language processing. The result is an account that emphasizes the explanatory priority of inferential relations amongst sentences, and that describes procedures through which these relations are determined in novel contexts via a kind of ``interpolation'' between familiar examples of correct inferential transitions. It is importantly an account that does not invoke the sort of compositionality characterized by rules like (1) and (2). 

\section{Arguments in Favor of Compositionality}

An interesting feature of arguments in favor of the principle of compositionality is that they almost all appeal to apparent facts about the psychological capacities of language users to \textit{understand} certain classes of linguistic expressions \citep{Szabo:2013}. This is somewhat puzzling given that theorists who uphold the principle also tend to claim that the study of semantics is best pursued by abstracting away from the psychological characteristics of language users \citep[e.g.,][]{Speaks:2014,Lewis:1970,Lewis:1975,Carpenter:1997}. Even more puzzling is the fact that theorists who invoke these arguments rarely, if ever, provide a substantive account of what qualifies as understanding a linguistic expression \citep{Szabo:2013}. As will become clear, these oversights render the standard arguments in favor the principle of compositionality surprisingly inconclusive. It is therefore wise to withold judgment on the claim that natural language is compositional, and not take this claim as a basic presupposition of semantic theory.

\subsection{The Argument from Productivity}

The main argument in favor of the claim that natural languages are compositional is an inference to the best explanation of our ability to understand vast numbers of linguistic expressions \citep{FodorPylyshyn:1988}. The explanation in question is simple: if people have the capacity to understand a finite number of lexical items, along with the capacity to understand the consequences of applying a finite number of syntactically guided composition rules of the sort codified by (2), then it follows that they have the capacity to understand all of the possible linguistic expressions produced via the application of these rules. Thus, the assumption that natural languages are compositional explains the unbounded nature of our capacity for linguistic comprehension.

The first problem with this argument is that the existence of unbounded linguistic competence is actually somewhat less than obvious. Rules like (1) and (2) permit the generation of bizarre sentences such as ``a round sleeping rectangle halts no stillness'' and ``melted water is monetarily rigid'', amongst many others. It is not clear that there is a way of understanding such sentences that is \textit{mandated} by their structure and the words they contain. Moreover, even if there is a compositionally mandated way of understanding such sentences, it is an open empirical question whether ordinary people actually make use of it.\footnote{A related point concerns the existence of idioms in most natural languages. By definition, idioms are understood in a non-compositional manner. The fact that at least some linguistic expressions are understood in this way makes it clear that natural languages are at best \textit{mostly} compositional \citep{FodorPylyshyn:1988,Szabo:2012}.} A related complication is that the need to postulate unbounded linguistic competence arguably only arises on the assumption that the expressions belonging to a language can be delimited from the expressions that do not by means of an infinitely generative syntax. In other words, it might only be the case that a language contains an infinite set of expressions if it is governed by rules like (1) and (2); but the postulation of such rules is motivated by the need to account for our ability to comprehend an infinite set of expressions. So unless some kind of theory-independent evidence can be given for the existence of an infinite number of linguistic expressions, the argument from productivity is circular.

The obvious response here is that expressions with iterated modifiers (e.g., ``the very, very, very...very angry teacher'') and relative clauses (e.g., ``the dog that chased the cat that chased the mouse that ate the cheese...'') provide just the sort of evidence that is required. Indeed, one might suppose that the apparent existence of such sentences is precisely what motivated theorists to postulate an infinitely generative syntax in the first place. However, these sentences are in many ways just as bizarre as the semantically anomalous ones considered above. To illustrate, suppose a sentence contains a chain of one hundred instances of the word ``very'' that collectively modify a single adjective. Now suppose a new sentence is produced by adding one further ``very'' to the chain. It is not particularly plausible to assume that the second sentence is understood differently from the first (if either sentence is understood at all). Hence it is not particularly plausible to assume that the meaning of each sentence is characterizable in terms of composition rules that produce unique effects depending on the specific way in which they are applied.\footnote{One might try here to save compositionality by allowing for rules that yield the same semantic value after each iteration in the chain. But presumably ``the very angry teacher'' means something different from the ``the very very angry teacher'', in which case one is stuck with the problem of determining the point at which further iterations are semantically redundant.} 

Similar remarks can be made for sentence pairs involving near-identical relative clauses, though one might object that the difference between such pairs could be grasped under appropriate idealizations concerning the memory of a comprehender \citep{FodorPylyshyn:1988}. Presumably the relativized phrase in each sentence refers to \textit{something}, and there is no guarantee that it is the same thing in both cases. Suppose this objection is correct. It is nonetheless true that the sentences under consideration will almost certainly never occur in the linguistic environment. Since there are no facts to explain concerning the use of such sentences, consideration of them is arguably superfluous to the goals of semantic theory. More generally, the point here is that not every ``well-formed'' sequence of words can be used to make a move in a language game. Semantics is in the business of explaining language use, and language use has clear limits in practice.

To illustrate, suppose we restrict our attention to sentences of up to twenty words in length. Suppose further that the words in these sentences are drawn from a vocabulary containing roughly sixty thousand items.\footnote{This is a standard estimate for the average vocabulary size \citep{Pinker:1994,Harley:2014}} At the upper limit, these assumptions yield a set of sentences containing $60,000^{20}$ items, which is large enough for practical purposes to be considered infinite. But notice that, as a 20-fold Cartesian product, this set contains all sorts of nonsense sentences such as a single word repeated twenty times, or one word repeated ten times followed by another word repeated ten times. The set is therefore a \textit{massive} overestimate of the number of possible sentences containing twenty words. To illustrate just how massive, it is useful to compare the number of sentences a language contains to the number of words it makes use of. For recall that morphology is considered to be compositional in just the same that syntax is.\footnote{That is, the number of possible words is also assumed to be infinite, given that morphology is generative in the same way that syntax is \citep{Pinker:1994}}. If one assumes that a word contains five morphemes, and that there are roughly ten thousand morphemes, one can derive a set of $10,000^{5}$ possible words, which is also large enough for practical purposes to be considered infinite.\footnote{The set contains $1 \times 10^{20}$ items, which is orders of magnitude larger than the number of seconds in the life of person who lives eighty years (i.e., $60 \times 60 \times 24 \times 365 \times 80 \approx 2 \times 10^{9}$)} The point here is that there is enormous difference between the number of ``theoretically possible'' words (i.e., $10,000^{5}$) and the number of words that people actually use (i.e., tens or perhaps hundreds of thousands). So unless there are reasons to suppose that syntax is somehow different from morphology in this respect, one ought to be cautious when making claims to the effect that natural languages contain infinite numbers of sentences.

One might object that people clearly produce and use unfamiliar sentences with ease, even if the language from which these sentences are drawn is not, strictly speaking, infinite in size. But even so, it does not follow that people make use of composition rules like (1) and (2). To explain, it is both possible and likely that people engage in a kind of ``pattern-matching'' to identify commonalities amongst linguistic constructions and assimilate the meaning of a new sentence to that of a familiar sentence it resembles. Intuitive examples are easy to come by: ``Please bring me the \underline{keys}'' might be assimilated to ``Please bring me the \underline{cooler},'' or to ``Please bring me the \textit{X}'' more generally. The point is that one 




Moreover, it is clear that composition rules are empirically inadequate in that they assign ``meanings'' to expressions that do not really mean anything in particular. Bizarre sentences of the sort considered above are a case in point. In fact, observing that they are bizarre is just another way of observing that they have no linguistically mandated pragmatic significance. Whatever follows from the use of one these sentences also follows from the use of numerous other sentences of similar length containing similar words. For instance, nothing specific follows from the use of the sentence ``a round sleeping rectangle halts no stillness'' that doesn't also follow from the sentence ``no sleeping rectangle halts a round stillness''; at most, one might infer some topical regularity involving geometric objects in each case.\footnote{But notice that one can also infer a topical regularity involving, say, high-pitched squeaks in cases involving random noises that bear no resemblance to language. So the existence of topical regularity does not imply semantic interpretability.} Similar remarks apply to sentences containing vast numbers of iterated modifiers or iterated relative clauses. Large sets of these sentences are simply equivalent with respect their communicative significance, and this significance is furthermore so vague as to be non-existent. Given as much, it is debatable whether such sentences even belong to a language at all: there is nothing to explain about their use, so there is no reason to talk about what they mean. 

Overall, an analysis of the argument from productivity yields two broad conclusions. First, it is entirely clear that natural languages are infinitely productive. The kinds of expressions that are produced as evidence for this claim tend to be either bizarre or circularly generated by the very rules that are invoked to provide an explanation of infinite productivity. Second, even if languages are infinitely productive, compositional rules schemes tend to overgenerate by assigning meanings to expressions that cannot be used to communicate something. It is accordingly doubtful that the inference from the existence of vast numbers of linguistic expressions to the conclusion that natural languages are compositional is a good one. 

\subsection{The Argument from Systematicity}

The argument from systematicity is an inference to the best explanation of the fact that the ability to understand certain linguistic expressions systematically co-occurs with the ability to understand other expressions with the same structure \citep{FodorPylyshyn:1988,Szabo:2012,Szabo:2013,FodorLepore:2002}. To give an example, any person who understands the sentence ``the red truck is bigger than the blue car'' is also able to understand the sentences ``the blue truck is bigger than the red car'' and ``the blue car is bigger than the red truck''. These sentences are syntactically invariant with respect to one another, so on the assumption that a person is able to grasp the meaning of one of them through the application of set of composition rules, it follows that they will be able to grasp the meanings of all the others by applying the same rules under substitution of lexical items in a given grammatical class (i.e., substitutions of ``red'' for ``blue'' and ``truck'' for ``car''). Put another way, the principle of compositionality entails that the rules used to compute the meaning of one sentence with a given structure can also be used to compute the meaning of every other sentence with the same structure, via lexical substitution. Hence, the principle provides a natural explanation for why the ability to understand some sentences co-occurs with the ability to understand others. 

The first thing to note about this argument is that it assumes that the ability to understand \textit{one} sentence with a given structure always goes along with the ability to understand \textit{every} sentence with same structure and known lexical constituents. As Szabo (\citeyear{Szabo:2013,Szabo:2012}) points out, this is an empirical claim that might not be true. He suggests that an understanding ``red car'' and ``tall building'' might not suffice to ensure an understanding of ``red building'' and ``tall car'', since one could, for instance, have a sense of what counts as tall building without having any sense of what counts as a tall car (p. 87). Similarly, if the phenomenon underyling systematicity is real, then anyone who understands the sentences ``the log split'' and ``the temperature increased'' should also understand the sentences ``the temperature split'' and ``the log increased'', which is odd to say the least. As before, there is no linguistically mandated pragmatic significance associated with the use of such sentences.

The second thing to note about the argument is that it leaves room for the possibility that linguistic comprehension is systematic but not \textit{structurally} systematic. In other words, one can concede that the ability to understand some sentences goes along with the ability to understand others, but nonetheless propose that the grouping of co-comprehended sentences is determined on basis of something other than syntax. Proponents of systematicity typically just enumerate a few examples of intuitively co-comprehended sentences that happen to share their syntactic structure, and then draw the conclusion that \textit{all} structurally equivalent sentences containing familiar words are co-comprehended \citep[e.g.,][]{FodorPylyshyn:1988}. This is a rather bold inductive leap. It could just as easily be true that linguistic understanding is inferentially systematic, in the sense that understanding one sentence goes along with understanding other sentences that are inferentially related to it. Examples are quite easy to come by: anyone who understands the sentence ``the temperature increased'' is bound to understand the sentences ``the temperature is now higher'' and ``it is warmer than it was before'', amongst others. Furthermore, it is also possible that the co-comprehension of certain structurally identical sentences is simply a side-effect of such inferential systematicity. All of this is to say that considerations of systematicity do not provide a particularly good reason to think that languages are compositional as per (1) and (2) above. 

\subsection{Discussion}

It is undeniable that people are able to understand vast quantities of linguistic expressions, and is also undeniable that the ability to understand some expressions tends to go along with the ability to understand others. But the supposition that natural languages are compositional does not provide a particularly good explanation of these facts. The problem is that people fall short of the comprehension abilities that compositional theories attribute to them. They cannot understand \textit{all} of the sentences produced by a generative syntax, and the fact that they understand one sentence with a given structure does not guarantee that they understand all sentences with the same structure containing familiar lexical components. It is also quite likely that people hypothesize about, rather than immediately identify, the meanings of novel sentences. Consider


However, even if our capacities for linguistic comprehension are more modest than is often assumed, it is still not clear that there are any plausible non-compositional explanations of their existence. It might be that a compositional explanation of our linguistic abilities is the best one available. 

To set the stage for alternative explanations, it is essential to give a proper characterization of the productivity and systematicity present in natural language. What arguments invoking these phenomena tend to miss is the fact that a ``language'' is an abstract description of a set of continually changing social practices that allow people to predict one another's behavior and engage in cooperative activity. To say that a language is productive is to say that these practices can be effectively generalized to cover all or most possible cooperative scenarios. To say that a language is systematic is to say that this generalization does not occur in a piecemeal fashion, or from one narrow practice to the next. When things are put this way, there is no immediately apparent need to assume that such generalization occurs on the basis of linguistic \textit{structure}, as proponents of the principle of compositionality tend to assume. It also becomes abundantly clear that problems concerning generalization are the fundamental ones, rather than problems concerning semantic composition per se.

\section{Three Kinds of Generalization}

To generalize is to ``go beyond'' what one has observed in the past so as to make predictions about some class of future events. A familiar example is the act of inferring or predicting that \textit{all} of the marbles in a particular bag are white on the basis of observing some finite set of white marbles being drawn from the bag. Generalization is accordingly a form of induction, and therefore subject to all of the usual philosophical puzzles concerning this particular type of inference. From a mathematical perspective, however, generalization is a well-studied phenomenon. The fields of machine learning and statistics more broadly are concerned with the formalization of procedures for generalizing from past experiences to correct performance on future tasks \citep[][p. 6]{LiangPotts:2015}. While these procedures can vary substantially, they typically make use of a parameterized function that maps inputs to outputs, a set of examples of correct input-output pairs, and a method for adjusting the function's parameters such that it behaves optimally with respect to mapping each example input to the corresponding output.\footnote{I am restricting consideration here to \textit{supervised} machine learning. It also possible to perform \textit{unsupervised} learning, wherein only unlabelled training examples are used to estimate the model parameters. Count-based embedding models (described in Chapter 2) are examples of models that rely on unsupervised learning.} The goal of this parameter adjustment (i.e., learning) is to obtain a function that generalizes beyond the training examples to correctly map unseen inputs to their matching outputs. For instance, one might learn a function that maps from the bag a marble was drawn out of to a prediction about its colour. Thus, training examples in the form of bag-color pairs constitute prior experience that the learning procedure exploits to form a basis for making predictions about a class of future events. 

What kind of generalization abilities are required for language use? I consider three non-exclusive possibilities in what follows. First, there is similarity-based generalization, which involves mapping a novel input to a particular output on the basis of its similarity to learned inputs. An example would be describing an animal as a horse on the basis of its similarity to other animals that are known to be horses. Second, there is syntactic generalization, which involves mapping a novel input to a particular output on the basis of a rule defined with respect to the input's structural form. An example would be a rule that maps $P \land Q$ to $P$ on the basis of the syntactic structure of conjunction \citep{FodorPylyshyn:1988}. Third, there is procedural generalization, which involves performing a novel sequence of actions or functional mappings to bring about some state on the basis of one's knowledge of how other action sequences bring about other states. An example would be figuring out how to mail a letter for the first time on the basis of one's knowledge of how to write on paper and one's knowledge of the location of a mailbox. 

Interestingly, the merits of these different forms of generalization have been discussed in a long running debate concerning the relative plausibility of classical and connectionist cognitive architectures \citep{FodorPylyshyn:1988,SmolenskyLegendre:2006}. On the classical side, it is claimed that humans routinely learn \textit{universal} generalizations from very limited amounts of data \citep{Hadley:2009,Marcus:1998}. It is further claimed that neural networks, unlike symbol systems, are fundamentally incapable of learning such generalizations. Therefore, neural networks are inadequate as models of human linguistic abilities. Symbolic models that exhibit syntactic generalization and postulate mental rules analogous to (1) and (2) are to be favored instead \citep{FodorPylyshyn:1988}. On the connectionist side, it is claimed that the limits on generalization in neural networks are grossly overstated. It also claimed that neural networks can learn to approximate or implement the kinds of structural rules that are given so much weight by classical theorists \citep{Plate:2003,SmolenskyLegendre:2006,Eliasmith:2013,Rasmussen:2011}. Finally, connectionists often argue that similarity-based generalization is a robust feature of human cognition that cannot be easily accounted for in symbol systems \citep{McClelland:2010}. 

Given the relevance of this debate, I will use it to frame the subsequent discussion of different kinds of generalization. Specifically, I illustrate how typical neural networks generalize on the basis of similarity relations in their input space, while typical symbol systems generalize on the basis of the structural properties of their inputs. Next, I discuss work that, contrary to the claims of symbolicists, illustrates how neural networks can be used to perform syntactic generalization \citep{Eliasmith:2013,Rasmussen:2011}. I then illustrate how procedural generalization is distinct from both 

. The point of this discussion is to set the stage for a positive account of how our linguistic abilities can be accounted for through a combination of similarity-based and procedural generalization. 

\subsection{Similarity-Based Generalization}

To generalize on the basis of similarity, it must first be possible to treat things that could fall under the scope of a generalization as alike and unalike to varying degrees. From a formal perspective, the mathematical structure of a vector space offers a well-defined means by which to allow for such similarity measurements, typically via the inner product of two vectors. Efforts to exploit similarity-based generalization in models of cognitive and linguistic phenomena accordingly tend to makes use of algebraic operations defined over vector spaces. Artificial neural networks are perhaps the best known examples of such models, and a more detailed examination of them can accordingly be used to explain the benefits and drawbacks of similarity-based generalization.

A standard feedforward neural network is a parameterized function that maps vectors in some input space $R^m$ to vectors in some output space $R^n$. The purpose of learning is to find a set of parameters (i.e., weights in the network) that computes the correct mapping between all vectors in $R^m$ and $R^n$. In typical classification tasks, the inputs are continuous feature vectors, and outputs are binary label vectors. Similarities between pairs of input vectors are often defined in terms of the cosine of the angle between them.\footnote{This cosine measure is equivalent to the inner product of two vectors both normalized to unit length.} The same is true for pairs of output vectors. When a new input is presented to the network, it will often be mapped to the same output as some learned input to which it is highly similar. 

The key to properly understanding generalization in a neural network lies in the observation that \textit{every} possible weight configuration defines a function whose domain is $R^m$ and whose codomain is $R^n$. In other words, regardless of how a network's weights are set, the mapping it defines generalizes to cover the entire input space. So the issue is not whether a neural network can generalize, but rather whether it can generalize correctly on the basis of available training data. 

A number of commentators are skeptical. Marcus (\citeyear{Marcus:1998}), for instance, describes several learning scenarios in which it is impossible for a neural network train via backpropogation to acquire a particular universal generalization that humans latch on to quite easily. The simplest scenario is one that involves learning the identity function over five digit binary strings (see pp. 260-63). If the training examples of this function are all such that one of the digits has a constant value (e.g., $0$), a neural network is incapable of learning to correctly compute the identity on strings containing the opposite value. So, if all of the training examples are of the form $01010 \mapsto 01010$, $11110 \mapsto 11110$, $01000 \mapsto 01000$, etc., and a $1$ never occurs as the final digit, the network will never learn to extend the identity function to include any mappings of the form $01011 \mapsto 01011$ and $11111 \mapsto 11111$, where a $1$ occurs as the final digit. 

The reason for this inductive failure is that, by hypothesis, the network has never been exposed to any training examples with a $1$ in final digit position. The network is accordingly never provided with evidence to suggest that this final digit should be ever be anything other than a $0$. But as any reader of Wittgenstein (\citeyear{Wittgenstein:1953}) or Kripke (\citeyear{Kripke:1982}) will be quick to observe, it is not clear that the network has made an error, since the nature of the true function being approximated is under-specified with respect to the available evidence.\footnote{Note that we've just stipulated the true function, and this stipulation is by no means apparent in the training data.} The problem, as Marcus notes, is that \textit{people} effortlessly extrapolate from a few training examples of the sort just described to apply the identity function to every possible five digit binary string. Given as much, it seems clear that people have generalization abilities (or inductive priors) that typical neural networks fundamentally lack.

Similar examples involving linguistic expressions can also be enumerated. For example, Marcus describes a simple experiment in which a recurrent neural network is trained to predict the next word after every word in a sentence. The training sentences are simple identity statements like ``a rose is a rose'' or ``a tulip is a tulip'' (p. 263). If, after training, a statement involving a completely novel word is presented to the network (e.g., ``a blicket is a $\rule{0.75cm}{0.15mm}$''), the network will fail to predict the appropriate continuation (i.e., ``blicket''). Again, people do not exhibit this sort of inductive failure -- they readily complete identity statements involving novel words. One might complain that humans possess all sorts of prior knowledge concerning syntax and word meaning that, if encoded in the network, would enable it to correctly complete these problematic identity statements. However, Hadley (\citeyear{Hadley:2009}) attempts to deflect this objection by considering linguistic input-output mappings that contain nonsense words arranged in accordance with an arbitrary syntax. For example, the training set might consist of the following mappings (p. 518):

\vskip 0.12in
\begin{tabular}{l l} 
Input: \textit{biffle biffle rose zarple}  & Output: \textit{rose zarple} \\
Input: \textit{biffle biffle frog zarple } & Output: \textit{frog zarple} \\
Input: \textit{biffle biffle dog zarple} & Output: \textit{dog zarple} \\
\end{tabular} 
\vskip 0.12in

\noindent
The task is to generalize this pattern to a novel input such as \textit{biffle biffle quoggie zarple}, where the correct output is \textit{quoggie zarple}. Humans can complete this task easily, while typical artificial neural networks cannot. The lesson Hadley draws here is that a hallmark of human intelligence is the ability to rapidly create variables that can be manipulated without regard to their value. In the cases above, the relevant variable is the sequence position that is occupied by the words \textit{rose}, \textit{dog}, and \textit{frog}. The relevant manipulation is to repeat the value of the variable to produce the desired output. Neural networks, according to Hadley (\citeyear{Hadley:2009}) are unable to rapidly create and deploy variables in this manner, and hence cannot account for the ways in which humans induce universal generalizations from sparse data.

Interestingly, it has recently been shown that exact input-output mappings introduced by Hadley can be learned by neural network models that make use of VSAs of the sort described in Chapter 2 \citep[][pp. 269-72]{Eliasmith:2013}. But such counterexamples aside, it is worth examining why the arguments of Hadley and Marcus seem to be so persuasive. Neural networks generalize by interpolating between known input-output mappings. Vectors that are similar to one another in the input space accordingly tend to get mapped to similar points in the output space.\footnote{This is a slight oversimplification, since neural networks can also be be trained to map very similar inputs to very different outputs. However, many more training examples are required correctly learn the overall input-output function in such cases.} So the drawback of methods that rely on similarity-based generalization is that, in order to be effective, they require training data that covers every possible region in the input space. To oversimplify somewhat, these methods generalize \textit{locally}, in the sense that what is learned from a particular training input is only extended to novel inputs that occupy a relatively small surrounding area in the input space. Problems of the sort described by Marcus and Hadley, in comparison, require methods that generalize \textit{globally} over the entire input space. For example, the identity mapping applied to one point in the space is the same mapping that ought to be applied to every other point in the space, hence a model must extrapolate beyond the local neighborhoods around each training item in order to learn the mapping successfully.\footnote{There is nothing special about the use of the identity function in this discussion. Functions that swap the first and last bit in a binary string or reverse the words in a sentence would work just as well.}

\subsection{Syntactic Generalization}

Syntactic generalization involves inducing rules that map inputs to outputs in a structure-sensitive manner. A structure-sensitive operation, to explain, is one that maps an input to an output strictly on the basis of its syntax or form. A standard example of this kind of operation is the elimination rule for conjunction, wherein an input of the form $P \land Q$ is mapped to the output $P$, for all possible values of $P$ and $Q$ \citep{FodorPylyshyn:1988}. 

The first point to note about this kind of mapping is that it is completely insensitive to content of the inputs over which it is defined. So, if the mapping works for any conjunction, it works for all of them, and the kind of generalization that is thereby achieved is \textit{global} in the sense defined above. The second point to note is that the identity function is a trivial structure-sensitive operation of the form $P \mapsto P$, for all values of $P$. So, the examples above that pose problems for certain neural architectures are naturally handled within a symbolic framework \citep{Hadley:2009,Marcus:1998}. The third point to note is that the inference rules that enable generalization in symbol systems all exploit variables in some way, as is illustrated by the use of abstract sentence letters such as $P$ and $Q$. It has been proposed that, implementationally, these variables correspond to memory registers, while variable values correspond to the contents of memory registers \citep{Marcus:1998}. Operations are then defined in terms of different methods for manipulating registers by, for example, copying, comparing, or adding their contents. It is because these operations are defined with respect to variables (i.e., memory registers) rather than values (i.e., register contents) that they are considered to be structure-sensitive or syntactic.

One interesting feature of syntactic generalization is that it is essentially a species of deductive inference. To illustrate, the goodness of the inference from $P \land Q$ to $P$ is guaranteed on structural grounds alone. One is forbidden from concluding from $P \land Q$ that $P$ is false. Similarly, if one generalizes the mapping $01010 \mapsto 01010$ to the mapping $11111 \mapsto 11111$ on structural grounds (i.e., by identifying an underlying rule of the form $P \mapsto P$, one is forbidden from countenancing further mappings that deviate from this pattern (e.g., $10011 \mapsto 11011$). The key point here is that generalizations and inferences made on the basis of structure do not permit exceptions: they are \textit{universal} in that they apply to all tokens of a given structural type. This is a potentially significant problem. For one thing, it becomes difficult to account for non-universal or probabilistic generalizations, which are the rule rather than the exception in linguistic domains \citep{SmolenskyLegendre:2006,ChaterManning:2006,Manning:2015,Seidenberg:1997}. For another thing, it becomes difficult to account for inductive generalizations, which cannot be defined in a purely structural manner. There is, for instance, no structural rule for inferring a universal generalization inductively through an enumeration of examples. The lesson here is that syntactic approaches to generalization are not necessarily panacea in comparison to similarity-based approaches. 

On a related note, it is also worth pointing out that structure-sensitive operations are completely localized to the structures for which they are defined. For example, there is nothing incoherent about a symbol system that can generalize on the basis of the rule $P \land Q \mapsto P$, yet cannot generalize on the basis of the rule $P \mapsto P$. This is a potentially problematic result. In order to explain our impressive linguistic abilities in terms of syntactic operations on symbol structures, one must specify both the nature of the operations and the order in which they are performed. In other words, the symbolicist needs to describe the program or algorithm that determines how linguistic phenomena are to be accounted for in terms of structure-sensitive rules. Yet the program that accounts for phenomena in one domain might be quite different from the program that accounts for phenomena in another, and there is nothing in the symbolic view of cognition to account for how generalization across such domains is possible. Absent some more general account of ``procedural generalization'' (see below), or some more specific account of the process by which certain rules are selected for execution instead of others from case to case, it is hard to view syntactic accounts of generalization as solely adequate to the task of explaining language use. 

\subsection{Procedural Generalization}

In the case of both similarity-based and syntactic forms of generalization, the method by which inputs are mapped to outputs is fixed upon the completion of learning (or programming). However, it is doubtful that our linguistic abilities can be accounted for in terms of a set of static input-output mappings. To \textit{use} language in a productive fashion, one has to be able to do different things in different situations. For instance, effective participation in a conversation involves asking questions, issuing imperatives, answering questions, along with a variety of other tasks. The operations involved in such tasks (i.e., operations for issuing imperatives, answering questions, etc.) have to be strung together in the right way.\footnote{Note that the operations themselves can involve internal generalizations that are either syntactic or similarity-based. For instance, one might generate a sentence that follows from a novel sentence on the basis of either similarity to known sentences or on the basis of a structural rule.} For instance, one cannot sustain a conversation by responding to every sentence with some further sentence that follows from it. One has to know when and \textit{when not} to ask, answer, and instruct. Moreover, one has to know all of this by generalizing from past conversations involving complex sequences of questions, statements, and instructions. Procedural generalization accordingly involves generalizing from known sequences of operations (i.e., procedures) to novel sequences of operations in an appropriate manner.
 
Given this way of looking at things, it can be appealing to think of procedural generalization as a kind of meta-generalization. This is true to an extent, but also somewhat misleading. Procedures can by defined at a variety of different levels of abstraction, and there is no in-principle obstacle to postulating sub-sentential procedures in addition to sentential procedures of the sort just discussed (i.e., those that involve the drawing of inferences). For instance, one can think of parsing a sentence into a dependency tree in terms of procedural generalizations that enable a parsing algorithm to execute distinct sequences of operations for distinct sentences. Similarly, one can think of memorization tasks in terms of procedural generalizations that enable one to select different items to commit to memory in different contexts. Memorizing every second number in a list, for instance, involves a different a procedure than memorizing every third number.

There are a number of possible ways in which procedural generalization might be implemented. One idea is to assimilate it to a kind of syntactic generalization by identifying different procedures with the behavior of an algorithm or program that responds differently to different inputs. For instance, a simple program that reverses every string in a list implements a kind of procedural generalization based on syntactic structure, since different sequences of operations will be executed on different input lists (i.e., the length of the list and the strings it contains can vary), and since the precise sequence in question is determined by the structure of the input and not its content (i.e., the  specific characters in each string do not matter). Another idea is to assimilate procedural generalization to a kind of similarity-based generalization by identifying different procedures with the different behaviors of a system that goes through a set of state transitions that are determined by the similarity between its current state and some set of ``transition-triggering'' states. For instance, a recurrent neural network used to decode a sentence from a distributed representation undergoes a series of a state transitions to produce a sequence of words, and the transitions in question are determined by similarity relations within the network's state space. The number of transitions, moreover, is determined by the initial state of the network. 

These assimilation strategies aside, there is also a sense in which procedural generalization is a unique form of generalization, since it involves generalizing from some multi-step procedures to others, rather than generalizing from some input-output mappings to others. Given its importance, it is interesting to note that procedural generalization is not often discussed in the literature. In the context of debates about cognitive architecture, this is likely because connectionists and classicists are on equally bad footing --- procedural generalization is a challenge for everyone.

\section{Generalization in Language Use}

Which of these three forms of generalization are necessary for language use? The diplomatic answer is that they all are: people use similar sentences in similar ways, learn structure-sensitive inference patterns of sort highlighted by Marcus (\citeyear{Marcus:1998}), and generalize to the procedures underlying novel conversational patterns with ease. A more parsimonious answer, however, is that most relevant aspects of language use can be accounted for without appeal to syntactic generalization. In order to be able to use language in an appropriately productive and systematic manner, one does not need to apply structure-sensitive operations to syntactically complex objects that are the product of a composition rules like (1) and (2). 

To illustrate this point, it is helpful to first revisit the model of communication that initially motivates an inferentialist approach to semantics. At bottom, the model gives explanatory priority to human behavior that involves producing and responding to sounds and gestures. To talk of the meaning of these sounds and gestures is to make explicit the role they play in the informal calculus that constitutes intentional interpretation. People make sense of one another through attributions of ``sentential attitudes'', and the significance of these attributions is determined by the inferential roles of the sentences in question. Thus, the direction of explanation is importantly top-down, in that sentence meaning takes priority over word meaning. Words are to be understood in terms of their effects on the inferential roles of sentences, and these effects are be codified in terms of inferential relations amongst sentences that are substitutional variants of one another.

If this model of communication is formalized in terms of operations defined over continuous embeddings corresponding to lexical items, as in the previous chapter, it is possible to ``interpolate'' between the inferential roles of sentences on the basis of similarities amongst the underlying lexical embeddings. Similar sentence embeddings generate similar inference chains, and similar lexical embeddings have similar substitutional effects on embeddings corresponding to the sentences in which they occur. For example, the sentences ``A man is walking in the park'' and ``A child is running through the cornfield'' share a number entailments, such as ``A person is outside'' and ``A person is moving''. These shared entailments arise because the embeddings that mediate the inferential behavior of the sentences under consideration are similar to one another. This similarity is in turn due to similarities amongst the embeddings assigned to certain lexical items. For example, ``park'' and ``cornfield'' are assimilated in virtue of the fact that substitution of one for other never affects the status of inferences from ``So-and-so is in the park/cornfield'' to ``So-and-so is outside'' in the underlying neural model. If such substitutional assimilations are available for all of the relevant words in a novel sentence, it is trivial for the model to generalize to an account of the sentence's inferential role. Suppose, for instance, that the model has never been exposed to the sentence ``A child is running through the cornfield'', but it has been exposed to the sentence ``A man is walking in the park'', amongst many others. If the model has been provided with enough information to substitutionally assimilate ``child'' to ``man'', ``running'' to ``walking'', and ``park'' to ``cornfield'', then model will be able to assimilate the sentences `A child is running through the cornfield'' and ``A man is walking in the park'' with respect to inferences to ``A person is moving'' and ``A person is outside'', as demonstrated in the previous chapter.\footnote{Of course, the assimilations just described do not extend to cover all possible inferences. For instance, the substitution of ``running'' for ``walking'' can change whether or not the sentences ``A person is moving quickly'' and ``A person is moving slowly'' have the status of entailments.}

One key feature of my model is that it never produces syntactically structured objects. Granted, syntactically guided compression and decompression operations are used to transform word embeddings into sentence embeddings and vice versa, but these embeddings are not composed of parts and wholes in the way that symbol structures are. The operations applied to these embeddings therefore do not generalize on the basis of syntax. Rather, they generalize largely on the basis of similarity, since similar sentence vectors get decompressed into similar word vectors, and similar word vectors get compressed into similar sentence vectors. Overall, the role of syntax in the model is compatible with Christiansen and Chater's (\citeyear{Christiansen:2015}) view of syntactic structure as a description of a sentence's processing history. Another key feature of the model is that it never assigns semantically interpretable entities (i.e., ``meanings'') to individual linguistic expressions. One cannot, for instance, ``read off'' the meaning of a sentence from the embedding it is assigned; rather, the meaning is read off of the overall behavior of a system in which this embedding plays a role. It is accordingly somewhat misleading to think of meanings as entities at all.
 
The generalization exhibited by the model under consideration is powerful, but perhaps not powerful enough. Handling phenomena of the sort discussed by Marcus (\citeyear{Marcus:1998}) and Hadley (\citeyear{Hadley:2009}) is a challenge. Handling the kind of generalization that applies to turn-taking behavior in conversational contexts is also a challenge. The model cannot generate questions and instructions, let alone string them together with assertions so as to successfully sustain a dialogue. However, identifying these limitations just points out the obvious: that the model falls short of replicating the functional properties of a fully competent language user. All models fall short of this standard, so the real question is whether syntactic structures and composition rules like (1) and (2) need to be added to our stock of raw materials before attempting to account for these more complex forms of language use. 

I think the answer is no. What is needed to account for these phenomena are descriptions of procedures that involve the manipulation of memory states. To account for dialogue, for example, one might define a procedure that selectively updates the state of a memory over the course of a conversation, and then exploits this memory to produce an appropriate response to the most recent ``move'' in the conversation. To account for anaphoric dependencies amongst the sentences used in a conversation, one might define a procedure that similarly updates the state of a memory, but then exploits this memory to substitute or link the occurrences of pronouns in new sentences with their anaphoric antecendents.\footnote{Such a procedure would work for lazy anaphora but not quantificational anaphora. See Brandom (\citeyear{Brandom:1994}, Ch. 7) for details on anaphoric chains.} The obvious way to implement these procedures using a model of the sort described in the previous chapter involves coupling a neural network to an external memory that can be written to and read from while the network generates predictions \citep{Weston:2016,Weston:2015,Sukhbataar:2015,Eliasmith:2012}. With such a system, it would be straightforward to handle the phenomena discussed by Hadley (\citeyear{Hadley:2009}) and Marcus (\citeyear{Marcus:1998}). For instance, a symbolic rule that computes the identity mapping $P \mapsto P$ can be translated into a procedure that takes some input, stores it in memory, and then retrieves it to produce an output. Similarly, a symbolic rule that maps sentences of the form $ AABC $ to sentences of the form $ BC $ can be translated into a procedure that writes a sequence of four inputs to memory, and then retrieves the last two. The obvious objection to this argument is that the procedures I am describing seem to be clear examples of structure-sensitive operations. To explain, a procedure that takes some input, stores it in memory, and then retrieves it as output can be thought of as simply \textit{implementing} the structure sensitive operation $P \mapsto P$. A neural network that carries out this procedure ought to accordingly be thought as a mere implementation of a classical symbol system \citep{FodorPylyshyn:1988}. Moreover, such an implementation would clearly be performing syntactic rather than similarity-based generalization when it maps some new value of $P$ onto itself.

There is something to this objection, but it nonetheless has two major shortcomings. First, the objection oddly implies that syntactic generalization encompasses any form of generalization that involves the manipulation of memory states. If so, then language users would trivially fall into the class of syntactic generalizers merely in virtue of the fact that they possess the ability to remember and repeat things. And even if one disregards this stipulative conflation of syntactic generalization with memory-dependent generalization, it is still not clear that the way people remember and repeat things typically involves the kind of variable manipulation highlighted by Marcus (\citeyear{Marcus:1998}). Human memory is content-addressable, highly sensitive to context, and prone to exhibiting interference effects. Likewise, human performance on rule-based generalization problems such as the Wason card selection task is highly sensitive to the content of the rules in question \citep{Eliasmith:2013,Thagard:2005}. It is therefore somewhat misleading to treat the mind as a ``syntactic engine'' that performs structure-sensitive operations of the sort described by Fodor and Pylyshyn (\citeyear{FodorPylyshyn:1988}). 

Second, it is possible to define procedures that realize the kind of phenomena emphasized by Hadley and Marcus without relying on explicit rules defined over discrete symbol structures.\footnote{Note the use of all-or-nothing rules defined over discrete structures is definitional of the sort symbol processing that underlies syntactic generalization \citep{FodorPylyshyn:1988}} For example, memory networks of the sort described in the previous chapter allow for continuous ``read'' and ``write'' operations to be performed using a memory that stores a series of embeddings \citep{Sukhbataar:2015,Graves:2014}. Likewise, neuro-computational models of the sort described by Eliasmith et al. (\citeyear{Eliasmith:2012}) make use of an action selection system that can copy, compare, and add items without directly employing symbolic rules.\footnote{Though the processing these system performs can be thought of as ``symbol-like'' in certain ways \citep{Eliasmith:2013}} Given these examples, it is not clear that a good account of human generalization requires postulating formal rules of the sort that define the behavior of modern computers. 

Together, I think these responses illustrate an important point: ``Pure'' syntactic generalization \citep[][p. 151]{Eliasmith:2013} is an ideal that cognitive systems rarely, if ever, satisfy. Rather, cognitive systems seem to implement a wide range of procedures for mapping between perceptual inputs and motor outputs, some of which are relatively (but not totally) content-insensitive. So, when characterizing the sort of generalization that underlies language use, it is sufficient to appeal to similarities between linguistic expressions and between the various procedures that are used to manipulate them. Such procedures can involve mapping sentences onto embeddings, mapping embeddings onto sentences, mapping embeddings to and from memory in a continuous (i.e., non-discrete) manner, and various other things. One thing such procedures do \textit{not} typically involve is pure variable manipulation. 

An important implication of this description of linguistic generalization is that it is in tension with some common assumptions about the nature of language comprehension. To explain, it is often assumed that understanding a linguistic expression involves building up some kind of structured representation that captures the expression's meaning \citep[see e.g.,][]{SmolenskyLegendre:2006}. My view, in contrast, is that understanding a linguistic expression involves satisfying a certain function specification. If so, then the focus should be on the inferential \textit{processes} that implement this function specification, rather than on representational \textit{products}. A consequence of this shift in focus is that much of the motivation for describing the semantics of natural language in terms of composition rules like (1) and (2) is lost, since such rules are designed to construct exactly the kind of representational products whose explanatory utility is being called into question. Overall, if merely being in a state that results from the application of certain composition rules suffices for understanding a linguistic expression, then organizing a semantic theory around such rules would make sense. But being in a particular representational state clearly does \textit{not} suffice for understanding a linguistic expression.

To summarize, the point of this discussion is to illustrate that the generalization abilities characteristic of linguistic competence can be well accounted for without the postulation of explicit syntactic structure and inference rules defined with respect to such structure. Moreover, there is no need to postulate entities that are assigned to linguistic expressions in a rule-based manner and suffice to fix the meanings of these expressions. The bearing of these conclusions on the claim that natural languages are compositional is investigated in the next section.  

\section{Is Natural Language Compositional?}

At the outset of this chapter, three assumptions associated with the principle of compositionality were highlighted: that word meaning is prior to sentence meaning; that meanings are entities; and that semantic interpretation is rule-based. All three of these assumptions have proven doubtful: inferential relations amongst sentences are primary, and indirectly confer meanings on words; meaning talk is talk of what follows from what, or of inferential relations amongst sentence types; and the ``rules'' that govern what follows from what are not rules at all - they are soft, probabilistic constraints that can be encoded into the parameters of a neural network. 

Does all of this mean that natural languages are non-compositional? Not exactly. There is a clear sense in which the model discussed in the previous chapter makes use of ``composition functions'' that assign embeddings to complex linguistic expressions on the basis of the embeddings assigned to their simpler parts. One might even take these composition functions to instantiate rules like (1) and (2). There are, however, two important dissimilarities between functions that merge word embeddings into sentence embeddings and rules that combine word meanings into sentence meanings. First, embeddings are not meanings. An embedding does not, in isolation, describe the world or license particular inferences. One cannot, for example, take a single sentence embedding produced by the model in Chapter 3 and ``read off'' the sentence's meaning from this embedding. Second, embeddings do not have constituent structure.\footnote{Embeddings produced using VSAs of the sort described in Chapter 2 are a partial exception, since they can be used to perform structure-sensitive operations. The exception is partial because a similarity relation is defined over these embeddings entails that makes the operations in question not \textit{purely} structure-sensitive \citep{Plate:2003,Eliasmith:2013}.} For instance, the sentence embeddings produced by the model described in Chapter 3 do not have constituent parts that correspond to individual words. Since they lack constituent parts, they cannot have explicit syntactic structure, which in turn means they cannot be manipulated via structure-sensitive operations. Put simply, the composition functions described in previous chapters do not produce composite representations that are \textit{anything} like those described by proponents of the principle of compositionality.

Natural language is nonetheless ``sort of'' compositional in the sense that the inferential procedures that underlie linguistic comprehension (in my model at least) are made up of components that get re-used in novel situations. To give one example, the embedding corresponding to an individual word gets re-used every time the model is used to generate entailments for a novel sentence containing this word. To give another example, the weight matrix associated with a particular syntactic dependency gets re-used every time the model propagates activities through a novel tree that includes this dependency. One might be tempted to think that such re-use of components is in accord with the principle of compositionality. Perhaps. But if so, then the principle is arguably of no special linguistic interest. A motor control system, for instance, would count as compositional by this standard in virtue of the fact that it re-uses certain joint angles and muscle torques when producing novel motions. Given that most philosophers and linguists would not treat motor control as compositional, it's clear that they have something different in mind than mere generalization through re-use. Specifically, they have in mind the creation of structured objects consisting of parts and wholes.\footnote{As a point of further comparison, note the oddity of treating the motion of, say, an arm as a ``structured object'' consisting of parts corresponding to various joint angles, muscle torques, and spatial co-ordinates in the arm's trajectory. For what it's worth, I take language use and motor control to be loosely compositional in roughly the same way.} For reasons already rehearsed, it is not clear that structured objects of this kind are needed to explain language use.

It is worth revisiting the debates about productivity and systematicity in light of the notion that natural language is only ``sort of'' compositional. In the case of productivity, it is fairly clear that a language processing system that re-uses certain basic components and procedures can productively handle vast numbers of expressions. The model in Chapter 3, for instance, productively generates entailments for all input sentences that can be generated using a known vocabulary of lexical items. Granted, the model does not generate \textit{correct} entailments for all input sentences, but this may in fact be a source of strength. Recall that in my discussion of the argument from productivity, I observed that not all well-formed sentences have a linguistically mandated way of being understood. For example, the sentence ``Your peak is fuming'' has no definite meaning that every competent language user can immediately identify. Rather, people form hypotheses or ``best guesses'' about what is meant by an utterance of this sentence. So, insofar as the model produces reasonable ``best guesses'' concerning the inferential consequences of atypical sentences, it is \textit{as productive as a compentent langauge user}.\footnote{I am not arguing that my model actually achieves this level of productivity}

In the case of systematicity, any system that operates in accordance with procedures that map linguistic expressions onto one another is bound to be systematic to a certain degree. Even in a degenerate case where only one such mapping is computed, there is a systematic relation between what the input expression is followed \textit{by} and what the output expression follows \textit{from}. Take, for instance, a system that is only capable of making the inference from ``It is raining'' to ``The streets are wet'' \citep[][p. 313]{Sellars:1954}. On the assumption that meaning ought to be characterized in terms of inference, it is quite clear that understanding somethings about the first sentence requires understanding something about the second one, too. Specifically, if one understands that ``It is raining'' entails ``The streets are wet'', then one cannot help but grasp that ``The streets are wet'' is entailed by ``It is raining''. Again, the model in Chapter 3 reflects this systematicity despite not operating in accordance with the principle of compositionality. An inferential network of the sort depicted in Figure \ref{chain}, for example, is clearly systematic in that it simultaneously defines the inferential roles of numerously linguistic expressions. The ability to navigate one these roles, moreover, cannot be separated from the ability to navigate others. 

The overall point of these observations is to provoke a shift from thinking about representational \textit{states} that encode sentence meanings as structured objects to thinking about inferential \textit{processes} that are involved in mapping sentences onto their expected consequences. This process-based approach to thinking about language use and linguistic cognition is not compatible with standard formulations of the principle of compositionality, on which complex ``meanings'' are built up out of simpler ones. The approach is, however, compatible with a looser notion of compositionality on which certain procedures get re-used when determining the inferential consequences of novel linguistic expressions. This loose notion of compositionality is compatible with as much productivity and systematicity as there actually is in natural language. 

\section{Conclusion}

As a point of comparison for the view I am offering, it is useful to imagine a perfectly \textit{non}-compositional language. Such a language would consist of an enormous number of unique expressions that are all akin to Wittgenstein's (\citeyear{Wittgenstein:1953}) one-word signals of ``Slab!'' and ``Beam!'' It goes without saying that such a language would be horribly inefficient and nearly impossible to learn, since every new expression would have to be memorized in rote fashion. Language use would thus pose a significant cognitive burden. The point of introducing sub-sentential structure into linguistic expressions is to reduce this burden by assimilating expressions with respect to shared features of their communicative significance. For example, the point of repeating the word ``slab'' in ``Bring two slabs'' and ``Bring him a slab'' is to exploit a redundancy in the communicative significance of these sentences - both are \textit{about slabs}. 

There is, however, a significant gap between the claim that languages are structured to exploit communicative redundancies and the claim that languages are compositional in the sense codified by (1) and (2). I've argued that there is no need to bridge this gap. For example, the sentences ``Bring two slabs'' and ``Bring him a slab'' mean similar things because they involve shared words that can be manipulated using shared procedures to form certain predictions. To learn a language, one needs to learn how to draw appropriate inferences using large numbers of novel expressions. The key challenge, then, is learning to generalize from from the use of familiar linguistic expressions to the use of unfamiliar linguistic expressions. My strategy for solving this generalization problem is fairly straightforward: by examining the distribution of sentences as tacit ``premises'' and ``conclusions'' in a space of inferences, one can isolate syntactic and lexical redundancies in these sentences (i.e., patterns that show up in numerous inferential contexts). These redundancies can then be exploited to assign a distributional profile in the space of inferences to novel sentences.  The model in Chapter 3 is a clear application of this strategy, and insofar as the model generalizes successfully, it provides evidence that the strategy works. 

Overall, the key claim I'm making is that debates about the principle of compositionality are really about generalization rather than semantic composition per se. The generalization that is characteristic of language use, moreover, involves re-applying simple procedures for processing lexical items so as to draw appropriate inferences from the sentences in which these lexical items occur. In the model in Chapter 3, such procedures involve compressing word embeddings into sentence embeddings, and decompressing sentence embeddings into word embeddings. Generalization is achieved on the basis of (a) similarities between word embeddings, and (c) similarities between the procedures used to manipulate these word embeddings. Put more simply, generalization occurs on the basis of similarities between the lexical items that occur in sentences, and between the syntactically-guided procedures used to manipulate these items to generate certain predictions. Generalization does \textit{not} occur on the basis of operations on objects comprised of parts and wholes. So, if this model is anything to go by, natural language is only ``sort of'' compositional, just as it is only ``sort of'' productive and systematic. 