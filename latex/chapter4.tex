%---------------------------------------------------------------------
% MAIN BODY
%----------------------------------------------------------------------
\externaldocument{chapter3}
%======================================================================
\chapter{Compositionality Reconsidered}
%======================================================================
\renewcommand{\epigraphrule}{0pt}
\setlength{\epigraphwidth}{4.5in}
\epigraph{\textit{It is enough if the sentence as whole has meaning; thereby also its parts obtain their meanings.}}{- Gottlob Frege, 1884}\footcitetext[qtd. in][]{Szabo:2012}

\epigraph{\textit{...it looks as if when someone says ``Bring me a slab!'', he could mean this expression as one long word corresponding indeed to the single word ``Slab!'' Then can one mean it sometimes as one word, and sometimes as four? And how does one usually mean it? I think we'll be inclined to say: we mean the sentence as one consisting of four words when we use it in contrast to other sentences such as ``Hand me a slab'', ``Bring him a slab'', ``Bring two slabs'', etc.}}{- Ludwig Wittgenstein, 1953}

\section{Introduction}

The principle of compositionality states that the meaning of a complex expression is fixed by its syntactic structure and the meanings of its simpler parts \citep{Szabo:2013,Szabo:2012,FodorLepore:1991}. In the study of natural language semantics, this principle is typically taken to entail that expressions such as phrases and sentences are interpreted in the following two-step manner \citep{Recanati:2012}: first, a set of a lexical rules are used to assign meanings to simple expressions; then, a set of composition rules are used to combine these simple meanings into the meaning of a phrase or sentence. A compositional semantics for a language is accordingly given by a finite number of instances of the following two rule schemes \citep[pp. 175-76]{Recanati:2012}:


\begin{enumerate}
  \item $ I(e) = m $
  \item $ I(f(e_1, e_2)) = g(I(e_1),I(e_2)) $
\end{enumerate}

\noindent
where \textit{I} is an interpretation function that maps an expression \textit{e} to some entity that constitutes its meaning, \textit{f} is a syntactic operation that combines simple or complex linguistic expressions, and \textit{g} is semantic operation that maps the meanings of the inputs to a syntactic operation to the meaning of its output \citep{Szabo:2012}. Conventional wisdom states that if natural languages were not compositional in the manner spelled out by (1) and (2), it would be impossible to explain the capacity of language users to produce and comprehend indefinitely large numbers of sentences.

There are at least three significant assumptions built into this characterization of compositionality. The first assumption is that lexical meanings are explanatorily prior to sentence meanings. One cannot, in other words, give a characterization of the meaning of a sentence in the absence of some independent characterization of the meanings the words it is comprised of. The second assumption is that meanings are entities of some kind. A semantic theory is thereby tasked with the job of pairing linguistic expressions with the entities that constitute their meanings. The third assumption is that semantic interpretation is rule-based. Once the conditions for the application of a composition rule are satisfied, all interpretations inconsistent with the rule's consequences are eliminated from consideration.   

Arguably, all three of these assumptions are mistaken. The problem with giving explanatory priority to words is that words have no pragmatic significance in isolation from the sentences in which they occur \citep{Brandom:1994}. Since it is impossible to give non-sentential explanations of word use, the idea that word meanings are fundamental is a non-starter. The problem with treating meanings as entities is that the pairing of an entity with an expression is generally insufficient to provide any insight into the expression's use. Moreover, this ``pairing'' view falsely suggests that the meaning of a one linguistic expression can be specified without reference to other linguistic expressions. Finally, the problem with treating semantic interpretation in rule-based terms is that, empirically speaking, there are essentially no inviolable regularities governing the behavior of linguistic expressions \citep{SmolenskyLegendre:2006,Manning:2015,Seidenberg:1997}. Hence, there should be no strict rules involved in the characterization of these expressions' meanings. 

The preceding considerations point to a significant tension between semantic theories that are compositional and semantic theories that actually do the job of explaining language use. To help resolve this tension, I propose to translate the question of how meanings compose into the question of how people are able to generalize to the use of expressions beyond those that they have had direct exposure to. The motivation for adopting this strategy is simple: existing arguments to the effect that natural languages are compositional largely take the form of inferences to the best explanation, in which the phenomenon to be explained is the evident generality of our capacities for linguistic comprehension \citep{Szabo:2013,Szabo:2012}. As such, my main claim in this chapter is that debates about the principle of compositionality \textit{are really about generalization rather than semantic composition per se}. I then build on this claim to argue that the generalization in question can be achieved without appeal to typical formulations of the principle of compositionality.

In what follows, I first analyze some standard arguments in favor of the principle. I conclude that these arguments do little to show that the semantics of natural language is well accounted for by a system of rules like (1) and (2). I then discuss three kinds of generalization --- similarity-based, syntactic, and procedural --- that are potentially relevant to explanations of how people extrapolate on the basis of prior experience to the correct usage of novel linguistic expressions. I assess the degree to which each of form of generalization is relevant to explanations of language use. On the basis of this assessment, I provide a positive account of linguistic generalization that is consistent with both the IPA framework and the formal properties of the model discussed in the previous chapter. Specifically, I argue that the ability to correctly use a realistically large number of linguistic expressions requires: (a) the ability to assimilate sentences in terms of similarities between the inferential contexts in which they occur; (b) the ability to assimilate subsentential expressions on the basis of similarities between the substitution-inferential contexts in which they occur; and (c) the ability to generalize certain procedures involved in language processing. The result is an account that emphasizes the explanatory priority of inferential relations amongst sentences, and that describes procedures through which these relations are determined in novel contexts via a kind of ``interpolation'' between familiar examples of correct inferential transitions. This interpolation is characterized in procedural terms, and gives rise to exactly the sort of generalization that I claim is at the core of debates about compositionality.

\section{Arguments in Favor of Compositionality}

An interesting feature of arguments in favor of the principle of compositionality is that they almost all appeal to apparent facts about the psychological capacities of language users to \textit{understand} certain classes of linguistic expressions \citep{Szabo:2013}. This is somewhat puzzling given that theorists who uphold the principle also tend to claim that the study of semantics is best pursued by abstracting away from the psychological characteristics of language users \citep[e.g.,][]{Speaks:2014,Lewis:1970,Lewis:1975,Carpenter:1997}. Even more puzzling is the fact that theorists who invoke these arguments rarely, if ever, provide a substantive account of what qualifies as understanding a linguistic expression \citep{Szabo:2013}. As will become clear, these oversights render the standard arguments in favor the principle of compositionality surprisingly inconclusive. It is therefore wise to withold judgment on the claim that natural language is compositional, and not take this claim as a basic presupposition of semantic theory.

\subsection{The Argument from Productivity}

The main argument in favor of the claim that natural languages are compositional is an inference to the best explanation of our ability to understand vast numbers of linguistic expressions \citep{FodorPylyshyn:1988}. The explanation in question is simple: if people have the capacity to understand a finite number of lexical items, along with the capacity to understand the consequences of applying a finite number of syntactically guided composition rules of the sort codified by (2), then it follows that they have the capacity to understand all of the possible linguistic expressions produced via the application of these rules. Thus, the assumption that natural languages are compositional explains the unbounded nature of our capacity for linguistic comprehension.

The first problem with this argument is that the existence of unbounded linguistic competence is actually somewhat less than obvious. Rules like (1) and (2) permit the generation of bizarre sentences such as ``a round sleeping rectangle halts no stillness'' and ``melted water is monetarily rigid'', amongst many others. It is not clear that there is a way of understanding such sentences that is \textit{mandated} by their structure and the words they contain. Moreover, even if there is a compositionally mandated way of understanding such sentences, it is an open empirical question whether ordinary people actually make use of it.\footnote{A related point concerns the existence of idioms in most natural languages. By definition, idioms are understood in a non-compositional manner. The fact that at least some linguistic expressions are understood in this way makes it clear that natural languages are at best \textit{mostly} compositional \citep{FodorPylyshyn:1988,Szabo:2012}.} A related complication is that the need to postulate unbounded linguistic competence arguably only arises on the assumption that the expressions belonging to a language can be delimited from the expressions that do not by means of an infinitely generative syntax. In other words, it might only be the case that a language contains an infinite set of expressions if it is governed by rules like (1) and (2); but the postulation of such rules is motivated by the need to account for our ability to comprehend an infinite set of expressions. So unless some kind of theory-independent evidence can be given for the existence of an infinite number of linguistic expressions, the argument from productivity is circular.

The obvious response here is that expressions with iterated modifiers (e.g., ``the very, very, very...very angry teacher'') and relative clauses (e.g., ``the dog that chased the cat that chased the mouse that ate the cheese...'') provide just the sort of evidence that is required. Indeed, one might suppose that the apparent existence of such sentences is precisely what motivated theorists to postulate an infinitely generative syntax in the first place. However, these sentences are in many ways just as bizarre as the semantically anomalous ones considered above. To illustrate, suppose a sentence contains a chain of one hundred instances of the word ``very'' that collectively modify a single adjective. Now suppose a new sentence is produced by adding one further ``very'' to the chain. It is not particularly plausible to assume that the second sentence is understood differently from the first (if either sentence is understood at all). Hence it is not particularly plausible to assume that the meaning of each sentence is characterizable in terms of composition rules that produce unique effects depending on the specific way in which they are applied.\footnote{One might try here to save compositionality by allowing for rules that yield the same semantic value after each iteration in the chain. But presumably ``the very angry teacher'' means something different from the ``the very very angry teacher'', in which case one is stuck with the problem of determining the point at which further iterations are semantically redundant.} 

Similar remarks can be made for sentence pairs involving near-identical relative clauses, though one might object that the difference between such pairs could be grasped under appropriate idealizations concerning the memory of a comprehender \citep{FodorPylyshyn:1988}. Presumably the relativized phrase in each sentence refers to \textit{something}, and there is no guarantee that it is the same thing in both cases. Suppose this objection is correct. It is nonetheless true that the sentences under consideration will almost certainly never occur in the linguistic environment. Since there are no facts to explain concerning the use of such sentences, consideration of them is arguably superfluous to the goals of semantic theory. More generally, the point here is that not every ``well-formed'' sequence of words can be used to make a move in a language game. Semantics is in the business of explaining language use, and language use has clear limits in practice.

To extend this point, suppose we restrict our attention to sentences of up to twenty words in length. Suppose further that the words in these sentences are drawn from a vocabulary containing roughly sixty thousand items.\footnote{This is a standard estimate for the average adult vocabulary size \citep{Pinker:1994,Harley:2014}} At the upper limit, these assumptions yield a set of sentences containing $60,000^{20}$ items, which is large enough for practical purposes to be considered infinite. But notice that, as a 20-fold Cartesian product, this set contains all sorts of nonsense sentences such as a single word repeated twenty times, or one word repeated ten times followed by another word repeated ten times. The set is therefore a \textit{massive} overestimate of the number of possible sentences containing twenty words. To illustrate just how massive, it is useful to compare the number of sentences a language contains to the number of words it makes use of. Recall that morphology is considered to be compositional in just the same way that syntax is.\footnote{That is, the number of possible words is also assumed to be infinite, given that morphology is generative in the same way that syntax is \citep{Pinker:1994}}. If one assumes that a word contains five morphemes, and that there are roughly ten thousand morphemes, one can derive a set of $10,000^{5}$ possible words, which is also large enough for practical purposes to be considered infinite.\footnote{The set contains $1 \times 10^{20}$ items, which is several orders of magnitude larger than the number of seconds in the life of person who lives eighty years (i.e., $60 \times 60 \times 24 \times 365 \times 80 \approx 2 \times 10^{9}$)} But there is clearly an enormous difference between the number of ``theoretically possible'' words (i.e., $10,000^{5}$) and the number of realistically usable words (i.e., tens or perhaps hundreds of thousands if we are generous). So unless there are reasons to suppose that syntax is somehow different from morphology with respect to such mismatches, one ought to be cautious in drawing conclusions about the nature of linguistic competence based on the number of theoretically possible sentences in a language.

One might object here that people clearly produce and use \textit{novel} sentences (and words) with ease, even if the language from which these sentences are drawn is not, strictly speaking, infinite in size. But even so, it does not follow that people exploit composition rules like (1) and (2). To explain, it is both possible and likely that people engage in a kind of ``pattern-matching'' to identify commonalities amongst linguistic expressions and assimilate the meaning of a new sentence to that of a familiar sentence it resembles \citep{Tomasello:2003}. Intuitive examples are easy to come by: ``Please bring me the \underline{keys}'' might be assimilated to ``Please bring me the \underline{cooler},'' or to ``Please bring me the \textit{X}'' more generally. Comprehension of one linguistic expression that communicates ``bringing'' can thereby be generalized to the comprehension of other, similar expressions in which different things are brought and different agents bring them. A considerable amount of research on language acquisition supports a view on which children build up an inventory of familiar linguistic expressions that can be generalized via pattern-matching\footnote{This sort of pattern matching is a clear example of the kind of similarity-based generalization discussed below. Note too that when children first acquire the ability to use multi-word expressions, these abilities are initially localized to specific constructions (e.g., those involving the verb ``to bring'') and then expanded in a somewhat piecemeal fashion \citep{Tomasello:2003,Tomasello:2005}. This strongly suggests that children are \textit{not} learning globally applicable rules that are infinitely generative.} and substitution to form related expressions \citep{Tomasello:2003}. The important point is that the items included in the inventory range from pure idioms (e.g., ``The cat's out of the bag'') to fairly abstract templates (e.g., \textit{X} gave \textit{Y} to \textit{Z}), with mixtures of the two in between (e.g. ``\textit{X} is a piece of cake!'') -- composition rules for combining word meanings into sentence meanings as per (1) and (2) do not enter in to the picture. 

More generally, there is a case to be made that composition rules are empirically inadequate in that they assign ``meanings'' to expressions that do not really mean anything in particular. Bizarre sentences of the sort considered previously are a case in point. In fact, observing that they are bizarre is just another way of observing that they have no linguistically mandated pragmatic significance. Whatever follows from the use of one these sentences also follows from the use of numerous other sentences of similar length containing similar words. For instance, nothing specific follows from the use of the sentence ``a round sleeping rectangle halts no stillness'' that doesn't also follow from the sentence ``no sleeping rectangle halts a round stillness''; at most, one might infer some topical regularity involving geometric objects in each case.\footnote{But notice that one can also infer a topical regularity involving, say, high-pitched squeaks in cases involving random noises that bear no resemblance to language. So the existence of topical regularity does not imply semantic interpretability.} Similar remarks apply to sentences containing vast numbers of iterated modifiers or iterated relative clauses. Large sets of these sentences are simply equivalent with respect their communicative significance, and this significance is furthermore so vague as to be non-existent. Given as much, it is debatable whether such sentences even belong to a language at all: there is nothing to explain about their use, so there is no reason to talk about what they mean. 

Overall, an analysis of the argument from productivity yields two broad conclusions. First, it is entirely clear that natural languages are infinitely productive. The kinds of expressions that are produced as evidence for this claim tend to be either bizarre or circularly generated by the very rules that are invoked to provide an explanation of infinite productivity. Second, even if languages are infinitely productive, compositional rules schemes tend to overgenerate by assigning meanings to expressions that cannot be used to communicate something. It is accordingly doubtful that the inference from the existence of vast numbers of linguistic expressions to the conclusion that natural languages are compositional is a good one. 

\subsection{The Argument from Systematicity}

The argument from systematicity is an inference to the best explanation of the fact that the ability to understand certain linguistic expressions systematically co-occurs with the ability to understand other expressions with the same structure \citep{FodorPylyshyn:1988,Szabo:2012,Szabo:2013,FodorLepore:2002}. To give an example, any person who understands the sentence ``the red truck is bigger than the blue car'' is also able to understand the sentences ``the blue truck is bigger than the red car'' and ``the blue car is bigger than the red truck''. These sentences are syntactically invariant with respect to one another, so on the assumption that a person is able to grasp the meaning of one of them through the application of set of composition rules, it follows that they will be able to grasp the meanings of all the others by applying the same rules under substitution of lexical items in a given grammatical class (i.e., substitutions of ``red'' for ``blue'' and ``truck'' for ``car''). Put another way, the principle of compositionality entails that the rules used to compute the meaning of one sentence with a given structure can also be used to compute the meaning of every other sentence with the same structure, via lexical substitution. Hence, the principle provides a natural explanation for why the ability to understand some sentences co-occurs with the ability to understand others. 

The first thing to note about this argument is that it assumes that the ability to understand \textit{one} sentence with a given structure always goes along with the ability to understand \textit{every} sentence with same structure and known lexical constituents. As Szabo (\citeyear{Szabo:2013,Szabo:2012}) points out, this is an empirical claim that might not be true. He suggests that an understanding ``red car'' and ``tall building'' might not suffice to ensure an understanding of ``red building'' and ``tall car'', since one could, for instance, have a sense of what counts as tall building without having any sense of what counts as a tall car (p. 87). Similarly, if the phenomenon underyling systematicity is real, then anyone who understands the sentences ``the log split'' and ``the temperature increased'' should also understand the sentences ``the temperature split'' and ``the log increased'', which is odd to say the least. As before, there is no linguistically mandated pragmatic significance associated with the use of such sentences.

The second thing to note about the argument is that it leaves room for the possibility that linguistic comprehension is systematic but not \textit{structurally} systematic. In other words, one can concede that the ability to understand some sentences goes along with the ability to understand others, but nonetheless propose that the grouping of co-comprehended sentences is determined on basis of something other than syntax. Proponents of systematicity typically just enumerate a few examples of intuitively co-comprehended sentences that happen to share their syntactic structure, and then draw the conclusion that \textit{all} structurally equivalent sentences containing familiar words are co-comprehended \citep[e.g.,][]{FodorPylyshyn:1988}. This is a rather bold inductive leap. It could just as easily be true that linguistic understanding is inferentially systematic, in the sense that understanding one sentence goes along with understanding other sentences that are inferentially related to it. Examples are quite easy to come by: anyone who understands the sentence ``the temperature increased'' is bound to understand the sentences ``the temperature is now higher'' and ``it is warmer than it was before'', amongst others. Furthermore, it is also possible that the co-comprehension of certain structurally identical sentences is simply a side-effect of such inferential systematicity. All of this is to say that considerations of systematicity do not provide a particularly good reason to think that languages are compositional as per (1) and (2) above. 

\subsection{Discussion}

It is undeniable that people are able to understand vast quantities of linguistic expressions, and it is also undeniable that the ability to understand some expressions tends to go along with the ability to understand others. But the supposition that natural languages are compositional does not provide a particularly good explanation of these facts. The problem is that people fall short of the comprehension abilities that compositional theories attribute to them. They cannot understand \textit{all} of the sentences produced by a generative syntax, and the fact that they understand one sentence with a given structure does not guarantee that they understand all sentences with the same structure containing familiar lexical components. However, even if our capacities for linguistic comprehension are more modest than is often assumed, it is still not clear that there are any plausible non-compositional explanations of their existence. It might be that a compositional explanation of our linguistic abilities is the best one available. 

To set the stage for alternative explanations, it is essential to give a proper characterization of the productivity and systematicity present in natural language. What arguments invoking these phenomena tend to miss is the fact that a ``language'' is an abstract description of a set of continually changing social practices that allow people to make sense of one another's behavior and engage in cooperative activity. To say that a language is productive is to say that these practices can be effectively generalized to cover all or most possible cooperative scenarios. To say that a language is systematic is to say that this generalization does not occur in a completely piecemeal fashion, or from one narrow practice to the next. When things are put this way, there is no apparent need to assume that such generalization occurs primarily on the basis of linguistic \textit{structure}, as proponents of the principle of compositionality tend to assume. It also becomes abundantly clear that problems concerning generalization are the fundamental ones, rather than problems concerning semantic composition per se.

\section{Three Kinds of Generalization}

To generalize is to ``go beyond'' what one has observed in the past so as to make predictions about some class of future events. A familiar example is the act of inferring or predicting that all of the marbles in a particular bag are white on the basis of observing some finite set of white marbles being drawn from the bag. Generalization is accordingly a form of induction, and therefore subject to all of the usual philosophical puzzles concerning this particular type of inference. From a mathematical perspective, however, generalization is a well-studied phenomenon. The fields of machine learning and statistics more broadly are concerned with the formalization of procedures for generalizing from past experiences to correct performance on future tasks \citep[][p. 6]{LiangPotts:2015}. While these procedures can vary substantially, they typically make use of a parameterized function that maps inputs to outputs, a set of examples of correct input-output pairs, and a method for adjusting the function's parameters such that it behaves optimally with respect to mapping each example input to the corresponding output.\footnote{I am restricting consideration here to \textit{supervised} machine learning. It also possible to perform \textit{unsupervised} learning, wherein only unlabelled training examples are used to estimate the model parameters. Count-based embedding models (described in Chapter 2) are examples of models that rely on unsupervised learning.} The goal of this parameter adjustment (i.e., learning) is to obtain a function that generalizes beyond the training examples to correctly map unseen inputs to their matching outputs. For instance, one might learn a function that maps from the bag a marble was drawn out of to a prediction about its colour. Thus, training examples in the form of bag-color pairs constitute prior experience that the learning procedure exploits to form a basis for making predictions about a class of future events. 

What kind of generalization is required for language use? I consider three non-exclusive possibilities in what follows. First, there is similarity-based generalization, which involves mapping a novel input to a particular output on the basis of its similarity to learned inputs. An example would be describing an animal as a horse on the basis of its similarity to other animals that are known to be horses. Second, there is syntactic generalization, which involves mapping a novel input to a particular output on the basis of a rule defined with respect to the input's structural form. An example would be a rule that maps $P \land Q$ to $P$ on the basis of the syntactic structure of conjunction \citep{FodorPylyshyn:1988}. Third, there is procedural generalization, which involves performing a novel sequence of actions to bring about some state on the basis of one's knowledge of how other action sequences bring about other states. An example would be figuring out how to mail a letter for the first time on the basis of one's knowledge of how to write on paper and one's knowledge of the location of a mailbox. 

Interestingly, the merits of the first two kinds of generalization have been discussed in a long-running debate concerning the relative plausibility of classical and connectionist cognitive architectures \citep{FodorPylyshyn:1988,SmolenskyLegendre:2006}. On the classical side, it is claimed that humans routinely learn \textit{universal} generalizations from very limited amounts of data \citep{Hadley:2009,Marcus:1998}. It is further claimed that neural networks, unlike symbol systems, are fundamentally incapable of learning such generalizations. Therefore, neural networks are inadequate as models of human linguistic abilities. Symbolic models that exhibit syntactic generalization and postulate mental rules analogous to (1) and (2) are to be favored instead \citep{FodorPylyshyn:1988}. On the connectionist side, it is claimed that the limits on generalization in neural networks are grossly overstated. It also claimed that neural networks can learn to approximate or implement the kinds of structural rules that are given so much weight by classical theorists \citep{Plate:2003,SmolenskyLegendre:2006,Eliasmith:2013,Rasmussen:2011,Gayler:2004}. Finally, connectionists often argue that similarity-based generalization is a robust feature of human cognition that cannot be easily accounted for in symbol systems \citep{McClelland:2010}. 

Given the relevance of this debate, I will use it to frame the subsequent discussion of different kinds of generalization. Specifically, I illustrate how typical neural networks generalize on the basis of similarity relations in their input space, while typical symbol systems generalize on the basis of the structural properties of their inputs.\footnote{Though it is worth noting that certain kinds of neural networks are demonstrably capable of generalizing on the basis of input structure \citep{Rasmussen:2011,Eliasmith:2013}} I then introduce the concept of procedural generalization, which is distinct from both similarity-based and syntactic generalization. The point of introducing this new and important form of generalization is to set the stage for a positive account of our linguistic abilities that explains certain structure-sensitive features of language use in terms of procedures that can be implemented in a neural network. These procedures importantly do \textit{not} make use of rules for manipulating discrete symbols. As such, the positive account I go on to develop invokes procedural and similarity-based forms of generalization to explain how people are able to ``interpolate'' between familiar inferential transitions, and thereby comprehend the meanings of a wide range of novel linguistic expressions.

\subsection{Similarity-Based Generalization}

To generalize on the basis of similarity, it must first be possible to treat things that could fall under the scope of a generalization as alike and unalike to varying degrees. From a formal perspective, the mathematical structure of a vector space offers a well-defined means by which to allow for such similarity measurements, typically via the inner product of two vectors. Efforts to exploit similarity-based generalization in models of cognitive and linguistic phenomena accordingly tend to makes use of algebraic operations defined over vector spaces. Artificial neural networks are perhaps the best known examples of such models, and a more detailed examination of them can accordingly be used to explain the benefits and drawbacks of similarity-based generalization.

A standard feedforward neural network is a parameterized function that maps vectors in some input space $R^m$ to vectors in some output space $R^n$. The purpose of learning is to find a set of parameters (i.e., weights in the network) that computes the correct mapping between all vectors in $R^m$ and $R^n$. In typical classification tasks, the inputs are continuous feature vectors, and outputs are binary label vectors. Similarities between pairs of input vectors are often defined in terms of the cosine of the angle between them.\footnote{This cosine measure is equivalent to the inner product of two vectors both normalized to unit length.} The same is true for pairs of output vectors. When a new input is presented to the network, it will often be mapped to the same output as some learned input to which it is highly similar. 

The key to properly understanding generalization in a neural network lies in the observation that \textit{every} possible weight configuration defines a function whose domain is $R^m$ and whose codomain is $R^n$. In other words, regardless of how a network's weights are set, the mapping it defines generalizes to cover the entire input space. So the issue is not whether a neural network can generalize, but rather whether it can generalize correctly on the basis of available training data. 

A number of commentators are skeptical. Marcus (\citeyear{Marcus:1998}), for instance, describes several learning scenarios in which it is impossible for a typical neural network trained via backpropogation to acquire a particular universal generalization that humans latch on to quite easily. The simplest scenario is one that involves learning the identity function over five digit binary strings (see pp. 260-63). If the training examples of this function are all such that one of the digits has a constant value (e.g., $0$), a neural network is incapable of learning to correctly compute the identity on strings containing the opposite value. So, if all of the training examples are of the form $01010 \mapsto 01010$, $11110 \mapsto 11110$, $01000 \mapsto 01000$, etc., and a $1$ never occurs as the final digit, the network will never learn to extend the identity function to include any mappings of the form $01011 \mapsto 01011$ and $11111 \mapsto 11111$, where a $1$ occurs as the final digit. 

The reason for this inductive failure is that, by hypothesis, the network has never been exposed to any training examples with a $1$ in final digit position. The network is accordingly never provided with evidence to suggest that this final digit should be ever be anything other than a $0$. But as any reader of Wittgenstein (\citeyear{Wittgenstein:1953}) or Kripke (\citeyear{Kripke:1982}) will be quick to observe, it is not clear that the network has made an error, since the nature of the true function being approximated is under-specified with respect to the available evidence.\footnote{Note that we have just stipulated the true function, and this stipulation is by no means apparent in the training data.} The problem, as Marcus notes, is that \textit{people} effortlessly extrapolate from a few training examples of the sort just described to apply the identity function to every possible five digit binary string. Given as much, it seems clear that people have generalization abilities (or inductive priors) that typical neural networks fundamentally lack.

Similar examples involving linguistic expressions can also be enumerated. For example, Marcus describes a simple experiment in which a recurrent neural network is trained to predict the next word after every word in a sentence. The training sentences are simple identity statements like ``a rose is a rose'' or ``a tulip is a tulip'' (p. 263). If, after training, a statement involving a completely novel word is presented to the network (e.g., ``a blicket is a $\rule{0.75cm}{0.15mm}$''), the network will fail to predict the appropriate continuation (i.e., ``blicket''). Again, people do not exhibit this sort of inductive failure -- they readily complete identity statements involving novel words. One might complain that humans possess all sorts of prior knowledge concerning syntax and word meaning that, if encoded in the network, would enable it to correctly complete these problematic identity statements. However, Hadley (\citeyear{Hadley:2009}) attempts to deflect this objection by considering linguistic input-output mappings that contain nonsense words arranged in accordance with an arbitrary syntax. For example, the training set might consist of the following mappings (p. 518):

\vskip 0.12in
\begin{tabular}{l l} 
Input: \textit{biffle biffle rose zarple}  & Output: \textit{rose zarple} \\
Input: \textit{biffle biffle frog zarple } & Output: \textit{frog zarple} \\
Input: \textit{biffle biffle dog zarple} & Output: \textit{dog zarple} \\
\end{tabular} 
\vskip 0.12in

\noindent
The task is to generalize this pattern to a novel input such as \textit{biffle biffle quoggie zarple}, where the correct output is \textit{quoggie zarple}. Humans can complete this task easily, while typical artificial neural networks cannot. The lesson Hadley draws here is that a hallmark of human intelligence is the ability to rapidly create variables that can be manipulated without regard to their value. In the cases above, the relevant variable is the sequence position that is occupied by the words \textit{rose}, \textit{dog}, and \textit{frog}. The relevant manipulation is to repeat the value of the variable to produce the desired output. Neural networks, according to Hadley (\citeyear{Hadley:2009}) are unable to rapidly create and deploy variables in this manner, and hence cannot account for the ways in which humans induce universal generalizations from sparse data.

Interestingly, it has recently been shown that exact input-output mappings introduced by Hadley can be learned by neural network models that make use of VSAs of the sort described in Chapter 2 \citep[][pp. 269-72]{Eliasmith:2013}. But such counterexamples aside, it is worth examining why the arguments of Hadley and Marcus seem to be so persuasive. Neural networks generalize by interpolating between known input-output mappings. Vectors that are similar to one another in the input space accordingly tend to get mapped to similar points in the output space.\footnote{This is a slight oversimplification, since neural networks can also be be trained to map very similar inputs to very different outputs. However, many more training examples are required correctly learn the overall input-output function in such cases.} So the drawback of methods that rely on similarity-based generalization is that, in order to be effective, they require training data that covers every possible region in the input space. To oversimplify somewhat, these methods generalize \textit{locally}, in the sense that what is learned from a particular training input is only extended to novel inputs that occupy a relatively small surrounding area in the input space. Problems of the sort described by Marcus and Hadley, in comparison, require methods that generalize \textit{globally} over the entire input space.\footnote{Or, alternatively, methods for representing the space that allows local generalization to produce the desired input-output mappings} For example, the identity mapping applied to one point in the space is the same mapping that ought to be applied to every other point in the space, hence a model must extrapolate beyond the local neighborhoods around each training item in order to learn the mapping successfully.\footnote{There is nothing special about the use of the identity function in this discussion. Functions that swap the first and last bit in a binary string or reverse the words in a sentence would work just as well.}

\subsection{Syntactic Generalization}

Syntactic generalization involves inducing rules that map inputs to outputs in a structure-sensitive manner. A structure-sensitive operation, to explain, is one that maps an input to an output strictly on the basis of its syntax or form. A standard example of this kind of operation is the elimination rule for conjunction, wherein an input of the form $P \land Q$ is mapped to the output $P$, for all possible values of $P$ and $Q$ \citep{FodorPylyshyn:1988}. 

The first point to note about this kind of mapping is that it is completely insensitive to content of the inputs over which it is defined. So, if the mapping works for any conjunction, it works for all of them, and the kind of generalization that is thereby achieved is \textit{global} in the sense defined above. The second point to note is that the identity function is a trivial structure-sensitive operation of the form $P \mapsto P$, for all values of $P$. So, the examples above that ostensibly pose problems for certain neural architectures are naturally handled within a symbolic framework \citep{Hadley:2009,Marcus:1998}. The third point to note is that the inference rules that enable generalization in symbol systems all exploit variables in some way, as is illustrated by the use of abstract sentence letters such as $P$ and $Q$. It has been proposed that, implementationally, these variables correspond to memory registers, while variable values correspond to the contents of memory registers \citep{Marcus:1998}. Operations are then defined in terms of different methods for manipulating registers by, for example, copying, comparing, or adding their contents. It is because these operations are defined with respect to variables (i.e., memory registers) rather than values (i.e., register contents) that they are considered to be structure-sensitive or syntactic.

One interesting feature of syntactic generalization is that it is essentially a species of deductive inference. To illustrate, the goodness of the inference from $P \land Q$ to $P$ is guaranteed on structural grounds alone. One is forbidden from concluding from $P \land Q$ that $P$ is false. Similarly, if one generalizes the mapping $01010 \mapsto 01010$ to the mapping $11111 \mapsto 11111$ on structural grounds (i.e., by identifying an underlying rule of the form $P \mapsto P$, one is forbidden from countenancing further mappings that deviate from this pattern (e.g., $10011 \mapsto 11011$). The key point here is that generalizations and inferences made on the basis of structure do not permit exceptions: they are \textit{universal} in that they apply to all tokens of a given structural type. This is a potentially significant problem. For one thing, it becomes difficult to account for non-universal or probabilistic generalizations, which are the rule rather than the exception in linguistic domains \citep{SmolenskyLegendre:2006,ChaterManning:2006,Manning:2015,Seidenberg:1997}. For another thing, it becomes difficult to account for inductive generalizations, which cannot be defined in a purely structural manner. There is, for instance, no structural rule for inferring a universal generalization inductively through an enumeration of examples. The lesson here is that syntactic approaches to generalization are not necessarily panacea in comparison to similarity-based approaches. 

\subsection{Procedural Generalization}

In the case of both similarity-based and syntactic forms of generalization, the method by which inputs are mapped to outputs is fixed upon the completion of learning (or programming). However, it is doubtful that our linguistic abilities can be accounted for in terms of a set of static input-output mappings. To \textit{use} language in a productive fashion, one has to be able to do different things in different situations. For instance, effective participation in a conversation involves asking questions, issuing imperatives, answering questions, along with a variety of other tasks. The operations involved in such tasks (i.e., operations for issuing imperatives, answering questions, etc.) have to be strung together in the right way.\footnote{Note that the operations themselves can involve internal generalizations that are either syntactic or similarity-based. For instance, one might generate a sentence that follows from a novel sentence on the basis of either similarity to known sentences or on the basis of a structural rule.} For instance, one cannot sustain a conversation by responding to every sentence with some further sentence that follows from it. One has to know when and \textit{when not} to ask, answer, and instruct. Moreover, one has to know all of this by generalizing from past conversations involving complex sequences of questions, statements, and instructions. Procedural generalization accordingly involves generalizing from known sequences of operations (i.e., procedures) to novel sequences of operations in an appropriate manner.
 
Given this way of looking at things, it can be appealing to think of procedural generalization as a kind of meta-generalization. This is true to an extent, but also somewhat misleading. Procedures can by defined at a variety of different levels of abstraction, and there is no in-principle obstacle to postulating sub-sentential procedures in addition to sentential procedures of the sort just discussed (i.e., those that involve the drawing of inferences). For instance, one can think of parsing a sentence into a dependency tree in terms of procedural generalizations that enable a parsing algorithm to execute distinct sequences of operations for distinct sentences. Similarly, one can think of memorization tasks in terms of procedural generalizations that enable one to select different items to commit to memory in different contexts. Memorizing every second item in a list, for instance, involves a different a procedure than memorizing every third item.

There are a number of possible ways in which procedural generalization might be implemented. One idea is to assimilate it to a kind of syntactic generalization by identifying different procedures with the behavior of an algorithm or program that responds differently to different inputs. For instance, a simple program that reverses every string in a list implements a kind of procedural generalization based on syntactic structure, since different sequences of operations will be executed on different input lists (i.e., the length of the list and the strings it contains can vary), and since the precise sequence in question is determined by the structure of the input and not its content (i.e., the specific characters in each string do not matter). Another idea is to assimilate procedural generalization to a kind of similarity-based generalization by identifying different procedures with the different behaviors of a system that goes through a set of state transitions that are determined by the similarity between its current state and some set of ``transition-triggering'' states. For instance, a recurrent neural network used to decode a sentence from a distributed representation undergoes a series of a state transitions to produce a sequence of words, and the transitions in question are determined by similarity relations within the network's state space. The number of transitions, moreover, is determined by the initial state of the network.

In what follows, I adopt this latter, similarity-based characterization of procedural generalization, primarily because it is consistent with the probabilistic and non-categorical nature of many of the regularities present in linguistic behavior \citep{Seidenberg:1997,Manning:2015}. To explain, it is difficult to come up with a rule-based algorithm that accurately characterizes the various procedures and action sequences involved in competent language use. It is much easier to appeal to ``family resemblances'' amongst procedures to show why, for instance, one who knows how to ask for a refreshment is also likely to know how to ask for directions.

Assimilation strategies aside, there is also a sense in which procedural generalization is a unique form of generalization, since it involves generalizing from some multi-step procedures to others, rather than generalizing from some input-output mappings to others. Given its importance, it is interesting to note that procedural generalization is rarely discussed in the literature (with the possible exception of work on reinforcement learning\citep[e.g.][]{Mnih:2015,Eliasmith:2012}). A plausible reason for this lack of discussion is that neither connectionists nor classicists have introduced many concrete proposals for describing the sophisticated procedures that underlie high-level lingusitic behavior. Providing an account of procedural generalization is accordingly a challenge for everyone. 

\section{Generalization with Inferential Roles}

So far, I have considered three ways in which one might generalize from the use of familiar linguistic expressions to the use of unfamiliar ones. With these options in mind, it is possible to consider whether an inferential role semantics is compatible with the kind of generalization that underlies competent language use. Could someone acquire the ability to draw appropriate inferences using \textit{all} of the expressions in a given language by learning to draw appropriate inferences involving \textit{some} of these expressions? To answer this question, I will consider similarity-based, syntactic, and procedural strategies for explaining the generality of our linguistic abilities.

It is fairly straightforward to sketch out a version of the similarity-based strategy. If an individual has learned that a particular sentence licenses particular inferences, then they should be able to grasp that similar sentences license similar inferences. For instance, anyone who can infer ``The animal has four legs'' from ``The animal is a healthy cat'' should also be able to infer ``The animal has four legs'' from ``The animal is a healthy dog,'' on the assumption that ``The animal is a healthy cat'' and ``The animal is a healthy dog'' are similar sentences. The obvious drawback to this approach is that the notion of ``similarity'' that is doing all of the work needs to be explicated. Sentences can be alike and unalike to various degrees and in various ways, which makes it difficult to predict exactly which inferential involvements a given pair of sentences will share with one another. One motivation for introducing the statistical techniques discussed in the previous two chapters is to induce an appropriate similarity relation from examples of how sentences are distributed as premises and conclusions in the space of possible inferences.

The syntactic strategy, in comparison, involves defining rules that manipulate a sentence on the basis of its structural form to yield further sentences that follow from it. If an individual has learned a sufficient number of ``transformation rules'' for converting premise sentences into conclusion sentences, then they have learned all that they need to know in order to draw correct inferences using completely novel sentences. For instance, anyone who can infer ``He walks'' from ``He walks and he talks'' should also be able to infer ``She sings'' from ``She sings and she dances,'' given that same inference rule is being applied in each case (i.e., conjunction elimination). The problem with this strategy is that it involves deriving inference from meaning, rather than vice versa. To explain, formal rules of inference function to preserve certain semantic properties of the sentences to which they apply.\footnote{Typically, the rules preserve the semantic property of truth. Whether a sentence has this property depends on (a) what it means, and (b) the way the world is.} These semantic properties are therefore explanatorily prior to the inference rules, contra the claim that a sentence's meaning is constituted by its inferential role. So, insofar as structure-sensitive rules are used to explain how people generalize from the use of familiar linguistic expressions to the use of unfamiliar ones, they cannot be rules that are defined in relation to the meanings of the sentences to which they apply. If they are, then one has simply given up on inferentialism. 

The procedural strategy, finally, involves invoking sequences of operations or actions that mediate between a sentence's inferential consequents and antecedents. If an individual has learned how to do various things with a sentence, such as identify what follows from it and what it rules out, then they have arguably learned what they need to know in order to do related things with novel sentences. For instance, if one is able to justify the claim that ``The mouse is alive'' by explaining that ``It is breathing,'' then one ought to be able to go through the process of justifying further claims by invoking their inferential antecedents in a similar way. It is important to note that such a process need not involve a rule defined with respect to a sentence's syntactic structure; rather, the process can involve an implicit pattern of behavior or cognitive activity \citep{Brandom:1994}.\footnote{Another way to put the point is to say that the procedural strategy involves explaining the generalization that underlies language use in terms of implicit abilities rather than explicit rules of inference. It is accordingly a strategy that fits well with the sort of pragmatism that analyzes what people believe, think, and mean in terms of what they \textit{do} \citep{Brandom:2011,Brandom:1994,Misak:2007,Misak:2013}}. A main drawback of adopting this strategy is that the notion of a ``procedure'' needs to be explicated. The model described in the previous chapter addresses this problem by describing encoding and decoding procedures that mediate between a sentence and its inferential consequences. 

Given these assessments, I think that a combination of the similarity-based strategy and the procedural strategy is best suited to explain how we are able to draw appropriate inferences using vast numbers of novel linguistic expressions. To see why, it is helpful to briefly revisit the IPA framework. At bottom, the framework gives explanatory priority to human behavior that involves producing and responding to sounds and gestures. To talk of the meaning of these sounds and gestures is to make explicit the role they play in the informal calculus that constitutes intentional interpretation. People make sense of one another through attributions of ``sentential attitudes,'' and the significance of these attributions is determined by the inferential roles of the sentences in question. Thus, the direction of explanation is importantly top-down, in that sentence meaning takes priority over word meaning. Words are to be understood in terms of their effects on the inferential roles of sentences, and these effects are to be codified in terms of inferential relations amongst sentences that are substitutional variants of one another \citep{Brandom:1994}. More importantly, the framework describes the meanings of linguistic expressions in terms of how people rely on them to predict and control the trajectory of a conversation. Using a language involves exercising certain linguistic abilities, and these abilities are naturally generalized by doing similar things in similar situations.\footnote{As a point of comparison, think of how a dancer make similar moves when doing the same dance with different partners, or how a baseball player makes similar moves when throwing to first on different plays.}

If the inferential role semantics that emerges from the IPA framework is formalized in terms of procedures defined over continuous vectors, it is possible to generalize this semantics over an entire language by ``interpolating'' between familiar examples of correct inferential transitions. Interpolation is achieved by exploiting similarities between the procedures that are used to generate the inferential transitions, along with similarities between the states over which these procedures are defined. Consider the encoder-decoder model described in Chapter 3. The model clearly generalizes on the basis of similarity, since similar sentence embeddings yield similar inference chains, and similar lexical embeddings have similar substitutional effects on the embeddings corresponding to the sentences in which they occur. To illustrate, suppose the model has been trained to infer ``A person is outside'' and ``A person is moving'' from ``A man is walking in the park.'' Suppose further that the model has never been exposed to the sentence ``A child is running through the cornfield.'' If the model is sufficienty familiar with the structure of the space of reasons to substitutionally assimilate ``child'' to ``man,'' ``running'' to ``walking,'' and ``park'' to ``cornfield'' with respect to their inferential significance, then model will be able generalize certain entailments from the sentence ``A man is walking in the park'' to the sentence ``A child is running through the cornfield.''\footnote{Of course, the assimilations just described do not extend to cover all possible inferences. For instance, the substitution of ``running'' for ``walking'' can change whether or not the sentences ``A person is moving quickly'' and ``A person is moving slowly'' have the status of entailments. Substitutional assimilation is accordingly context-dependent.} The results described in Chapter 3 illustrate how this kind of similarity-based generalization works in practice.

However, in the cases just considered, the procedure the model uses to generate each entailment is fixed, since the same syntactic description applies to each input sentence (i.e., ```A man is walking in the park'' and ``A child is running through the cornfield'' share identical dependency parses). When the model is confronted with a syntactically novel input sentence, it generalizes to a novel procedure for generating an inferential transition by utilizing a new encoding tree. To illustrate with an example, suppose that the model has been trained on inferential transitions involving input sentences with relative clauses attaching to either the subject of the main verb (e.g., ``The \underline{dog that barks} ran away.'') or its object (e.g., ``He chased the \underline{cat that meows}.''), but never both at the same time. Now suppose that ``The dog that barks chased the cat that meows'' is presented as an input sentence. To produce an embedding for this sentence, the model simply re-uses portions of the procedures involved in processing the training sentences (i.e., the portions corresponding to the phrases ``the dog that barks'' and ``the cat that meows,'' respectively). There is accordingly an important sense in which the unfamiliar procedure is \textit{similar} to the familiar ones. It is possible to quantify this degree of similarity by looking at the number of familiar subtrees in the encoding tree corresponding to the novel sentence.\footnote{These trees, recall, are descriptions of the process by which a sequence of word embeddings are transformed into a sentence embedding.} Again, the results described in Chapter 3 illustrate how this kind of procedural generalization works in practice. 
 
Insofar as this discussion of the encoder-decoder model is persuasive, it is plausible that a combination of procedural and similarity-based generalization is sufficient to explain how people are able to draw appropriate inferences using vast numbers of novel linguistic expressions. One might nonetheless worry about handling phenomena of the sort discussed by Marcus (\citeyear{Marcus:1998}) and Hadley (\citeyear{Hadley:2009}). One might also worry about handling more sophisticated linguistic phenomena, such as those that involve conversational turn-talking and or the resolution of anaphoric dependencies. However, identifying these limitations just points out the obvious: the model falls short of replicating the functional properties of a fully competent language user. All models fall short of this standard, so the real question is whether some further ingredient needs to be added to our stock of modelling materials.

I think the answer is no. To see why, it is necessary to first notice that a common feature of the phenomena under consideration is that they involve the use of \textit{memory}. The tasks described by Hadley (\citeyear{Hadley:2009}) and Marcus (\citeyear{Marcus:1998}), for instance, involve remembering something (e.g., the nonsense word ``blicket''), and then later repeating it. The task of participating in an extended dialogue similarly requires remembering what has already be said, at least in outline, and then responding appropriately. There are good reasons to think that the generalizations involved in these novel uses of memory or are either similarity-based or procedural. In the case of dialogue, for example, it is plausible to invoke cognitive procedures that selectively update the state of a memory over the course of a conversation, and then exploit this memory to produce an appropriate response to the most recent ``move'' in the conversation. Likewise, in the case of anaphoric dependencies, it is plausible to invoke procedures that update the state of a memory, and then exploit this memory to substitute or link the occurrences of pronouns in new sentences with their anaphoric antecendents. The obvious way to implement these procedures involves coupling a neural network to an external memory that can be written to and read from while the network carries out a particular task \citep{Weston:2016,Weston:2015,Sukhbataar:2015,Eliasmith:2012,Graves:2014}. With such a system, it is straightforward to handle the phenomena discussed by Hadley (\citeyear{Hadley:2009}) and Marcus (\citeyear{Marcus:1998}), as Eliasmith (\citeyear{Eliasmith:2013}) illustrates. 

The obvious objection here is that the procedures I am describing seem to require the existence of purely formal inference rules that operate on symbol structures. To explain, a procedure that takes some input, stores it in memory, and then retrieves it as output can be thought of as simply implementing the formal inference rule $P \mapsto P$. The problem with this objection is that it mistakenly conflates the ability to apply formal rules of inference with the ability to remember and repeat things. Claiming that people are capable of remembering and repeating things is clearly \textit{not} equivalent to claiming that people apply formal transformations to symbolic representations. Moreover, there is simply no need to invoke formal rules of inference to account for the interplay between memory and language use. It is demonstrably possible to define procedures that realize the kind of phenomena emphasized by Hadley and Marcus without relying on explicit rules defined over discrete symbol structures. For example, memory networks of the sort described in the previous chapter allow for continuous ``read'' and ``write'' operations to be performed using a memory that stores a series of embeddings \citep{Sukhbataar:2015,Graves:2014}. Likewise, neuro-computational models of the sort described by Eliasmith et al. (\citeyear{Eliasmith:2012}) make use of an action selection system that can copy, compare, and add items without directly employing symbolic rules. Given these examples, it is somewhat misleading to treat the mind as a ``syntactic engine'' of the sort described by Fodor and Pylyshyn (\citeyear{FodorPylyshyn:1988}).

To be clear, I am arguing that the phenomena introduced by Marcus (\citeyear{Marcus:1998}) and Hadley (\citeyear{Hadley:2009}) are best explained by invoking informal procedures rather than formal rules of inference. My reasons are twofold. First, formal rules of inference are explanatorily superfluous, as the previous paragraph illustrates. Second, such rules presuppose a non-inferential semantics precisely because of their formality; the rules \textit{act on} meanings rather than help constitute them. Non-formal procedures, in contrast, implement the implicit abilities that a system must possess in order for its behaviors to be semantically interpretable in the first place. These procedures can be implemented using neural networks, and they can generalize to account for various inferences that are typically explained in terms of formal operations on symbol structures. To invoke the ``structure'' at play in a structure-sensitive inference is to invoke an implicit feature of an underlying procedure rather than an explicit feature of a representational state. 

Granted, the model uses syntactically guided compression and decompression operations to transform word embeddings into sentence embeddings and vice versa, but it is quite clear that these operations do not produce semantically interpretable objects of the sort that result from composition rules like (1) and (2). Overall, the role of syntax in the model is in line with Christiansen and Chater's (\citeyear{Christiansen:2015}) view of syntactic structure as a description of a sentence's processing history.


Overall, the point of this discussion is to illustrate that the generalization abilities characteristic of linguistic competence can be well accounted for without the postulation of purely formal rules of inference of the sort typically thought to be required for syntactic generalization. The bearing of these conclusions on the claim that natural languages are compositional is investigated in the next section.  

\section{Is Natural Language Compositional?}

At the outset of this chapter, three assumptions associated with the principle of compositionality were highlighted: that word meaning is prior to sentence meaning; that meanings are entities; and that semantic interpretation is rule-based. All three of these assumptions have proven doubtful: inferential relations amongst sentences are primary, and indirectly confer meanings on words; meaning talk is talk of what follows from what, or of inferential relations amongst sentence types; and the ``rules'' that govern what follows from what are not rules at all -- they are soft, probabilistic constraints that can be encoded into the parameters of a neural network. 

While certainly suggestive, these considerations do not directly answer the question of whether natural language is compositional. It is accordingly helpful to examine the relationship between the principle of compositionality and the inferential role semantics defined by the encoder-decoder model. At first glance, there is a clear sense in which the model makes use of ``composition functions'' that assign embeddings to complex linguistic expressions on the basis of the embeddings assigned to their simpler parts. One might even take these composition functions to instantiate rules like (1) and (2). If so, then it seems safe to conclude that the model operates in accordance with the principle of compositionality. 

There are, however, two features of the model that belie this straightforwardly compositional interpretation of its behavior. The first feature is that the model never explicitly assigns ``meaning entities'' to the expressions it manipulates. The embedding corresponding to sentence, for instance, is not something from which one can directly ``read off'' a meaning. Rather, an embedding is something that can only be understood in terms of the role that it plays in mediating the behavior of the system in which it resides. This is an important point. It illustrates that the model is best thought of as a description of the practical abilities a system must exhibit in order to count as understanding certain linguistic expressions. Thus, in the spirit of Brandom's (\citeyear{Brandom:1994,Brandom:2011}) pragmatism, the model makes explicit what one has to be able to \textit{do} in order to \textit{understand} what an expression means. 

The second key feature of the model is that the embeddings it manipulates lack explicit constituent structure. A sentence embedding, for instance, is not a ``whole'' that is comprised of ``parts'' corresponding to individual word embeddings \citep{Eliasmith:2013}. One consequence of a lack of part-whole structure is that it is misleading to think of an embedding as a complex representation literally composed out of simpler ones. Another consequence is embeddings cannot be manipulated by purely formal inference rules, since such rules operate on part-whole structures by definition. As such, embeddings of the sort manipulated by the encoder-decoder model are not at all like the entities assigned to linguistic expressions by proponents of the principle of compositionality.

One might nonetheless say that natural language is ``procedurally compositional'' in the sense that the procedures that underlie linguistic comprehension (in my model at least) are made up of component parts that get re-used in novel situations. To give one example, the embedding corresponding to an individual word gets re-used every time the model is used to generate entailments for a novel sentence containing this word. To give another example, the weight matrix associated with a particular syntactic dependency gets re-used every time the model propagates activities through a novel tree that includes this dependency. One might be tempted to think that such re-use of components is in accord with the principle of compositionality. But if so, then the principle is arguably of no special linguistic interest. A motor control system, for instance, would count as compositional by this standard in virtue of the fact that it re-uses certain joint angles and muscle torques when producing novel motions. Given that most philosophers and linguists would not treat motor control as compositional, it's clear that they have something different in mind than mere generalization through re-use. Specifically, they have in mind the creation of structured objects consisting of parts and wholes.\footnote{As a point of further comparison, note the oddity of treating the motion of, say, an arm as a ``structured object'' consisting of parts corresponding to various joint angles, muscle torques, and spatial co-ordinates in the arm's trajectory. For what it's worth, I take language use and motor control to be procedurally compositional in roughly the same way.} For reasons already rehearsed, it is not clear that structured objects of this kind are needed to explain language use.

It is worth revisiting the debates about productivity and systematicity in light of these remarks. In the case of productivity, it is fairly clear that a language processing system that re-uses certain basic components and procedures can productively handle vast numbers of expressions. The encoder-decoder model, for instance, productively generates entailments for all input sentences that can be generated using a known vocabulary of lexical items. Granted, the model does not generate \textit{correct} entailments for all input sentences, but this may in fact be a source of strength. Recall that in my discussion of the argument from productivity, I observed that not all well-formed sentences have a linguistically mandated way of being understood. For example, the sentence ``Your peak is fuming'' has no definite meaning that every competent language user can immediately identify. Rather, people form hypotheses or ``best guesses'' about what is meant by an utterance of this sentence. So, insofar as the model produces reasonable ``best guesses'' concerning the inferential consequences of atypical sentences, it is \textit{as productive as a compentent langauge user}.\footnote{I am not arguing that my model actually achieves this level of productivity}

In the case of systematicity, any system that operates in accordance with procedures that map linguistic expressions onto one another is bound to be systematic to a certain degree. Even in a degenerate case where only one such mapping is computed, there is a systematic relation between what the input expression is followed \textit{by} and what the output expression follows \textit{from}. Take, for instance, a system that is only capable of making the inference from ``It is raining'' to ``The streets are wet'' \citep[][p. 313]{Sellars:1954}. On the assumption that meaning ought to be characterized in terms of inference, it is quite clear that understanding somethings about the first sentence requires understanding something about the second one, too. Specifically, if one understands that ``It is raining'' entails ``The streets are wet'', then one cannot help but grasp that ``The streets are wet'' is entailed by ``It is raining''. Again, the model in Chapter 3 reflects this systematicity despite not operating in accordance with the principle of compositionality. An inferential network of the sort depicted in Figure \ref{chain}, for example, is clearly systematic in that it simultaneously defines the inferential roles of numerously linguistic expressions. The ability to navigate one these roles, moreover, cannot be separated from the ability to navigate others. 

The overall point of these observations is to provoke a shift from thinking about representational \textit{states} that encode sentence meanings as structured objects to thinking about inferential \textit{processes} that mediate between a sentence's antecedents and consequents. This process-based approach to thinking about language use and linguistic cognition is not compatible with standard formulations of the principle of compositionality, on which complex ``meanings'' are built up out of simpler ones. The approach is, however, compatible with a looser notion of compositionality on which certain procedures get re-used when determining the inferential consequences of novel linguistic expressions. This loose notion of compositionality is compatible with as much productivity and systematicity as there actually is in natural language. 

\section{Conclusion}

As a point of comparison for the view I am offering, it is useful to imagine a perfectly \textit{non}-compositional language. Such a language would consist of an enormous number of unique expressions that are all akin to Wittgenstein's (\citeyear{Wittgenstein:1953}) one-word signals of ``Slab!'' and ``Beam!'' It goes without saying that such a language would be horribly inefficient and nearly impossible to learn, since every new expression would have to be memorized in rote fashion. Language use would thus pose a significant cognitive burden. The point of introducing sub-sentential structure into linguistic expressions is to reduce this burden by assimilating expressions with respect to shared features of their communicative significance. For example, the point of repeating the word ``slab'' in ``Bring two slabs'' and ``Bring him a slab'' is to exploit a redundancy in the communicative significance of these sentences -- both are \textit{about slabs}. 

There is, however, a significant gap between the claim that languages are structured to exploit communicative redundancies and the claim that languages are compositional in the sense codified by (1) and (2). I have argued that there is no need to bridge this gap. For example, the sentences ``Bring two slabs'' and ``Bring him a slab'' mean similar things because they involve shared words that can be manipulated using shared procedures to form certain predictions. To learn a language, one needs to learn how to draw appropriate inferences using large numbers of novel expressions. The key challenge, then, is learning to generalize from from the use of familiar linguistic expressions to the use of unfamiliar linguistic expressions. My strategy for solving this generalization problem is fairly straightforward: by examining the distribution of sentences as tacit ``premises'' and ``conclusions'' in a space of inferences, one can isolate syntactic and lexical redundancies in these sentences (i.e., patterns that show up in numerous inferential contexts). These redundancies can then be exploited to assign a distributional profile in the space of inferences to novel sentences.  The model in Chapter 3 is a clear application of this strategy, and insofar as the model generalizes successfully, it provides evidence that the strategy works. 

Overall, the key claim I am making is that debates about the principle of compositionality are really about generalization rather than semantic composition per se. The generalization that is characteristic of language use, moreover, involves re-applying simple procedures for processing lexical items so as to draw appropriate inferences from the sentences in which these lexical items occur. In the model in Chapter 3, such procedures involve compressing word embeddings into sentence embeddings, and decompressing sentence embeddings into word embeddings. Generalization is achieved on the basis of (a) similarities between word embeddings, and (c) similarities between the procedures used to manipulate these word embeddings (i.e, the procedures described by dependency parses). Put more simply, generalization occurs on the basis of similarities between the lexical items that occur in sentences, and between the syntactically-guided procedures used to manipulate these items to generate certain predictions. Generalization does \textit{not} occur on the basis of formal rules of inference that operate on symbol structures comprised of parts and wholes. So, if this model is anything to go by, natural language is not compositional in anything like the way that theorists typically assume. 