%----------------------------------------------------------------------
% MAIN BODY
%----------------------------------------------------------------------

%======================================================================
\chapter{Intentional Interpretation and Cognitive Architecture}
%======================================================================
\renewcommand{\epigraphrule}{0pt}
\setlength{\epigraphwidth}{4.5in}
\epigraph{\textit{It is not that we attribute (or should attribute) beliefs and desires only to things in which we find internal representations, but rather that we find some object for which the intentional strategy works, we endeavor to interpret some of its internal states and processes as representations. What makes some internal feature of a thing a representation could only be its role in regulating the behavior of an intentional system.}}{- Daniel Dennett, 1987}

\section{Introduction}

A common view of the relationship between thought and language, often traced back to Locke \citep{Brandom:1994,KortaPerry:2015}, is that linguistic expressions are like vessels that transport ideas from one mind to another. Speaking involves encoding a thought into a sentence, and understanding what was spoken involves decoding a sentence back into the corresponding thought. A widely appreciated consequence of this model of communication is that the meanings of linguistic expressions are parasitic on the meanings of the mental states they are used to express. Attempts to deal with this consequence have resulted in a substantial literature on the semantics of mental representations \citep{Fodor:1998,Block:1986,Harman:1982}, and as a result, the Lockean ``transportation model'' of communication has achieved something close to default status in contemporary philosophy. 

A challenge for the model is that it requires an account of what is shared by two people who come think or believe the same thing as a result of talking to one another. One proposal is that they share type-identical sentences in a ``language of thought'' whose atomic entities -- symbols -- represent particular features of the world by causally connecting to them in a special way \citep{Fodor:1998}. Other proposals postulate different representational constructs (e.g., prototypes, exemplars, theory-like structures etc.) that similarly connect to particular features of the world. So the answer to the challenge is roughly that successful communication results in two speakers adopting identical representational states, where two states count as identical if they refer to the same thing \citep{Fodor:1998}.\footnote{I say ``roughly'' because this description omits various complications that arise when representations \textit{refer} to the same thing, but do not to \textit{mean} the same thing (i.e., so-called ``Frege cases''), and when one tries to answer the question of what sentences (as opposed to words) refer to. Considerable efforts have been devoted to addressing these complications within a broadly Lockean framework \citep[see e.g.,][]{Speaks:2014}.} Regardless of how the details get spelled out, the strategy is clear: first, one tells a story about representational states; then, one tells a story about how language makes it possible to expose these private states to public scrutiny. 

In order for this strategy to work, it must be possible to provide a completely non-linguistic theory of the mental representations that get paired with particular words and sentences upon the learning of a language. Developing such a theory is a challenge, to say the least. One problem is that linguistic expressions tend to come in packages, in the sense that the meaning of one expression cannot be specified without invoking the meanings of others. But if so, then any representation that gets transported by a linguistic expression must bear relations to \textit{other} linguistic expressions, in which case the representation cannot be defined in a purely non-linguistic manner. Another problem is that, for many cases, it is plausible that one could not acquire the mental representation corresponding to a particular linguistic expression without first participating in a linguistic practice. Words like ``garrulous'' and ``persuasive'' are a case in point. A third problem is that meanings are supposed to explain facts about language use, and such facts primarily concern the social practices of linguistic communities. Thus, the pairing of a mental representations with a linguistic expression is generally insufficient for the purposes of characterizing the expression's meaning. 

In light of these problems, a number of theorists attracted to use-theoretic approaches to semantics have developed views on which communication is not the transportation of thought, but rather a kind of ``joint action'' \citep{Clark:1996}, or a co-operative activity that involves navigating between two social perspectives \citep{Brandom:1994}. What is shared during communication is then taken to be analogous to what is shared to by two people engaged in a dance \citep{Clark:1996,Brandom:2010}; both act independently, but the significance of each action is determined by the contribution made to the dance as a whole. Similarly, conversationalists speak independently, but the significance of what they say is determined by the contribution made to the conversation as a whole. The point can be made even clearer by again considering the notion of a language game: Just as a making a move with the king in chess depends not just on the king piece but on the nature of chess, so too is it the case that making a move in a language game depends not just on the sentence used to make the move but on the nature of the game itself. As such, there is a lot of ``social stage-setting'' that needs to be in place before it makes sense to talk about sentences meaning particular things \citep[][p. 461]{Brandom:1994}. The importance of this stage-setting cautions against views that tie sentence meanings to mental states in too narrow a fashion. 

One reason to be wary of the approach under consideration is that it makes for a complicated relationship between language and cognition. Nonetheless, I think it is possible to provide a fully adequate account of this relationship while at the same subscribing to the view that communication is kind of a joint action, as per the IPA framework. The key to developing this view lies in expanding on the strategy advocated by Dennett in the above epigraph. According to this strategy, there is no reason to describe the states of a system in representational rather than non-representational terms \textit{unless} one is committed to the applicability of the sort of ``linguistic calculus'' that is implicit in the use of intentional state attributions. My goal in this chapter is to draw an important lesson from the role that the intentional stance plays in legitimizing ascriptions of sub-personal representational states. The lesson, put simply, is that one has to \textit{start} with intentional interpretation when theorizing about mental representations, which means that one cannot use these representations to indepedently \textit{derive} an account of how intentional interpretation works. As such, the order of intentional explanation is importantly ``top-down,'' given that the use of intentional vocabulary is fundamentally rooted in the interpretation of linguistic practices rather than in the interpretation of mental states. Moreover, the point of using representational rather than, say, causal descriptions of a system's internal states is to hook up these descriptions to the linguistic calculus of intentional systems theory. The theory therefore has to come in at the start of things, contrary to what many philosophers seem to assume \citep[e.g.,][]{Millikan:1989,Fodor:1998,Dretske:1986}.\footnote{To be clear, I am not making the obviously false claim that there was language before there was the cognition in non-linguistic animals. Rather, the point is that it only makes sense to describe the behavior of these animals in semantic terms by ``stretching'' the typical uses of semantic vocabularly in linguistic contexts \citep[][p. 59]{Dennett:2010,Brandom:2010}. As a point of comparison, notice that the description of an electron as a particle that ``orbits'' an atom's nucleus involves a similar kind of stretching -- what an electron does is only loosely analogous to what we typically think of as orbiting. Moreover, if the behavior of electrons were all we had to go on, it is unlikely that we could even identify or introduce the concept of orbiting as it currently exists. Likewise, if non-linguistic animals were all we had to go on, theoretically speaking, it is unlikely that we could identify or introduce the concept of representation as it currently exists, for reasons discussed below.} 

This thesis concerning the priority of intentional interpretation has some interesting implications for debates about cognitive architecture. Intentional interpretation arises from language use, and to be a competent language user, one must be able to make certain predictions and draw certain inferences. More generally, one must be able to \textit{do} certain things by acting in particular ways. This suggests that cognitive systems are organized so as to satisfy certain function specifications. Recent accounts of cognitive architecture that are organized around the idea that brains function to control behavior \citep[e.g.,][]{Eliasmith:2003,Eliasmith:2013} accordingly fit naturally with a usage-based, inferentialist approach to semantics. As such, I contend that the inferential role semantics I have developed in no way violates the cognitive plausibility criterion introduced in Chapter 1.  

The rest of this chapter is divided into three sections. The first section develops the idea that it only makes sense to attribute representations to things that can first be interpreted as intentional systems, or things that satisfy function specifications described from the perspective of the intentional stance. The second section develops the idea that the linguistic calculus that constitutes intentional interpretation derives from the social nature of language use. The third and final section develops the idea that intentional systems -- the houses of mental representations -- are systems that implement the particular behaviors and functions that warrant identifying them as intentional to begin with. Collectively, the purpose of these discussions is to illustrate why it is a mistake to try to identify mental representations as the ``contents'' communicated by particular linguistic expressions.

Before proceeding, it is worth deflecting a potential misunderstanding. I am in no way claiming that the folk psychological categories of intentional systems theory have a privileged status in the scientific study of the mind. Rather, I take these categories to be intrinsic to the phenomenon of language use, since speakers interpret one another as agents that understand (or misunderstand) things that are said.\footnote{It is helpful to notice that ``understands'', like ``wants'' or ``thinks'', is a clear example of a propositional attitude verb of the sort used in intentional interpretation.} As such, explaining language use requires explaining how intentional interpretation works. Overall, insofar as folk psychology plays a role in the account developed here, it acts as a phenomenon in need of explanation and not as source of explanatory insight. 

\section{Rethinking Mental Representation}

While it is widely assumed that mental representations are naturalistic entities, efforts to naturalize mental representation have not exactly been paradigms of theoretical success \citep[][Ch. 3]{Horwich:2005}. The basic problem is that representations are subject to assessments of error, and what counts as an error or instance of \textit{misrepresentation} cannot be ``read off'' of a physical description of a system in which representations are hypothesized to reside. In other words, the notion of error is inherently normative, and it is not entirely clear how to accomodate this normativity within a naturalistic framework. Theories of mental representation are therefore tasked with a rather delicate balancing act. On the hand, if normativity is abandoned, it becomes impossible to usefully distinguish things that are representations from the things are not. On the other hand, if normativity is embraced, it becomes difficult to maintain one's naturalistic scruples. 

I think that my view concerning the priority of intentional interpretation offers a plausible way to navigate between these two poles. As Dennett (\citeyear{Dennett:1987)} notes, the explanations one provides upon adopting the intentional stance ``make an ineliminable appeal to the rationality of the agent'' whose behavior is being explained (p. 48). The theory of intentional systems, in other words, is an inherently normative theory. This is good news, since one can appeal to the norms of rationality at work in the theory to underwrite norms of representational correctness. One can then go on to describe, in fully naturalistic terms, the facts about a system that warrant the use of intentional systems theory when describing it. As I illustrate below, most existing theories of mental representation actually seem follow this route, albeit quite implicitly. These theories are accordingly not nearly as isolated from the linguistic phenomena at the core of intentional interpretation as one might think.\footnote{To explain, the normative notion of ``rational agency'' that is being used to underwrite an account representational error is a linguistic notion. Rational agents, in other words, are in the first instance linguistic agents who think, speak, and act in accordance with their interests. Semi-rational agents (e.g., simpler animals) are interpretable as such only by comparison to their linguistic counterparts. This is not as radical a claim as it might first appear. Consider the case of simple creatures such as bees and ants that have sophisticated social arrangements. We might call these arrangements ``semi-political,'' (cf. ``semi-rational'') but it is pretty obvious they are interpretable as such only in comparison to genuine instances of political organization amongst humans. For example, the ``queen'' of a beehive is not literally a monarch. The point here is that semantic vocabulary, like political vocabulary, is paradigmatically organized around making sense of the activities of language users.}

\subsection{Where Normativism meets Naturalism}

The risk of failing to distinguish the intentional from the non-intentional mainly confronts theories that appeal to causal, informational, or statistical relations when determining what a given representation is a representation \textit{of}. This risk is also well known to philosophers. For example, it is widely acknowledged that the fact that occurrences of a state are caused by occurrences of particular objects does does not imply that the former represent the latter, since causes are everywhere, while representations are not. It is also acknowledged that making the story more complicated by invoking asymmetrical \citep[][Ch. 4]{Fodor:1987} or statistical \citep{Eliasmith:2000} dependencies amongst causes does little to improve things on its own, since such dependencies are also everywhere. For instance, the growth of moss on a tree trunk is asymmetrically dependent on the presence of sunlight in comparison to lamplight (in the sense that the moss grows in lamplight because it grows in sunlight, but not vice versa), but moss is not by this token a representation of sunlight.\footnote{Moss might very well indicate sunlight to \textit{us} in certain circumstances, but this fact is irrelevant to the present discussion.} Similarly, a dead fire is highly statistically dependent on (and can be caused by) a lack of fuel, but a dead fire does not represent the world as lacking fuel. Given these kinds of considerations, almost no one thinks that representations can be ``read off'' of naturalistic relations characterized in purely causal or statistical terms. 

Proponents of broadly causal theories of mental representation accordingly tend to adopt the following two-step strategy. First, one identifies some entity as a representation by appealing to facts about the system in which it resides and the role it plays within this system \citep[see e.g.,][]{Eliasmith:2000}. Then, once the entity's status as a representation is secured, one appeals to causal or statistical relations of some kind to determine what the entity is a representation of. The important point is that the first step in the strategy involves a tacit appeal to the intentional stance. To explain, the decision to treat a system as a cognitive system that manipulates representations is nothing more or less than the decision to adopt the intentional stance towards it. Why? Because systems that manipulate representations are, almost by definition, systems that exhibit some degree of rational agency. And systems that exhibit rational agency are, without exception, intentional systems.\footnote{Dennett (\cite{Dennett:1987}), in fact, defines the intentional stance as a stance that involves treating an entity ``as a rational agent'' (p. 17).} So, even though the intentional stance is rarely invoked directly by proponents of causal-informational theories \citep[cf.][]{Dretske:1986}, it nonetheless comes in at the start of these theories rather than at the end. 

The opposing risk of abandoning one's naturalistic scruples mainly confronts theories that appeal to the ``proper function" of mechanisms that produce and consume representational states \citep{Millikan:1989,Millikan:2005,Dretske:1986}, or to the ``functional roles" of representational states \citep{Block:1986,Harman:1982,Eliasmith:2000}. The reason the risk arises is because specifying the role of a state or the function of a mechanism is tantamount to specifying how it \textit{ought} to behave. Functional accounts of representation are therefore inherently normative. To illustrate with an example, Millikan (\citeyear{Millikan:1989}) claims that cognitive systems can be decomposed into systems that produce representations and systems that consume representations. A state then counts as a representation if two conditions are met (pp. 287-288): first, the systems that consume the state require it to correspond to the world in a certain way in order to function properly, and second, the state must vary so as to represent different things to consuming systems in different situations. For example, the states produced in a frog's visual system by the presence of small bug-shaped dots count as representations of bugs on Millikan's view because they trigger a tongue reflex whose proper function is to result in bug ingestion \citep[][p. 291]{Millikan:1989}. If the visual states in question do not correspond to the presence of bugs (and vary in accordance with the position and velocity of these bugs), then the frog's behavior will fail to result in bug ingestion, which is contrary to its purpose. Ingesting flies is what the frog \textit{ought} to do, and the fact that this purpose is not furthered in cases where the frog snatches up bug-shaped wooden pellets is what warrants treating such cases as instances of misrepresentation. The key point in all of this is that teleo-functional accounts of mental representation are normative accounts through and through. 

To be fair, proponents of these accounts would quickly agree that normativity is playing an important explanatory role \citep{Millikan:1989,Dennett:1987}. But such proponents typically do not locate the source of this normativity within social practices that involve intentional interpretation. Rather, they appeal to evolutionary considerations to determine which organismal attributes are ``good'' and ``bad'' for reproductive fitness. I will discuss evolutionary accounts of the origins of normativity more fully in the next section, but for now, it is sufficient to note that there has to be more to the story than a simple appeal to natural selection. For one thing, natural selection acts on plants, microbes, algaes, and a variety of other living things that lack minds. So the fact that evolution discriminates between organismal attributes that do and do not promote reproductive fitness is insufficient to determine whether such attributes should be characterized in representational terms. For another thing, the notion of a ``representational consumer'' is not a purely evolutionary notion, but rather an intentional notion. It is therefore unsurprising that Millikan's (\citeyear{Millikan:1987}) descriptions of the systems that produce and consume representation repeatedly invoke intentional terminology: consumers ``attend'' to the environment (p. 290), ``understand'' the representations they consume (p. 286); producers, on the other hand, yield ``signs'' in a ``language'' that is ``read'' by the consumers (p. 286). Such terminology strongly suggests that the normativity in the theory is not being derived from selectional processes. Rather, it is being derived from the use of the intentional stance to describe and make sense of these processes.\footnote{Thanks to Eric Hochstein for helpful discussion on this point.} So once again, even if the intentional stance is rarely invoked by proponents of teleo-functional theories, it seems to be employed from the get-go in the formulation of these theories.  

One lesson to draw from this discussion is that the question of whether a system has a certain representation is quite different from the question of whether a system has, say, a certain mass or volume. One need not assume anything further about a system in order to determine its mass or volume; one simply measures it. But in order to determine whether a system contains a representation of, for instance, the temperature, one must assume that the system is an agent of sorts, with interests and needs. Put another way, one must adopt the intentional stance and treat the system as though it can know that the temperature is \textit{X}, and then act on this knowledge to warm up or cool off as desired. The cost of not adopting the stance in this case is that any grounds for attributing a temperature representation to an organism (e.g., by identifying some internal state that co-varies with temperature) would also suffice for attributing a similar temperature representation to mundane objects such as copper rings and clay pots. As such, if one cannot treat a system as an intentional system, then there is just no point in attributing representations to it. One is better off attributing non-semantic properties of sort cataloged by biologists, chemists, and physicists.  

Another way to draw the same conclusion is to observe, as others have \citep[e.g.,][]{Brandom:1994}, that representations only represent to or for interpreters. For example, to say that a danger sign at a construction site is a representation of danger involves assuming that is representation \textit{for} nearby pedestrians. The sign represents \textit{to} the pedestrians that danger is nearby. Similarly, to say that some state in a frog's visual system is a representation of a bug involves assuming that it is a representation for the frog. The state represents to the frog that a bug is in such-and-such a location. Given as much, it is incoherent to attribute a representation to a system without simultaneously treating the system as something that can interpret or understand representations. It is accordingly incoherent to attribute a representation to system without simultaneously treating that system as an intentional system.

\subsection{Where Semantics Meets Cognitive Science}

An obvious worry about this linguistically-oriented approach to representational phenomena is that it seems to be in tension with some of the most basic assumptions of contemporary cognitive science. Namely, researchers in the field tend to treat low-level perceptual and motor representations as more fundamental than high-level linguistic ones, contra my thesis concerning the priority of intentional interpretation. Neuroscientists, for example, routinely ascribe representational properties to individual neurons on the basis of their responsiveness to certain non-linguistic stimuli \citep{Eliasmith:2000,EliasmithAnderson:2003,Eliasmith:2013}. Psychologists similarly ascribe representational properties to cognitive sub-systems that regulate non-linguistic behaviors in simple reward-seeking tasks (citation?). Given these facts, it is important to consider whether a commitment to the priority of intentional interpretation is even compatible with current scientific methods for the study of cognition. 

I do not think that there is a conflict here. Rather, I think that the priority thesis actually helps one to understand why neuroscientists and psychologists attribute representations to the systems that they study. The reason for the lack of conflict is because there is rarely an empirical \textit{requirement} for neuroscientists and psychologists to describe the states in their models as representations. To illustrate, consider the case of psychologists who use artificial neural networks to describe processes that mediate between perception and action \citep[e.g.,][]{SmolenskyLegendre:2006,McClelland:2010,Elman:1990,Elman:1991}. Strictly speaking, these networks are simply collections of equations that relate certain mathematical objects to one another. Some of the objects get interpreted as stimuli (e.g., an input image becomes a vector of pixel intensities), while others get interpreted as behavioral responses (e.g., an output vector becomes a categorization decision). Certain objects also tend to get interpreted as representations (e.g., a ``hidden layer'' vector becomes a representation of an input's features). The important point is that nothing mandates taking this latter interpretational step, since it has no bearing on how the network behaves. Put simply, the question of which function gets compute (and how) is completely unrelated to the question of whether some of the network's internal states are labelled as representations. And given that such labellings make precisely \textit{no} difference to what the network actually does, they have no direct empirical significance. 

The preceding argument can be generalized by observing that when formal models are used to explain and predict cognitive phenomena, little hinges on whether the states in these models are characterized in representational terms. For instance, when neuroscientists describe populations of neurons in terms of the dynamical systems they implement \citep[e.g., oscillators, point attractors, line attractors, etc.][]{EliasmithAnderson:2003}, nothing about the behavior these systems depends on whether the states they contain are described as representations. Likewise, when psychologists use statistical models to characterize the ``knowledge'' that people possess of the world \citep[e.g.,][]{Goodman:2015}, nothing about the predictions yielded by these models depends on whether they are described as mental representations; the same distributions are assigned to the same random variables regardless. Overall, insofar as the predictions and explanations provided by cognitive scientists are directly gleaned from formal models, their quality is unaffected by choice to use representational terminology.

Why, then, is talk of internal representations so prevalent in cognitive science? Arguably, the function of such talk is to build a bridge between the computational, statistical, or control-theoretic descriptions that scientists use to characterize how a system interacts with its environment and the linguistic descriptions that they use to initially identify it as a rational, cognitive system. Once such a bridge exists, the predictions that are directly licensed by the formal properties of a model become situated against a backdrop of further predictions licensed by the adoption of the intentional stance. An example can help to make the point clear. Neuroscientists have long thought that neurons in lateral intraparietal (LIP) cortex ``code'' for the spatial locations of objects in the visual field (\citeauthor{EliasmithAnderson:2003}, \citeyear{EliasmithAnderson:2003}, pp. 72-9; \citeauthor{Andersen:1985}, \citeyear{Andersen:1985}). Models of these neurons, in turn, have been designed to mathematically express certain relationships between the neurons' spiking activities and the locations of stimuli \citep{EliasmithAnderson:2003}. On their own, however, there is nothing intrinsically representational about such relationships. Similar relationships exist between internal system states and external features of the environment in all sorts of non-cognitive entities such as wind turbines, radios, and vending machines \citep{Dennett:1987}. Nonetheless, calling a neural state a representation highlights a necessary background assumption: the entity in which the state resides is an \textit{agent} that can make use of the representation to guide its behavior. A monkey whose LIP neurons code for the position of a flashing light, for instance, can then be treated as \textit{knowing} where the light is; what the monkey goes on to do (e.g., reaching towards the light) can then be explained in terms of what it knows and what it wants (e.g., the treat behind the light). Given as much, it plausible that the point of describing certain states as representations is to allow facts about these states to guide and constrain intentional interpretation. 

A further reason for thinking that the priority thesis actually helps to make sense of representation-talk lies in the observation that competing theories of mental representation do not seem to have much in common with one another. In the recent literature, representations have alternately been described as symbols \citep{Fodor:1998}, emulators \citep{Grush:2004}, simulators \citep{Barsalou:1999}, patterns of activation \citep{McClelland:2010}, probability distributions \citep{Goodman:2015}, control-theoretic state variables \citep{Eliasmith:2003,Eliasmith:2013}, and various other things. This surfeit of variety makes no sense if the theories are taken to be competing descriptions of single kind of thing. However, it does make sense if the theories all aim at ``hooking up'' computational, statistical, or control-theoretic descriptions of different system components to the informal framework of intentional systems theory. Why? Because then there is no need for these descriptions to share anything more than a common role in guiding the attribution of linguistically specified intentional states. There might be multiple, unrelated ways of providing such guidance.

Altogether, rather than conflicting with the methods of contemporary cognitive science, the priority thesis actually helps to explain why these methods are successful. After all, a main goal of cognitive science is to develop explanatory ``ladders'' that allow one to traverse between theories at different levels of abstraction. The intentional stance gives rise to a theoretical framework concerning overt linguistic behavior. Work in psychology and neuroscience, by comparison, gives rise to a theoretical framework concerning causal relations amongst states in cognitive systems. The act of labelling these states as representations does the crucial job of building a bridge between these two theoretical frameworks, so as to lessen the mystery of how they are related to one another. An interesting consequence of this view is that the act of calling a cognitive state a representation has more to do with invoking a certain way of reasoning about a system than it has to do with identifying what the state \texit{is}.

\subsection{Where Epistemology Meets Metaphysics}

At this point, one might worry that the goal of answering questions about what mental representations really are has simply been abandoned. If labelling a state as a representation amounts to little more than adopting a certain mode of reasoning, then it become hard to think of representations as objectively real entities akin to blood cells or nucleotides. However, this consequence of my view is arguably a virtue rather than a vice. Claims about the ontological statuses of states in cognitive systems are plausibly exhausted by claims about their naturalistic properties, their causal relations to other states, and the phenomena they directly give rise to.\footnote{Or, at least, they are exhaustive if one takes a naturalistic approach to answering metaphysical questions.} Representational terminology is arguably superfluous in the context of such claims. Notice, moreover, that when cognitive scientists talk about representations as entities, they are principally talking about representational \textit{vehicles} of some kind -- brain regions, neurons, activation patterns, and so forth. These vehicles are clearly describable in physical or biological terms. It is therefore plausible that representational terminology serves as a useful epistemological heuristic, or a tool for reasoning about vehicles in the context of background assumptions that involve the use of intentional interpretation. 

This pragmatic approach to questions about the nature of mental representation makes even more sense in the context of a view favoring the explanatory priority of intentional interpretation. As Dennett \citep{Dennett:1987,Dennett:1991} notes, intentional state attributions are warranted by their predictive adequacy. It is accordingly possible for there to be equally predictive but inconsistent intentional interpretations of a single system, in which case there are no fundamental facts about which representational properties the system really has (see e.g., \citeauthor{Dennett:1987}, \citeyear{Dennett:1987}, pp. 28-9; \citeauthor{Dennett:1991}, \citeyear{Dennett:1991}, pp. 47-49).\footnote{There are, of course, fundamental facts about which physical events lead to other physical events in the system, and one could in principle rely on these non-semantic facts to accurately predict what the system goes on to do. In practice, however, this strategy is untenable due to the sheer complexity of the facts that need to be consulted. Note that there are also fundamental facts concerning when and why incommensurable sets of intentional state attributions arise \citep{Dennett:1987}.} Intentional states are therefore not concrete objects posited by a theory, but rather ``calculation-bound entities or logical constructs'' \citep[][p. 53]{Dennett:1987} that can be applied for better or for worse. Given as much, and given that intentional interpretation is fundamental in the order of semantic explanation, it is quite clear that labelling a mental state as a representation is a way of incorporating the state's behavior into a pre-existing system of a calculation-bound abstractions. Intentional terminology, in other words, invokes a kind of linguistically-based ``measurement system'' for reasoning about complicated entities \citep{Brandom:2010}, similar to the way in which numerical terminology provides a mathematically-based measurement system for performing such reasoning. It therefore makes about as much sense to ask about the physical properties of intentional states as it does to ask about the physical properties of numbers.\footnote{Though one may, of course, ask questions about which physical properties warrant the use of particular intentional or numerical descriptions of a given entity}

A further benefit of understanding intentional state attributions in primarily epistemological terms is that doing so helps to make sense of the cases in which intentional interpretation both fails and succeeds. First, consider a simple artifact such as a clothespin. One could characterize a clothespin as capable of thinking that its prongs are either touching or not touching, and as always wanting for them be touching. One could accordingly use the intentional stance to predict the clothespin's behavior -- any time its prongs are forced apart, the clothespin notices, and tries to force them back together. This characterization is pointless for the simple reason that everything the pin does can be described simply and non-intentionally in terms of the force exerted by a spring in relation to angle of the prongs. Now consider Drestke's (\citeyear{Dretske:1986}) example of an ocean-dwelling bacterium that ``represents'' the location of oxygenated surface water (which is toxic to it) through a mechanism that is, in relative terms at least, only somewhat more complicated than a clothespin \citep[cf.][p. 290-91]{Millikan:1989}. The bacterium contains an internal ``magnetosome'' that draws it directly towards magnetic north, which in the northern hemisphere is downwards and away from the toxic surface water (in the southern hemisphere, the magnetosome is reversed). An intentional interpretation of the bacterium is potentially useful because there is clearly a sense in which it ``wants'' to stay away from the toxic surface water; if it doesn't stay away, it will die. Moreover, it becomes possible to make sense of potential errors on the part of the bacterium, as when it is fooled by a nearby magnet. The appropriateness of this kind of intentional interpretation is questionable, though, given that we can predict most of what happens to the bacterium by appealing solely to the effects of magnetic forces. What we cannot predict in terms of such effects are the details of how oxygen destroys the bacterium. If these details are not fully understood, positing a need to avoid oxygen on the part of the bacterium is an effective tool for making sense of its behavior. On the other hand, if the details are simple, the bacterium can be treated like a complicated clothespin with no loss of explanatory power. 

Does the bacterium \textit{really} represent its environment using its magnetosome? It is doubtful that an answer to this question can serve any purpose other than satisfying the prejudices of intuition. The important thing is that intentional interpretation is more predictively useful for complicated systems that are difficult to understand in purely biological or mechanistic terms. Consider an ordinary rat. A considerable amount of neuroscientific research has been directed towards understanding the neural mechanisms by which rats come to learn to navigate through complicated spatial environments. One of the most prominent findings of this research concerns the existence of ``place cells'' \citep{McNaughton:1993}, or neurons that selectively respond to particular environmental locations. The responses of these neurons are accordingly characterized as representations that serve as a map of sorts to direct the rat's movements. Intentional interpretation is valuable here because it is possible to predict to what a rat is going to do if it ``thinks'' it is in such-and-such location and ``wants'' the treat located to the left of this location rather than the right. Predicting that the rat will go left is easy if one adopts the intentional stance, and probably very hard if one tries to reason through a causal chain of events in the rat's nervous system. To make the utility of the stance even clearer, consider a person who says ``I'm arriving in China tomorrow evening'' after being asked about their travel schedule. Intentional interpretation is at this point indispensable, as it offers pretty much the \textit{only} way to make a reliable prediction about which country the person will be in tomorrow evening \citep{Dennett:1987}. 

The point of comparing clothespins and bacteria to rats and people is to illustrate what is misguided about strongly metaphysical approaches to characterizing the nature of intentional states. As these examples illustrate, the question of whether an entity has intentional states is really a question about the applicability of a certain framework for reasoning about what the entity does. This framework, of course, is the ``linguistic calculus'' that one makes use of upon adopting the intentional stance, and it is a framework varies in its applicability and usefulness.\footnote{The same is also true of the more formal frameworks used to perform explicitly statistical or logical reasoning. Probabilistic frameworks, for instance, are not particularly useful when reasoning about the behavior of digital computers, while logical frameworks are.} Adopting the stance works insofar as the target of interpretation is analogous to us -- the creatures that made the stance visible in the first place through our efforts to interpret one another. It is accordingly plausible that intentional interpretation is modeled on and therefore presupposes public language use. Providing a more detailed argument in favor of this claim is the purpose of the next section. 

\section{The Social Origins of Intentional Interpretation}

The idea that genuine intentionality only gets off the ground in the presence of socially instituted norms governing language use is largely at odds with conventional philosophical wisdom. The standard view, again, is that we are thinkers first and speakers second, or that non-linguistic representations are explanatorily prior to linguistic representations. In the context of intentional systems theory, however, a departure from conventional wisdom is well motivated. To see why, notice that while the theory provides criteria for identifying intentional systems in terms of the predictive successes of intentional interpreters, it does \textit{not} provide criteria for identifying intentional interpreters \citep[][p. 57-59]{Brandom:1994}. This state of affairs amounts to solving one mystery by trafficking in another: what makes it possible to adopt the intentional stance in the first place?

An answer to this question can be given through appeal to public linguistic practices. To adopt the intentional stance, it is trivially the case that one must be a language user, and to be a language user, one must internalize the norms of a linguistic community.\footnote{One might object that these requirements rule out the possibility of animals such as monkeys or dolphins engaging in intentional interpretation. Even granting that such animals engage in fairly complex social behavior, it is quite clear that they do not attribute genuine beliefs to one another, since they do not form expectations that are consistent with the use of such attributions. For example, a monkey will be not be surprised if another monkey fails to acknowledge having eaten since yesterday even though it ``believes'' it just finished a meal.} Internalizing these norms, in the first instance, involves learning how to properly use particular linguistic expressions in particular interactions, such as when a child learns to name or retrieve a toy for an adult \citep[][]{Tomasello:2005}. More generally, learning a language involves learning about what follows from one's own verbal behavior and about what follows from the verbal behavior of others. If I ask you a question, I can usually expect an answer of some sort. If you tell me not to take your soda from the fridge, I can expect you to get angry if I do. If I describe a candle as a broomstick, I can expect anyone listening to me to be confused. And so on. The point is that these expectations are all ones that we \textit{confer on each another}; trivially, they arise from communal interaction.

Expectations involving the use of mental state verbs such as ``thinks'', ``understands'', and ``wants'' are no exception to this general rule. One learns about these terms by learning the ``conventions of use and response'' \citep[][p. 50]{Millikan:2005} that govern their behavior in the linguistic community. For instance, if James is described as  thinking that the stuffed bear is in the toy box, one learns to expect that if James wants the bear, he will look in the toy box (rather than, say, in the laundry hamper or under the coffee table), even if the bear is not actually in the toy box. It is quite uncontroversial from the perspective of developmental psychology that ``theory of mind,'' or the ability to engage to intentional interpretation, emerges in tandem with linguistic ability \citep{Miller:2006}. For instance, children typically develop an understanding of mental state terms via linguistic explanation, and their performance on false-belief tasks is markedly improved when they are instructed in the use of certain linguistic constructions. Moreover, their initial linguistic abilities are much more predictive of their later theory of mind abilities than vice versa. This asymmetry suggests that the ability to use language is an important precursor to the ability to engage in intentional interpretation. Overall, regardless of the exact nature of the relationship between language use and theory of mind, it is quite clear that the two tend to go hand-in-hand.

Some reasons for this connection between language use and intentional interpretation are fairly easy to identify. On an empirical level, language learning involves forming expectations about the roles played by certain noises and gestures in social interaction \citep{Tomasello:2005,Tomasello:2003}. It also involves identifying others as the primary producers and consumers of these noises and gestures; one's expectations become attuned to the fact that the consequences of language use always get routed through people. As such, the need to keep track of these highly complex consequences creates pressure to interpret or model the people from which they originate. Adopting the implicit calculus of intentional interpretation is a natural way of relieving this pressure. On a more conceptual level, noises and gestures only \textit{become} meaningful by being \textit{treated} as meaningful within a community of language users \citep{Brandom:1994}. And as noises and gestures become meaningful, the beings that produce and respond to them become beings that \textit{mean} by speaking and \textit{understand} by listening. The fact that meaning and understanding are ``two sides of the same coin'' in this way illustrates the conceptual dependence between intentional interpretation and language use \citep[][p. ??]{Brandom:1994}. Put simply, a precondition of meaning something is knowing what would constitute someone else \textit{understanding} what was meant, and treating someone else as potentially capable of understanding trivially involves adopting the intentional stance towards them. As such, the idea that a person can genuinely mean something by their behavior without being able to engage in intentional interpretation is incoherent \citep{Brandom:1994}. Overall, the thesis that intentional interpretation has social origins amounts to the claim that by conferring expectations upon one another via their joint linguistic behavior, people \textit{mold} one another into intentional interpreters. 

Again, the major concern with this approach is that is it treats intentionality as a primarily \textit{linguistic} phenomenon, which misleadingly ignores the more typical cases of intentional phenomena in non-linguistic creatures \citep{Eliasmith:2000,Dennett:1987,Dennett:2010,Millikan:1989,Millikan:2005,Dretske:1986}. Language using creatures are merely the most complex and sophisticated representational systems, so it makes sense to try to understand simpler representational systems first. Indeed, absent some story about how simpler representational systems transitioned into more complicated systems that exhibit linguistic abilities, the existence of language (and hence intentionality) is left to appear almost magical \citep{Dennett:2010}. 

Proponents of this criticism must, of course, provide an alternative account that makes no appeal to norms of public language while nonetheless underwriting norms of representational correctness. As mentioned above, the typical way of discharging this responsibility involves an appeal to evolutionary considerations \citep{Millikan:1989,Millikan:2005,Dennett:1987,Dennett:2010}. The idea is that various mechanisms in non-linguistic organisms are ``designed'' via natural selection to indicate or detect certain features of the environment, and thereby form representations. For instance, the famous ``dance of the honeybee'' has the function of indicating the location of nectar to other bees, and the fact that the dance has this function is because it has evolved to have this function \citep[see][]{Sellars:1954}. As Millikan (\citeyear{Millikan:1989}) puts it, the ``proper function'' of a process such as the honeybee dance is whatever explains or is responsible for the process's continued existence in the honeybee population. Dennett (\citeyear{Dennett:1987}, Ch. 8) provides a nice analogy that generalizes this idea further. Organisms can be thought of ``survival machines'' that acquire capacities to monitor and react to their environment only insofar as these capacities help preserve their existence from one generation to the next. Natural selection, through a random search of possible machine designs, settles on a design that constitutes a minimal solution to the problem of survival. The ``specs'' of this design thus constitute the norms against which instances of misrepresentation and error can be evaluated. 

There are two general limitations to this teleological approach to intentionality. First of all, the idea that natural selection is the source of all intentional phenomena is both trivially true and largely unhelpful. It is trivially true because no reasonable person would disagree with the claim that cognitive beings have come to exist they do as a result of natural selection. But to say as much is unhelpful because no explanation is provided for why certain states and mechanisms in organisms should be described in representational terms rather than in causal or biological terms. In fact, the idea that a state has the function of indicating or detecting already presupposes the idea that the state resides in an intentional system. Moreover, treating nature as a ``designer'' (even if just metaphorically) that assigns functions to various representation-producing mechanisms \textit{assumes} the intentional stance as a tool for interpreting evolutionary processes. One needs to indulge in the pretense that nature is a purposive agent in order to make sense of the idea that nature designs or determines the ``proper function'' of various biological mechanisms.\footnote{Notice that appeals to brute optimization are cannot be used to underwrite norms of proper function, since brute optimization acts many on things that have no proper function. The course taken by riverbed, for example, is an optimal ``path of least resistance'' from high ground to low ground, but there is no sense in ``oughts'' come into play in descriptions of riverbeds.} But helping oneself to the intentional stance in an explanation of the origins of intentionality is circular. 

A second problem is that even if a non-circular teleological account of intentionality can be given, it is not at all obvious how such an account might be extended the full range of intentional phenomena in language users. All parties to the debate acknowledge that selectional pressures do not yield mechanisms for producing particular representational states of the sort corresponding to sentences like ``The election results were surprising'' or ``Coffee is better with cream in it.'' Rather, the story is that organisms have adapted to have generic representation-producing mechanisms that can be used in highly general and ``innumerably diverse'' ways \citep[][p. 292]{Millikan:1989}. True enough, but identifying evolutionary pressures as distal causes of intentional phenomena is a bit like identifying the existence of carbon as a distal cause of certain architectural phenomena. Learning about carbon will not tell you much about the architecture of buildings made from carbon-based metals, just as evolutionary considerations will not tell you much about meanings of specific linguistic expressions. In any event, teleological accounts of intentionality are typically only worked out for cases involving low-level perceivables such as object locations \citep{Millikan:1989}, or mid-level perceivables such as faces \citep{Dennett:1987}. Building up towards mental representations of more complicated things is, to put it mildly, a challenge. The fact that this challenge has not been met despite decades of effort suggests that it is wise to place evolutationary considerations to the side during theory development (as many scientists who study human behavior, in fact, do). 

To be clear, the conclusion here is \textit{not} that one should adopt a linguistically oriented approach to studying cognitive systems, or even that mental representations are inherently linguistic. Rather, the conclusion is that the use of semantic vocabulary in characterizing the internal states of cognitive systems ought to be seen as a way of hooking these characterizations up to the implicit calculus of intentional systems theory. For instance, designating a state as a representational state as opposed to a solely neural state introduces a commitment to the idea that the surrounding system \textit{makes use} of the state in a purposive manner, analogously to how people make use of things that are said to them. It is admittedly true that the informal theory that governs intentional interpretation has a rich evolutionary history, since it is part of the ``manifest image'' \citep{Sellars:1963} that evolution has endowed us with so as to usefully structure our pre-scientific understanding of the world \citep{Dennett:1987}. However, it does not follow from this that norms of representational correctness can be directly read off of selectional processes. It is instead the case that these processes have given rise to a manifest image that contains notions of norms and rationality. Once these notions are in place, they can be adapted to make sense of the evolutionary processes from which they arose. 

\section{Consequences for Cognitive Architecture}

If being a language user is a matter of satisfying a certain function specification, then not just anything can \textit{be} a language user. Keeping track of of the defeasible expectations that regulate communal language use requires the possession of certain information-processing capabilities. Since brains are principally responsible for the realization of such information-processing capabilities, the following two questions naturally arise. First, what kinds of things do brains have to be able to do in order perform the kind of intentional interpretation that gives rise to meaningful language use? And second, do brains actually do these things? Call these the functional and implementational questions, respectively. Answering them is the purpose of the remainder of this section. 

Concerning the functional question, a useful starting point is the observation that brains seem to be largely in the business of performing statistical inference \citep{Eliasmith:2007,clark:2013}. This is good news, since adopting the intentional stance involves forming probabilistic expectations about what people are likely do next during a conversation. The main constitutive requirements of intentional interpretation are accordingly that one (a) be able to \textit{infer} the likely consequences of various forms of linguistic behavior, and (b) be able to \text{act} on the basis of these inferred consequences. The first of these requirements concerns language comprehension, while the second concerns language production. 

To introduce a bit more in the way of details, it helps to consider an intuitive example of the sort described in Chapter 1. Suppose Jim and Jane are talking about Jane's recent hiking trip. Jim asks, ``Did you see any interesting animals on the hike?'' To count as properly understanding this question, it is plausible that Jane has to be able to form certain predictions about what Jim is likely to do next. In the absence of some expectation that Jim will be taken aback if she does not respond, it is hard to justify the claim that Jane understands that Jim \textit{asked a question}. Similarly, in the absence of some expectation that Jim will puzzled if she responds by talking about how she is tired, it is hard to justify the claim that Jane understands that Jim's question was about whether or not she \textit{saw animals}. Now suppose that Jane's actual response is ``Yes, I saw a badger leaving its burrow at one point.'' To count as properly understanding this response, Jim has to likewise form certain predictions about what Jane is likely to do next. For instance, Jim ought to expect that Jane will acknowledge having seen a gray animal with stripes. Jim also ought to expect that Jane will naturally answer certain further questions such as ``How big was it?'' or ``How far away was it?'', but not ``How how high in the air was it?'' (or at least not without some consternation). And whatever Jim's actual response is, it is fair to assume that it will induce yet further expectations in Jane insofar as she is capable of understanding what was said. 

The point of the example is to illustrate that one can only \textit{use} language in an effective manner if one has a model of the expected consequences of linguistic acts. Otherwise, dialogue breaks down under the weight of odd silences and frequent non-sequiters. Just imagine if Jane's response to Jim's initial question was ``I'm oddly tired today,'' while Jim's follow-up was ``How high in the air was it?'' Models of the inferential roles of linguistic expressions, again, are hypothesized to be just the sort of models we use avoid such conversational mishaps. For instance, the reason that Jim can expect Jane to answer questions concerning the size and shape of the badger (but not its altitude) is because it follows from fact that something is a badger that it has a size, and that it can be nearer or farther away. The inferential role of the sentence ``I saw a badger leaving its burrow at one point'' accordingly specifies the targets of plausible questions and hence the plausible directions in which the conversation can proceed. Likewise, the fact that there is no straightforward inference from something being a badger to it being airborne explains why questions concerning altitude are so out of place.

Altogether, participating in a conversation requires keeping track of what \textit{can be} said as a result of what \textit{has been} said. The fact that linguistic expressions bear inferential relationships towards one another is what makes such tracking possible. In other words, a sentence's inferential role is what determines \textit{how} the conversation is altered when the sentence is uttered, by settling which further sentences can plausibly be uttered by each interlocutor. This general point can be usefully illustrated by observing that each movement in a ``linguistic dance'' is effectively an inference from what was just said to what is said next. For instance, providing an answer to a question clearly involves an inference whose premises are the question itself and various further facts known to the answerer. Asking a question similarly involves an inference from some prior statements to a request for further relevant information. For instance, if these prior statements concern the value of an antique vase, then there is no plausible inference from these statements to a question about, say, the distance between Waterloo and Toronto.  

The preceding description is a slight oversimplification given that pragmatic considerations involving such things as the social roles, appropriate subject matter, and general etiquette also influence how questions are asked and answered. But to admit this in no way undermines the claim that inferential roles are explanatorily fundamental to how conversations unfold, as per the IPA framework. Taking etiquette into account, for instance, presupposes that there are more basic conversational principles that the norms of etiquette somehow infringe upon. Shifts in subject matter similarly presuppose that within-subject dialogue is independently well-defined. Separating out the core facets of language use from more peripheral and context-dependent ones is undoubtedly hard work, but then again, linguistic phenomena are some of the most complex phenomena in existence, so the need for hard work should come as no surprise.

Now that it is clear that the minimal requirements of intentional interpretation include being able to predict the consequences of various linguistic acts, it is possible to turn to the implementational question: Do brains actually do the job of predicting and inferring upcoming conversational events? A good starting point for answering this question can be found in recent research concerning the role of prediction in language processing \citep{Pickering:2013,Pickering:2007,Christiansen:2015}, and cognition more generally \citep{clark:2013}. I consider three sources of evidence indicating that the IPA framework is consistent with our current understanding of linguistic cognition.

The first source of evidence concerns conversational turn-taking. Effective dialogue requires participants to alternate between speaking and listening in an appropriate manner, and to avoid wasteful lags between such alternations, people implicitly predict when and how a speaker will stop talking \citep{Christiansen:2015,Pickering:2013}. It is clear that such anticipation occurs given that shifts between speakers are nearly instantaneous, which means that listeners begin to generate a response \textit{before} the speaker even finishes, given that the syntactic, phonological, and articulatory processes involved in speech production collectively take several hundred milliseconds to complete \citep{Pickering:2013}.\footnote{Notice too that the predictions underlying such rapid alternations cannot merely be along the lines of ``It's my turn now'', given that the anticipatory initiation of speech production has to result in a very specific utterance. The natural conclusion to draw here is that listeners make use of prediction to start responding to exactly what speakers say before they even finish saying it.} Further evidence of this kind of anticipation can be found in fMRI studies that indicate a general alignment in the patterns of neural activity observed across speakers and listeners, with speakers lagging behind listeners in striatal and anterior frontal areas in virtue of listeners trying to anticipate the current trajectory of the dialogue \citep[reviewed in][]{Christiansen:2015}.  Such alignment between speakers and listeners also appears to strongly facilitate mutual comprehension \citep{Pickering:2013,Christiansen:2015}. This all makes sense within the IPA framework, since understanding an utterance is taken to involve drawing certain inferences.

A second source of evidence concerns the incremental interpretation of speech. As mentioned in Chapter 1, the fact that speech is voluminous while memory is limited favors processing mechanisms that rapidly compress linguistic inputs into increasingly abstract ``chunks'' \citep{Christiansen:2015}. To facilitate such chunking, predictions of subsequent inputs are used to constrain how current inputs are compressed, so as to quickly resolve local ambiguities and avoid having to backtrack later on (p. 9). Evidence of the existence of such anticipatory processing is perhaps most pronounced in the literature on the N400 event-related potential \citep{Federmeier:2007,Kutas:2011}. This response is evoked by the presentation of anomalous sentence continuations (e.g., ``He planted beans in his \underline{car}''), and is hypothesized to reflect processing involved in suppressing or revising an earlier prediction of more plausible continuations (e.g., ``He planted beans in his \underline{garden}'', see p. 2). Eye-tracking studies similarly indicate that subjects attend to particular visible objects in anticipation of sentence continuations. For instance, subjects presented with an image depicting a young girl, a carousel, and a motorcycle will fixate on the carousel upon hearing, ``The girl will ride the...'' \citep[][p. 194]{Kutas:2009}. Overall, there is little doubt that people understand speech by incrementally building up a set of expectations about what the speaker is likely to say next. 

A third source of evidence concerns the existence of discourse-level predictions. Studies of narrative processing, for example, indicate that subjects anticipate specific sentential transitions on the basis of a variety of pragmatic cues \citep{Rohde:2008}. The effect of these cues is to suggest a particular kind of an inferential transition from one sentence to the next. For instance, sentences describing ongoing events (e.g., ``John was handing a book to Bob'') tend to generate expectations of transitions that are either explanatory (e.g., ``He wanted Bob to read it'') or elaborative (e.g., ``He reached across the table''). Sentences describing completed events (e.g., ``John handed a book to Bob'', in contrast, tend to generate expectations of transitions that introduce new information (e.g., ``He took it and thanked John''). The existence of these expectations is revealed in part by how people interpret pronouns. Specifically, in the case of a statement describing an ongoing event, the initial pronoun in a subsequent statement tends to be immediately interpreted as referring to the individual associated with the \textit{start} of the event (i.e., ``John'' in the example above). In the case of a statement describing a completed event, however, the initial pronoun in a subsequent statement tends to be immediately interpreted as referring to the individual associated with the \textit{result} of the event (i.e., ``Bob'' in the example above). This difference is hard to explain unless subjects are relying on their tacit expectations of how the narrative will continue to preemptively settle on a particular interpretation. It is also possible to bias the interpretation in question by manipulating the prior narrative to suggest the onset of a particular type of inferential transition \citep{Rohde:2008}. Altogether, this research provides quite direct evidence in favor of the IPA framework: engaging in a ``linguistic dance'' with another a speaker requires continually updating and acting on a set of expectations concerning what they are likely to say and do next.\footnote{The fact that the inference from ``John was handing a book to Bob'' to ``John wanted Bob to read it'' is highly contingent on further facts about John and Bob does not undermine the claim that the inference is partially constitutive of what these sentences mean. To explain, if it were equally plausible to reason from ``John was handing a book to Bob'' to either ``John wanted Bob to read it'' or ``Woodworking is a common hobby'', then ``John was handing a book to Bob'' would clearly not mean what it in fact does mean. Moreover, inferences of the sort in question typically involve multiple (perhaps implicit) premises that collectively lend plausibility to the conclusion.}

There are two caveats to keep in mind with regard to the question of how all of this evidence bears on the model described in Chapter 3. First, the model does not directly account for any of the empirical phenomena just discussed, with the exception of discourse transitions that involve elaboration, since predicting an elaboration involves anticipating what is entailed by a given statement. As such, there remains a lot of work to do in identifying the mechanisms and processes by which speakers exploit their tacit understanding of the inferential roles of sentences to adopt the intentional stance towards one another. Second, I have not directly made use of existing approaches to modeling the kinds of prediction just discussed. For instance, work on ``predictive processing'' is typically carried out by assuming that a generative model matches top-down sensory predictions to bottom-up sensory information, and that sensory representations are in fact representations of prediction-error \citep{clark:2013}.\footnote{These representations of error are then hypothesized drive both learning and behavior so as to reduce the error.} 

\section{Conclusion}

What, then, is the nature of the relationship between language and cognition? 



Meaning, on the view proposed here, is very much a part of what Wilfrid Sellars (\citeyear{Sellars:1963}) calls ``the manifest image,'' or the intuitive theories that make up our commonsense understanding of the world. The notion that one thing can be a representation of another only becomes visible in communal, normative practices of intentional interpretation; once these practices are in place, it then becomes possible to adapt the notion of something being a representation to make sense of non-linguistic mental states. There are, of course, a variety of facts about people that make it such that we interact in the ways that we do and thereby come to conceive of the world in the ways that we do. These facts are of the sort analyzed and described by biologists and neuroscientists in largely non-semantic terms. The introduction of semantic vocabulary is accordingly a way of using the commonsense notions of representation and meaning to explain how we are built to acquire these notions in the first place. As such, making states and processes visible as representations amounts to retrospectively interpreting the preconditions of our own linguistic intentionality in terms of their relationship to the kind of cognitive prowess that is their end result.